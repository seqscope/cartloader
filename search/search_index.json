{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"CartLoader","text":""},{"location":"#a-scalable-harmonized-and-cloud-friendly-ecosystem","title":"A Scalable, Harmonized, and Cloud-friendly Ecosystem","text":"<p>Spatial transcriptomics (ST) technologies have revolutionized our ability to map molecular features with remarkable resolution\u2014down to cellular and subcellular levels. The rapid development of sequencing-based platforms (e.g., Seq-Scope, Stereo-seq, Pixel-seq, 10x Visium HD) and imaging-based platforms (e.g., 10x Xenium, Vizgen MERSCOPE, CosMx SMI) has led to an explosion in the production of ST datasets across diverse tissues and species.</p> <p>However, the rapid diversification of spatial transcriptomics platforms has led to heterogeneous data formats, inconsistent metadata schemas, and platform-specific analysis pipelines. Moreover, existing tools often lack the scalability to visualize gigapixel-scale data without downsampling.</p> <p>To address this challenge, we introduce a scalable, harmonized, and cloud-friendly CartoScope ecosystem for spatial omics data across platforms.</p>"},{"location":"#core-modules","title":"Core Modules","text":"<p>CartoScope ecosystem is composed of three modules:</p> <p>CartLoader \u2013 a harmonized, scalable pipeline for data processing.</p> <p>This document introduces <code>CartLoader</code>, the core engine of our ecosystem. It provides a modular, reproducible tool to harmonize, integrate, analyze, and visualize raw high-resolution ST data across platforms. Usage examples are provided in the Vignettes. A detailed description (action, inputs, outputs, and parameters) is provided for each module in the Reference Pages.</p> <p>Key Features</p> <ul> <li>Cross-Platform Format Conversion: Converts raw SGE data from diverse ST platforms into a unified format, enabling consistent downstream processing.</li> <li>Spatial Factor Inference: Applies FICTURE to infer spatial factors directly from pixel-level data, capturing biological patterns without requiring cell segmentation.</li> <li>Multi-Modal Alignment: Aligns and overlays histology images with SGE data so all layers share a common coordinate system for pixel-accurate comparisons.</li> <li>Cloud-Friendly Outputs: Produces compact, geospatially-indexed data formats suitable for web visualization and cloud storage.</li> <li>Batch Integration and Sample Stitching: Supports joint analysis and SGE stitching across samples or platforms to reveal shared or differential features across tissues.</li> <li>Modular and Reproducible Workflow: Orchestrates all steps through a Makefile-based system to ensure scalability, transparency, and reproducibility.</li> </ul> CartoStore \u2013 an open-access, cloud-hosted repository for dataset sharing. <p>CartoStore acts as the data repository, hosting datasets processed by CartLoader and making them accessible to CartoScope. </p> <p>Core Features:</p> <ul> <li>Ready-to-use Datasets: Access processed, high-resolution datasets of which have FICTURE analysis results, morphology images, cell analysis results, etc., immediately for interactive exploration.</li> <li>Broad Coverage: Spans diverse species, tissues, and disease models for a wide range of research needs.</li> <li>Growing Repository: Continuously updated with new datasets as they are processed and added.</li> </ul> <p>Visit the CartoStore Repository to access public datasets.</p> CartoScope \u2013 a web-based App for interactive exploration at original resolution. <p>CartoScope is the frontend of our ecosystem, enabling interactive, pixel-level exploration of spatial omics data without requiring programming expertise. </p> <p>Core Capabilities:</p> <ul> <li>Ultra-high-resolution data at scale: Seamless web exploration for submicron-resolution spatial transcriptomics data with hundreds of millions of spatial pixels, tens of thousands of genes, and billions of transcripts.</li> <li>Molecular-level Inference with FICTURE: Powered by FICTURE analysis to preserve spatial accuracy and complexity, breaking the barrier of histology-based segmentation bias.</li> <li>Dynamic Multi-layer Exploration: Interactive multi-layer maps with aligned multimodal datasets\u2014including morphology images, cell-level analysis, molecular inference, and spot summaries\u2014enabling exploration with rich, end-to-end spatial context.</li> <li>Seamless Integration with Morphology Images: Support for various morphology images (H&amp;E, DAPI, fluorescence reporters) in diverse formats, seamlessly integrated with omics data.</li> <li>Interactive ROI Analysis: Interactively define regions of interest, extract spatial features, and run differential expression analysis.</li> <li>Save &amp; Share Workspace: One-click save for your workspace (layers, styling, ROIs) and instant sharing with collaborators via unique links.</li> <li>Open Access: Upload, screen, and share datasets worldwide at no cost.</li> </ul> <p>Visit the CartoScope to learn more details.</p> <p>Together, this system provides a unified solution for working with raw pixel-level spatial omics data\u2014without sacrificing resolution or reproducibility.</p>"},{"location":"#citations","title":"Citations","text":"<ul> <li>FICTURE: doi.org/10.1038/s41592-024-02415-2</li> </ul>"},{"location":"installation/","title":"Installation Guide","text":"<p>This document walks through the environment setup and installation steps required for <code>CartLoader</code>.</p>"},{"location":"installation/#1-dependencies","title":"1. Dependencies","text":"<p>Before installing <code>CartLoader</code>, make sure the tools below are present on your system.</p>"},{"location":"installation/#11-required-system-utilities","title":"1.1 Required System Utilities","text":"<p>Confirm that these command-line programs are installed:</p> <ul> <li><code>gzip</code></li> <li><code>sort</code></li> <li><code>bgzip</code></li> <li><code>tabix</code></li> </ul>"},{"location":"installation/#12-external-tools-and-utilities","title":"1.2 External Tools and Utilities","text":"<p>These packages support spatial data handling and file conversion. Several are bundled as git submodules.</p> <p>Python &amp; Related Tooling</p> <ul> <li><code>python</code> (verified with versions 3.10 and 3.13.1)</li> <li><code>parquet-tools</code></li> </ul> <p>R &amp; related Packages:</p> <ul> <li><code>R</code> from CRAN(verified with versions 4.5.1)</li> </ul> <p>External Tools (included as submodules)</p> <ul> <li><code>punkst</code> (the latest and more efficient implementation of FICTURE)</li> <li><code>spatula</code></li> <li><code>tippecanoe</code></li> <li><code>magick</code></li> <li><code>go-pmtiles</code></li> </ul> <p>Geospatial Utilities</p> <ul> <li><code>gdal</code></li> </ul> <p>Cloud &amp; CLI Utilities</p> <ul> <li><code>aws-cli</code></li> </ul>"},{"location":"installation/#2-setting-up-the-environment-using-conda","title":"2. Setting Up the Environment using <code>conda</code>","text":"<p>We recommend isolating the project in a <code>conda</code> environment to avoid dependency conflicts.</p>"},{"location":"installation/#21-installing-conda","title":"2.1 Installing <code>conda</code>","text":"<p>If <code>conda</code> is not already available, download and install Miniconda or Anaconda.</p> <p>Example installation of <code>Miniconda3</code> on Linux:</p> <pre><code>env_dir=/path/to/your/directory/hosting/tools/      ## replace `/path/to/your/directory/hosting/tools/` with your preferred tools directory\ncd $env_dir\n\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\nbash Miniconda3-latest-Linux-x86_64.sh\n</code></pre>"},{"location":"installation/#22-creating-an-environment","title":"2.2 Creating an Environment","text":"<p>Set up a fresh environment for <code>CartLoader</code>:</p> <pre><code>conda create -n ENV_NAME python=3.13.1   # choose the environment name and Python version that suits your workflow\nconda activate ENV_NAME\n</code></pre>"},{"location":"installation/#23-install-core-dependencies","title":"2.3 Install Core Dependencies","text":"<p>Install the core dependencies once the environment is active:</p> <pre><code>conda install -c conda-forge gdal aws-cli imagemagick parquet-tools r-base\n</code></pre>"},{"location":"installation/#3-installing-cartloader","title":"3. Installing <code>CartLoader</code>","text":"<p>Clone the repository and install required Python and R packages:</p> <pre><code>cd $env_dir\ngit clone git@github.com:seqscope/cartloader.git\ncd cartloader\n\n# Install python requirements:\npip install -r ./requirements.txt\n\n# Install R packages:\nRscript ./install_r_packages.R\n\npip install -e ./\n</code></pre>"},{"location":"installation/#4-initializing-submodules","title":"4. Initializing Submodules","text":"<pre><code>cd $env_dir/cartloader\ngit submodule update --init --recursive\n</code></pre>"},{"location":"installation/#41-installing-spatula","title":"4.1 Installing <code>spatula</code>","text":"<p>Install <code>spatula</code> with its dependencies from the submodules directory:</p> <pre><code>cd ${env_dir}/cartloader/submodules/spatula\n\ncd submodules\nbash -x build.sh\ncd ..\n\n## build spatula\nmkdir build\ncd build\ncmake ..\nmake\n</code></pre>"},{"location":"installation/#42-installing-punkst","title":"4.2 Installing <code>punkst</code>","text":"<p>Install the <code>punkst</code> toolkit to use <code>FICTURE</code> (Si et al., Nature Methods 2024).</p> <p>Please follow the <code>punkst</code> installation guide.</p> <p>What are <code>FICTURE</code> and <code>punkst</code>?</p> <p><code>FICTURE</code> is a segmentation-free method that infers latent spatial factors\u2014coherent spatial patterns of gene activity\u2014that correspond to underlying transcriptional programs or tissue structures. These factors can then be projected back to the pixel level. Although <code>FICTURE</code> is built on a Latent Dirichlet Allocation (LDA) framework by default, it is also compatible with clustering outputs from external tools like <code>Seurat</code> for pixel-level projection.</p> <p>The <code>punkst</code> toolkit is a streamlined implementation of <code>FICTURE</code>, designed for improved computational efficiency and scalability while producing results equivalent to the original.</p>"},{"location":"installation/#43-installing-tippecanoe","title":"4.3 Installing <code>tippecanoe</code>","text":"<pre><code>cd ${env_dir}/cartloader/submodules/tippecanoe\nmake -j\n\n## Choose one of the following installation options:\n# (1) System-wide installation (requires root access):\nmake install\n\n# (2) Local installation (no root access): specify a custom PREFIX\nmake install PREFIX=${env_dir}/cartloader/submodules/tippecanoe/  # Replace with your desired installation path\n</code></pre>"},{"location":"installation/#44-installing-go-pmtiles","title":"4.4 Installing <code>go-pmtiles</code>","text":"<p>An easy way to install <code>go-pmtiles</code> is to download a release from the official website and decompress it. This provides a <code>pmtiles</code> binary ready for use.</p> <p>Here is an example of its installation:</p> <pre><code>cd ${env_dir}\nwget https://github.com/protomaps/go-pmtiles/releases/download/v1.28.0/go-pmtiles_1.28.0_Linux_x86_64.tar.gz\ntar -zxvf go-pmtiles_1.28.0_Linux_x86_64.tar.gz\n</code></pre>"},{"location":"installation/#45-installing-imagemagick","title":"4.5 Installing ImageMagick","text":"<p>Skip this step if ImageMagick was already installed via <code>conda</code> in Section 2.3.</p> <pre><code>cd ${env_dir}/cartloader/submodules/ImageMagick\n./configure     # Alternatively, run `./configure --prefix=${env_dir}/cartloader/submodules/ImageMagick`.\nmake \nmake install \n</code></pre>"},{"location":"installation/#5-verifying-the-installation","title":"5. Verifying the Installation","text":"<p>Run the following command to verify that the package loads correctly:</p> <pre><code>python -c \"import cartloader; print('cartloader installed successfully!')\"\n</code></pre>"},{"location":"reference/feature_customization/","title":"Feature Filtering (Add-on)","text":""},{"location":"reference/feature_customization/#overview","title":"Overview","text":"<p><code>CartLoader</code> provides an add-on module, named <code>feature_filtering</code>, to filter features (e.g., genes) from a CSV/TSV using explicit lists, substrings, regex patterns, or a type reference file.</p> <p>The curated feature file can then be used downstream, including FICTURE analysis.</p>"},{"location":"reference/feature_customization/#example-usage","title":"Example Usage","text":""},{"location":"reference/feature_customization/#1-filter-by-regex","title":"1) Filter by Regex","text":"<p>This example demonstrates an exclude-only pattern with <code>--exclude-feature-regex</code>; conversely, you could keep only matching features using <code>--include-feature-regex</code>.</p> <pre><code>cartloader feature_filtering \\\n  --in-csv /path/to/sge/feature.clean.tsv.gz \\\n  --out-csv /path/to/sge/feature.filtered.tsv.gz \\\n  --exclude-feature-regex '^(BLANK.*$|NegCon.*$|NegPrb.*$)'\n</code></pre>"},{"location":"reference/feature_customization/#2-filter-by-lists","title":"2) Filter by Lists","text":"<p><code>CartLoader</code> supports include-only and exclude-only list-based filtering; pick the one that fits your use case (or combine them). Below is an example using <code>--include-feature-list</code>.</p> <pre><code>include_list=/path/to/input_keep_genes.txt \ncartloader feature_filtering \\\n  --in-csv /path/to/sge/feature.clean.tsv.gz \\\n  --out-csv /path/to/sge/feature.filtered.tsv.gz \\\n  --out-record /path/to/sge/feature.filter_record.tsv \\\n  --csv-colname-feature-name gene \\\n  --include-feature-list ${include_list}\\\n  --log\n</code></pre>"},{"location":"reference/feature_customization/#3-filter-by-substrings","title":"3) Filter by Substrings","text":"<p>Below, include and exclude are shown together for illustration; you may use either one independently.</p> <pre><code>cartloader feature_filtering \\\n  --in-csv /path/to/sge/feature.clean.tsv.gz \\\n  --out-csv /path/to/sge/feature.neuronal.tsv.gz \\\n  --include-feature-substr Neur \\\n  --exclude-feature-substr Pseudo\n</code></pre>"},{"location":"reference/feature_customization/#4-filter-by-feature-types","title":"4) Filter by Feature Types","text":"<p>These examples show include-by-type filtering using a reference file; adapt the regex to the types you want to keep. Below provides two examples:</p> <pre><code># Example 4A includes `protein_coding` features and uses column names and a TSV reference file.\n\nref_tsv=/path/to/refs/feature_types.tsv\n\ncartloader feature_filtering \\\n  --in-csv /path/to/sge/feature.clean.tsv.gz \\\n  --out-csv /path/to/sge/feature.protein_coding.tsv.gz \\\n  --include-feature-type-regex '^protein_coding$' \\\n  --feature-type-ref ${ref_tsv} \\\n  --feature-type-ref-colname-name gene \\\n  --feature-type-ref-colname-type type\n\n# Example 4B includes `lncRNA` features using column indices (0-based) and a CSV reference file:\n\nref_csv=/path/to/refs/gene_types.csv \n\ncartloader feature_filtering \\\n  --in-csv /path/to/sge/feature.clean.tsv.gz \\\n  --out-csv /path/to/sge/feature.lncRNA.tsv.gz \\\n  --include-feature-type-regex '^lncRNA$' \\\n  --feature-type-ref ${ref_csv} \\\n  --csv-delim \",\" \\\n  --feature-type-ref-colidx-name 0 \\\n  --feature-type-ref-colidx-type 2\n</code></pre>"},{"location":"reference/feature_customization/#actions","title":"Actions","text":"<p>Action Specifications</p> <p>No action runs by default. Activate at least one using filtering criteria the filter parameters.</p> <p>Include or exclude features by using explicit lists, substrings, regex patterns of feature name or types. Please note that:</p> <ul> <li>Include criteria are restrictive (a feature must satisfy all provided include constraints).</li> <li>Exclude criteria are subtractive (a feature matching any exclude constraint is removed).</li> </ul>"},{"location":"reference/feature_customization/#parameters","title":"Parameters","text":""},{"location":"reference/feature_customization/#inputoutput-parameters","title":"Input/Output Parameters","text":"<ul> <li><code>--in-csv</code> (str, required): Input CSV/TSV of features (plain text or gzipped).</li> <li><code>--out-csv</code> (str, required): Output filtered CSV/TSV; gzipped.</li> <li><code>--out-record</code> (str): Optional TSV with <code>feature</code> and <code>filtering</code> reason per feature.</li> <li><code>--csv-colname-feature-name</code> (str): Feature column name in the input file (default: <code>gene</code>).</li> <li><code>--csv-delim</code> (str): Field delimiter for the input (applies to output as well; default: <code>\\t</code>).</li> <li><code>--chunksize</code> (int): Chunk size for streaming reads (default: 50000).</li> <li><code>--log</code> (flag): Write logs to <code>feature_filtering.log</code> next to outputs.</li> </ul>"},{"location":"reference/feature_customization/#filters-parameters","title":"Filters Parameters","text":""},{"location":"reference/feature_customization/#list-filters-parameters","title":"List Filters Parameters","text":"<ul> <li><code>--include-feature-list</code> (str): Path to a file with feature names to include.</li> <li><code>--exclude-feature-list</code> (str): Path to a file with feature names to exclude.</li> </ul>"},{"location":"reference/feature_customization/#substring-filters-parameters","title":"Substring Filters Parameters","text":"<ul> <li><code>--include-feature-substr</code> (str): Include features containing the substring.</li> <li><code>--exclude-feature-substr</code> (str): Exclude features containing the substring.</li> </ul>"},{"location":"reference/feature_customization/#regex-filters-parameters","title":"Regex Filters Parameters","text":"<ul> <li><code>--include-feature-regex</code> (str): Include features matching the regex.</li> <li><code>--exclude-feature-regex</code> (str): Exclude features matching the regex.</li> </ul>"},{"location":"reference/feature_customization/#type-filters-parameters","title":"Type Filters Parameters","text":"<p>Reference file columns (name vs. index)</p> <p>If the reference file has a header row, specify the feature-name and feature-type columns with <code>--feature-type-ref-colname-*</code>; otherwise, use the 0-based index flags <code>--feature-type-ref-colidx-*</code>.</p> <ul> <li><code>--include-feature-type-regex</code> (str): Include by feature type (e.g., <code>^protein_coding$</code>).</li> <li><code>--feature-type-ref</code> (str): Reference file with feature name and type columns.</li> <li><code>--feature-type-ref-delim</code> (str): Delimiter for the reference file (default: <code>\\t</code>).</li> <li><code>--feature-type-ref-colname-name</code> (str): Column name for feature name.</li> <li><code>--feature-type-ref-colname-type</code> (str): Column name for feature type.</li> <li><code>--feature-type-ref-colidx-name</code> (int): 0-based column index for feature name.</li> <li><code>--feature-type-ref-colidx-type</code> (int): 0-based column index for feature type.</li> </ul>"},{"location":"reference/feature_customization/#outputs","title":"Outputs","text":"<p>A CSV/TSV file contains the remaining features. </p> <p>If <code>--out-record</code> is set, a TSV mapping each feature to a <code>filtering</code> reason; empty when a feature is kept.</p>"},{"location":"reference/import_cell/","title":"Cell Analysis Import","text":""},{"location":"reference/import_cell/#overview","title":"Overview","text":"<p>Import platform\u2011specific cell analysis outputs (cells, boundaries, clusters/DE), convert them to web\u2011ready layers (PMTiles/GeoJSON), and optionally register them in a <code>CartLoader</code> catalog. Supported platforms include 10x Xenium and 10x Visium HD.</p>"},{"location":"reference/import_cell/#requirements","title":"Requirements","text":"<ul> <li>Cell analysis outputs from the platform (see per\u2011platform sections).</li> <li>For PMTiles conversion: <code>tippecanoe</code> installed and on PATH.</li> <li>Optional catalog update: an existing <code>catalog.yaml</code> from Asset Packaging.</li> </ul>"},{"location":"reference/import_cell/#example-usages","title":"Example Usages","text":"<p>Two Input Modes</p> <p><code>CartLoader</code> accepts two input modes for each platform:</p> <ul> <li>JSON mode: pass <code>--in-json</code> with required keys.</li> <li>Manual mode: pass <code>--in-dir</code> with specific file locations.</li> </ul> Xenium ExampleVisium HD Example <pre><code># JSON input mode (requires keys: CELL, BOUNDARY, CLUSTER, DE)\ncartloader import_xenium_cell \\\n  --cells --boundaries --summary \\\n  --outprefix /path/to/out/xeniumranger \\\n  --in-json /path/to/xenium_cells.json \\\n  --tippecanoe /path/to/tippecanoe\n\n# Manual input mode\ncartloader import_xenium_cell \\\n  --cells --boundaries --summary \\\n  --outprefix /path/to/out/xeniumranger \\\n  --in-dir /path/to/xenium_ranger_output \\\n  --csv-cells analysis/cell_feature_matrix/cells.csv \\\n  --csv-boundaries analysis/cell_segmentation/cells_boundary.geojson \\\n  --csv-clust analysis/clustering/gene_expression_graphclust/clusters.csv \\\n  --csv-diffexp analysis/diffexp/gene_expression_graphclust/differential_expression.csv \\\n  --tippecanoe /path/to/tippecanoe\n</code></pre> <pre><code># JSON input mode (requires keys: CELL_FEATURE_MEX, CELL_GEOJSON, CLUSTER, DE)\ncartloader import_visiumhd_cell \\\n  --cells \\\n  --boundaries \\\n  --outprefix /path/to/out/spaceranger \\\n  --in-json /path/to/visiumhd_cells.json\n\n# Manual input mode\ncartloader import_visiumhd_cell \\\n  --cells \\\n  --boundaries \\\n  --outprefix /path/to/out/spaceranger \\\n  --in-dir /path/to/spaceranger_output \\\n  --mtx-cell filtered_feature_bc_matrix \\\n  --geojson-cells spatial/cells.geojson \\\n  --csv-clust analysis/clustering/gene_expression_graphclust/clusters.csv \\\n  --csv-diffexp analysis/diffexp/gene_expression_graphclust/differential_expression.csv\n</code></pre>"},{"location":"reference/import_cell/#actions","title":"Actions","text":"<p>Action Specifications</p> <p>No action runs by default. Activate at least one using the action parameters.</p>"},{"location":"reference/import_cell/#cell-conversion-step-cells","title":"Cell Conversion Step (<code>--cells</code>)","text":"<p>Convert cell points/centroids, clusters, and differential expression results to PMTiles with counts and top cluster index (topK). A JSON summary of inputs/outputs and basic stats will be written.</p>"},{"location":"reference/import_cell/#cell-boundary-conversion-step-boundaries","title":"Cell Boundary Conversion Step (<code>--boundaries</code>)","text":"<p>Convert cell polygons to GeoJSON with <code>cell_id</code> and <code>topK</code> attributes. A JSON summary of inputs/outputs and basic stats will be written.</p>"},{"location":"reference/import_cell/#catalog-update-update-catalog","title":"Catalog Update (<code>--update-catalog</code>)","text":"<p>Append generated layers to an existing <code>catalog.yaml</code>.</p>"},{"location":"reference/import_cell/#umap-conversion-step-umap","title":"UMAP Conversion Step (<code>--umap</code>)","text":"<p>Convert UMAP embeddings to PMTiles.</p>"},{"location":"reference/import_cell/#parameters","title":"Parameters","text":""},{"location":"reference/import_cell/#action-parameters","title":"Action Parameters","text":"<ul> <li><code>--cells</code> (flag): Import segmented cells and generate PMTiles.</li> <li><code>--boundaries</code> (flag): Import segmented cell boundaries and generate GeoJSON/PMTiles.</li> <li><code>--umap</code> (flag): Import UMAP projection and generate PMTiles.</li> <li><code>--update-catalog</code> (flag): Update an existing catalog.yaml.</li> <li><code>--all</code> (flag): Enable all actions (<code>--cells</code>, <code>--boundaries</code>, <code>--umap</code>).</li> </ul>"},{"location":"reference/import_cell/#inputoutput-parameters","title":"Input/Output Parameters","text":"<ul> <li><code>--outprefix</code> (str, required): Output prefix (e.g., <code>/path/to/out/sample</code>).</li> <li><code>--id</code> (str): Identifier for the cell factor (default: basename of <code>--outprefix</code>).</li> <li><code>--name</code> (str): Display name for the cell factor (default: basename of <code>--outprefix</code>).</li> <li><code>--tmp-dir</code> (str): Temporary directory for intermediate files.</li> </ul> Xenium InputVisium HD Input <p>JSON Mode: - <code>--in-json</code> (str): Path to JSON with keys <code>CELL</code>, <code>BOUNDARY</code>, <code>CLUSTER</code>, <code>DE</code>, <code>UMAP_PROJ</code>.</p> <p>Manual Mode (relative to <code>--in-dir</code>): - <code>--in-dir</code> (str): Base input directory. - <code>--csv-cells</code> (str): Cell table (CSV/Parquet) (default: <code>cells.csv.gz</code>). - <code>--csv-boundaries</code> (str): Cell boundaries (CSV) (default: <code>cell_boundaries.csv.gz</code>). - <code>--csv-clust</code> (str): Clustering results (CSV) (default: <code>analysis/clustering/gene_expression_graphclust/clusters.csv</code>). - <code>--csv-diffexp</code> (str): Differential expression (CSV) (default: <code>analysis/diffexp/gene_expression_graphclust/differential_expression.csv</code>). - <code>--csv-umap</code> (str): UMAP projection (CSV) (default: <code>analysis/pca/gene_expression_10_components/projection.csv</code>).</p> <p>JSON Mode: - <code>--in-json</code> (str): Path to JSON with keys <code>CELL_FEATURE_MEX</code>, <code>CELL_GEOJSON</code>, <code>CLUSTER</code>, <code>DE</code>, <code>UMAP_PROJ</code>.</p> <p>Manual Mode (relative to <code>--in-dir</code>): - <code>--in-dir</code> (str): Base input directory. - <code>--mtx-cells</code> (str): Cell-feature matrix directory (default: <code>segmented_outputs/filtered_feature_cell_matrix</code>). - <code>--geojson-cells</code> (str): Cell segmentations (GeoJSON) (default: <code>segmented_outputs/cell_segmentations.geojson</code>). - <code>--csv-clust</code> (str): Clustering results (CSV) (default: <code>analysis/clustering/gene_expression_graphclust/clusters.csv</code>). - <code>--csv-diffexp</code> (str): Differential expression (CSV) (default: <code>analysis/diffexp/gene_expression_graphclust/differential_expression.csv</code>). - <code>--csv-umap</code> (str): UMAP projection (CSV) (default: <code>analysis/pca/gene_expression_10_components/projection.csv</code>). - <code>--scale-json</code> (str): Scale factors JSON (default: <code>spatial/scalefactors_json.json</code>, or None). - <code>--units-per-um</code> (float): Coordinate units per \u00b5m (default: 1).</p> Auxiliary Parameters <p>PMTiles Conversion:   - <code>--min-zoom</code> (int, default: 10): Min zoom for cells/boundaries.   - <code>--max-zoom</code> (int, default: 18): Max zoom for cells/boundaries.   - <code>--umap-min-zoom</code> (int, default: 0): Min zoom for UMAP.   - <code>--umap-max-zoom</code> (int, default: 18): Max zoom for UMAP.   - <code>--max-tile-bytes</code> (int, default: 5000000): Max bytes per tile.   - <code>--max-feature-counts</code> (int, default: 500000): Max features per tile.   - <code>--preserve-point-density-thres</code> (int, default: 1024): Point density threshold.</p> <p>Coloring and DE:   - <code>--tsv-cmap</code> (str): Color table TSV (default: <code>assets/fixed_color_map_60.tsv</code>).   - <code>--de-max-pval</code> (float, default: 0.01): Max p-value.   - <code>--de-min-fc</code> (float, default: 1.2): Min fold change.</p> <p>Catalog:   - <code>--catalog-yaml</code> (str): Input catalog to update.   - <code>--out-catalog-yaml</code> (str): Output catalog path (if different from input).</p> <p>Column Names (Collapsible):   Xenium Only:   - <code>--cells-colname-cell-id</code> (str, default: <code>cell_id</code>)   - <code>--cells-colname-x</code> (str, default: <code>x_centroid</code>)   - <code>--cells-colname-y</code> (str, default: <code>y_centroid</code>)   - <code>--cells-colname-count</code> (str, default: <code>transcript_counts</code>)   - <code>--boundaries-colname-cell-id</code> (str, default: <code>cell_id</code>)   - <code>--boundaries-colname-x</code> (str, default: <code>vertex_x</code>)   - <code>--boundaries-colname-y</code> (str, default: <code>vertex_y</code>)</p> <p>Common/Both:   - <code>--clust-colname-barcode</code> (str, default: <code>Barcode</code>)   - <code>--clust-colname-cluster</code> (str, default: <code>Cluster</code>)   - <code>--umap-colname-barcode</code> (str, default: <code>Barcode</code>)   - <code>--umap-colname-x</code> (str, default: <code>UMAP-1</code>)   - <code>--umap-colname-y</code> (str, default: <code>UMAP-2</code>)</p> <p>Environment:   - <code>--tippecanoe</code> (str): Path to tippecanoe binary.   - <code>--parquet-tools</code> (str): Path to parquet-tools (Xenium only).   - <code>--R</code> (str): Path to R/Rscript binary.   - <code>--threads</code> (int): Number of threads.   - <code>--log</code> (flag): Enable logging.   - <code>--log-suffix</code> (str): Log file suffix.</p>"},{"location":"reference/import_cell/#outputs","title":"Outputs","text":"<ul> <li>Cells PMTiles (<code>*.cells.pmtiles</code>): cell centroids/points with attributes <code>cell_id</code>, <code>count</code>, <code>topK</code>.</li> <li>Boundaries GeoJSON (<code>*.boundaries.geojson</code>): cell polygons with <code>cell_id</code>, <code>topK</code>.</li> <li>Summary TSV/JSON (when <code>--summary</code>).</li> </ul>"},{"location":"reference/import_image/","title":"Background Image Import","text":""},{"location":"reference/import_image/#overview","title":"Overview","text":"<p><code>import_image</code> loads a histology or background image and produces a web\u2011ready PMTiles layer. It supports OME\u2011TIFF/TIFF/PNG inputs and offers optional orientation transforms.</p>"},{"location":"reference/import_image/#requirements","title":"Requirements","text":"<ul> <li>Input image: OME\u2011TIFF/TIFF/PNG.</li> <li>Georeference bounds (required if input image is neither georeferenced nor OME\u2011TIFF)</li> <li>Pre-installed CLI tools: <code>pmtiles</code>, <code>gdal_translate</code>, <code>gdaladdo</code>, <code>gdalinfo</code>.</li> </ul>"},{"location":"reference/import_image/#example-usage","title":"Example Usage","text":""},{"location":"reference/import_image/#1-ometiff-png-pmtiles-auto-georeference","title":"1) OME\u2011TIFF \u2192 PNG \u2192 PMTiles (auto georeference)","text":"<pre><code>IMAGE_ID=TEST_ID      # replace TEST_ID with your own ID (no whitespace)\n\ncartloader import_image \\\n  --ome2png --png2pmtiles --update-catalog \\\n  --in-img /path/to/input.ome.tif \\\n  --out-dir /path/to/out \\\n  --img-id  ${IMAGE_ID} \\\n  --pmtiles /path/to/pmtiles \\\n  --gdal_translate /path/to/gdal_translate \\\n  --gdaladdo /path/to/gdaladdo\n</code></pre>"},{"location":"reference/import_image/#2-png-pmtiles-manual-georeference-via-bounds","title":"2) PNG \u2192 PMTiles (manual georeference via bounds)","text":"<p>Pick one bounds input method and enable <code>--georeference</code>.</p> <pre><code>IMAGE_ID=TEST_ID      # replace TEST_ID with your own ID (no whitespace)\n\n# A) Bounds string\ncartloader import_image \\\n  --png2pmtiles --georeference \\\n  --in-img /path/to/image.png \\\n  --georef-bounds \"ulx,uly,lrx,lry\" \\\n  --out-dir /path/to/out \\\n  --img-id ${IMAGE_ID}\n\n# B) Bounds TSV\ncartloader import_image \\\n  --png2pmtiles --georeference \\\n  --in-img /path/to/image.png \\\n  --georef-bounds-tsv /path/to/bounds.tsv \\\n  --out-dir /path/to/out \\\n  --img-id ${IMAGE_ID}\n\n# C) Pixel TSV from run_ficture2 (e.g., *.pixel.sorted.tsv.gz)\ncartloader import_image \\\n  --png2pmtiles --georeference \\\n  --in-img /path/to/image.png \\\n  --georef-pixel-tsv /path/to/decode.pixel.sorted.tsv.gz \\\n  --out-dir /path/to/out \\\n  --img-id ${IMAGE_ID}\n</code></pre> <p>If your input image requires to orientate, you can apply <code>--rotate</code>, <code>--flip-horizontal</code> <code>--flip-vertical</code>. For example:</p> <pre><code>cartloader import_image \\\n  --png2pmtiles --georeference \\\n  --rotate 90 --flip-horizontal \\\n  --in-img /path/to/image.png \\\n  --georef-bounds \"ulx,uly,lrx,lry\" \\\n  --out-dir /path/to/out \\\n  --img-id ${IMAGE_ID}\n</code></pre>"},{"location":"reference/import_image/#actions","title":"Actions","text":"<p>Action Specifications</p> <p>No action runs by default. Activate at least one using the action parameters.</p>"},{"location":"reference/import_image/#georeference-step-georeference","title":"Georeference Step (<code>--georeference</code>)","text":"<p>If input is OME-TIFF, extracts a PNG and bounds from the OME\u2011TIFF and georeferencing is applied automatically.</p> <p>If <code>--georeference</code> is applied with <code>--georef-*</code>, georeferencing is applied with bounds provided via one of <code>--georef-*</code>.</p>"},{"location":"reference/import_image/#orientation-step-rotate-flip-vertical-flip-horizontal","title":"Orientation Step (<code>--rotate</code>, <code>--flip-vertical</code>, <code>--flip-horizontal</code>)","text":"<p>If any of <code>--rotate</code>, <code>--flip-vertical</code>, <code>--flip-horizontal</code> is set, rotation and flips can be applied accordingly prior to tiling. It supports rotate the image clockwise by 90/180/270 degrees. Rotation is applied before flips.</p>"},{"location":"reference/import_image/#ometiff-to-png-step-ome2png","title":"OME\u2011TIFF to PNG Step (<code>--ome2png</code>)","text":"<p>Converts an OME\u2011TIFF to PNG, reads bounds from OME metadata, and records color mode when applicable.</p>"},{"location":"reference/import_image/#png-to-pmtiles-step-png2pmtiles","title":"PNG to PMTiles Step (<code>--png2pmtiles</code>)","text":"<p>Converts the PNG to GeoTIFF and then to PMTiles. An asset JSON is written during conversion.</p>"},{"location":"reference/import_image/#catalog-update-step-update-catalog","title":"Catalog Update Step (<code>--update-catalog</code>)","text":"<p>Appends the generated <code>&lt;img-id&gt;.pmtiles</code> to <code>catalog.yaml</code> as a basemap layer. This only applies if <code>catalog.yaml</code> exists.</p>"},{"location":"reference/import_image/#parameters","title":"Parameters","text":"<p>Below are the core arguments you\u2019ll typically set. For all other options, expand the collapsible \"Auxiliary Parameters\" section.</p>"},{"location":"reference/import_image/#action-parameters","title":"Action Parameters","text":"<ul> <li><code>--ome2png</code> (flag): Extract PNG (and bounds) from OME\u2011TIFF (auto\u2011georeference), and/or</li> <li><code>--png2pmtiles</code> (flag): Convert PNG to PMTiles (via GeoTIFF/MBTiles).</li> <li><code>--georeference</code> (flag): For manual georeference (non\u2011OME inputs) (used with one of <code>--georef-*</code>).</li> <li><code>--rotate</code> (int) [90|180|270]: Rotate clockwise (applied before flips).</li> <li><code>--flip-vertical</code> (flag): Flip vertically (around X axis; after rotation).</li> <li><code>--flip-horizontal</code> (flag): Flip horizontally (around Y axis; after rotation).</li> <li><code>--update-catalog</code> (flag): Update or create <code>catalog.yaml</code> with the generated PMTiles as a basemap.</li> </ul>"},{"location":"reference/import_image/#inputoutput-parameters","title":"Input/Output Parameters","text":"<ul> <li><code>--out-dir</code> (str): Output directory for generated files.</li> <li><code>--img-id</code> (str): Image ID used as filename prefix and basemap ID (when updating catalog). No whitespace.</li> <li>Input source (choose one):<ul> <li><code>--in-img</code> (str): Path to input image (PNG or OME\u2011TIFF/TIFF).</li> <li><code>--in-json</code> (str): JSON/YAML mapping from image IDs to file paths.</li> </ul> </li> </ul> Auxiliary Parameters <p>Auxiliary for --ome2png</p> <ul> <li><code>--micron2pixel-csv</code> (str): Vizgen transform CSV (micron_to_mosaic_pixel_transform.csv).</li> <li><code>--page</code> (int): Z\u2011slice index to extract from multi\u2011page OME\u2011TIFF (3D).</li> <li><code>--level</code> (int): Resolution level index to extract from OME\u2011TIFF.</li> <li><code>--series</code> (int): Series index to extract from OME\u2011TIFF.</li> <li><code>--upper-thres-quantile</code> / <code>--upper-thres-intensity</code>: Rescale cap (mutually exclusive).</li> <li><code>--lower-thres-quantile</code> / <code>--lower-thres-intensity</code>: Rescale floor (mutually exclusive).</li> <li><code>--transparent-below</code> (int): Make pixels below threshold transparent (0\u2013255).</li> <li><code>--colorize</code> (str): Colorize mono images using an RGB hex or name.</li> <li><code>--high-memory</code> (flag): Use a memory\u2011intensive path for large OME\u2011TIFFs.</li> </ul> <p>Auxiliary for --png2pmtiles</p> <ul> <li><code>--srs</code> (str, default: <code>EPSG:3857</code>): Spatial reference.</li> <li><code>--mono</code> (flag): Input PNG is single\u2011band mono (skip if <code>--ome2png</code>).</li> <li><code>--rgba</code> (flag): Input PNG is 4\u2011band RGBA (skip if <code>--ome2png</code>).</li> <li><code>--resample</code> (str, default: <code>cubic</code>): GDAL resampling.</li> <li><code>--blocksize</code> (int, default: <code>512</code>): GDAL block size in pixels.</li> </ul> <p>Auxiliary for --georeference   Pick one bounds source:   - <code>--georef-detect</code> (flag): Used the detect bounds from image metadata (e.g., 'OME'). Extracted bounds will automatically be applied to png2pmtiles.   - <code>--georef-pixel-tsv</code> (str): Pixel TSV (e.g., <code>*.pixel.sorted.tsv.gz</code> from run_ficture2).   - <code>--georef-bounds-tsv</code> (str): One\u2011line TSV with <code>ulx,uly,lrx,lry</code>.   - <code>--georef-bounds</code> (str): Bounds string <code>\"ulx,uly,lrx,lry\"</code>.</p> <p>Environment Parameters</p> <ul> <li><code>--pmtiles</code> (str, default: <code>pmtiles</code>): Path to go\u2011pmtiles binary.</li> <li><code>--gdal_translate</code> (str, default: <code>gdal_translate</code>)</li> <li><code>--gdaladdo</code> (str, default: <code>gdaladdo</code>)</li> <li><code>--gdalinfo</code> (str, default: <code>gdalinfo</code>)</li> </ul> <p>Run Parameters</p> <ul> <li><code>--dry-run</code> (flag): Generate the Makefile; do not execute.</li> <li><code>--restart</code> (flag): Ignore existing outputs and rerun steps.</li> <li><code>--n-jobs</code> (int): Number of parallel jobs (default: 1).</li> <li><code>--makefn</code> (str): Makefile name to write (default: <code>&lt;out-dir&gt;/&lt;img-id&gt;.mk</code>).</li> </ul>"},{"location":"reference/import_image/#output","title":"Output","text":"<p>Outputs are written under <code>--out-dir</code> with prefix <code>&lt;img-id&gt;</code>:</p> <ul> <li><code>&lt;img-id&gt;.pmtiles</code>: Final PMTiles for web visualization.</li> <li><code>&lt;img-id&gt;.json</code>: Asset JSON produced during PNG\u2192PMTiles conversion.</li> <li><code>&lt;img-id&gt;.geotif.tif</code> and intermediate tiles (when relevant).</li> </ul>"},{"location":"reference/import_square/","title":"Square Analysis Import","text":""},{"location":"reference/import_square/#overview","title":"Overview","text":"<p><code>import_visiumhd_square</code> packages Space Ranger square-bin analysis outputs (clusters, DE, and optional UMAP coordinates) into PMTiles and a square assets JSON for CartLoader. Use it directly, or via <code>run_visiumhd --import-squares</code> to fold square-bin layers into your catalog.</p>"},{"location":"reference/import_square/#action","title":"Action","text":"<p>Convert one bin size of Visium HD square results into PMTiles, write <code>&lt;square-id&gt;-sqXXX_assets.json</code>, and optionally update an existing <code>catalog.yaml</code>.</p>"},{"location":"reference/import_square/#requirements","title":"Requirements","text":"<ul> <li>Space Ranger square-bin outputs for a given bin size (8 \u00b5m or 16 \u00b5m are common):</li> <li>Positions Parquet (<code>spatial/tissue_positions.parquet</code>)</li> <li>Cluster CSV (<code>analysis/clustering/.../clusters.csv</code>)</li> <li>Differential expression CSV (<code>analysis/diffexp/.../differential_expression.csv</code>)</li> <li>(Optional) UMAP CSV (<code>analysis/pca/gene_expression_10_components/projection.csv</code>)</li> <li>Scale factors JSON (<code>spatial/scalefactors_json.json</code>) to derive units-per-\u00b5m, or provide <code>--units-per-um</code>.</li> <li>Tippecanoe and parquet-tools (or pigz/polars) available on PATH.</li> </ul>"},{"location":"reference/import_square/#example-usage","title":"Example Usage","text":"JSON mode (preferred; auto paths)Manual mode (explicit files) <pre><code>cartloader import_visiumhd_square \\\n  --in-json /path/to/space_ranger_assets.json \\\n  --bin-size 8 \\\n  --outprefix /path/to/cartload2/squares/spaceranger-sq008 \\\n  --threads 8\n</code></pre> <pre><code>cartloader import_visiumhd_square \\\n  --in-dir /path/to/space_ranger_output \\\n  --bin-size 8 \\\n  --parquet spatial/tissue_positions.parquet \\\n  --csv-clust analysis/clustering/gene_expression_graphclust/clusters.csv \\\n  --csv-diffexp analysis/diffexp/gene_expression_graphclust/differential_expression.csv \\\n  --csv-umap analysis/pca/gene_expression_10_components/projection.csv \\\n  --outprefix /path/to/cartload2/squares/spaceranger-sq008 \\\n  --threads 8\n</code></pre>"},{"location":"reference/import_square/#parameters","title":"Parameters","text":""},{"location":"reference/import_square/#inputoutput","title":"Input/Output","text":"<ul> <li><code>--in-json</code> (str): Space Ranger assets JSON (from <code>load_space_ranger</code> or <code>run_visiumhd --load-space-ranger</code>); mutually exclusive with manual mode.</li> <li><code>--outprefix</code> (str, required): Output prefix for generated artifacts.</li> <li><code>--id</code>, <code>--name</code> (str): Override asset ID/display name (default: basename of <code>--outprefix</code>).</li> </ul>"},{"location":"reference/import_square/#manual-inputs-relative-to-in-dir-override-as-needed","title":"Manual Inputs (relative to <code>--in-dir</code>; override as needed)","text":"<ul> <li><code>--in-dir</code> (str): Space Ranger output directory for manual mode.</li> <li><code>--bin-size</code> (int, required): Bin size in \u00b5m (e.g., 8 or 16).</li> <li><code>--parquet</code> (str): Positions Parquet (default: <code>spatial/tissue_positions.parquet</code>).</li> <li><code>--csv-clust</code> (str): Cluster assignments (default: <code>analysis/clustering/gene_expression_graphclust/clusters.csv</code>).</li> <li><code>--csv-diffexp</code> (str): Differential expression (default: <code>analysis/diffexp/gene_expression_graphclust/differential_expression.csv</code>).</li> <li><code>--csv-umap</code> (str): UMAP projection CSV (default: <code>analysis/pca/gene_expression_10_components/projection.csv</code>; optional).</li> <li><code>--scale-json</code> (str): Scale factors JSON (default: <code>spatial/scalefactors_json.json</code>).</li> <li><code>--units-per-um</code> (float): Override microns-per-unit if scale JSON is missing.</li> </ul>"},{"location":"reference/import_square/#column-overrides","title":"Column Overrides","text":"<ul> <li><code>--pos-colname-*</code>, <code>--clust-colname-*</code>, <code>--umap-colname-*</code>: Adjust barcode/coordinate column names if they differ from defaults.</li> </ul> Auxiliary Parameters <p>Recommend to use the default values; override only if needed.</p> <p>PMTiles Conversion: * <code>--min-zoom</code> (int): Minimum zoom level (default: 0). * <code>--max-zoom</code> (int): Maximum zoom level (default: 18). * <code>--max-tile-bytes</code> (int): Max bytes per tile. * <code>--preserve-point-density-thres</code> (int): Density preservation threshold. * <code>--max-feature-counts</code> (int): Max features per tile.</p> <p>Auxiliary UMAP Parameters: * <code>--umap-colname-factor</code> (str): Column name for the clustering factor (default: <code>Cluster</code>). * <code>--umap-colname-x</code> (str): Column name for UMAP X (default: <code>UMAP1</code>). * <code>--umap-colname-y</code> (str): Column name for UMAP Y (default: <code>UMAP2</code>). * <code>--umap-min-zoom</code> (int): Min UMAP zoom (default: 0). * <code>--umap-max-zoom</code> (int): Max UMAP zoom (default: 18).</p> <p>Auxiliary Colname Parameters: * <code>--pos-colname-barcode</code> (str): Column name for barcode in -- (default: <code>Barcode</code>). * <code>--pos-colname-x</code> (str): Column name for X position. * <code>--pos-colname-y</code> (str): Column name for Y position. * <code>--cluster-colname-barcode</code> (str): Column name for the barcode (default: <code>Barcode</code>). * <code>--cluster-colname-cluster</code> (str): Column name for cluster ID (default: <code>Cluster</code>).</p> <p>Auxiliary Catalog Parameters: * <code>--update-catalog</code> (flag): Append square assets to an existing <code>catalog.yaml</code> (default path <code>&lt;in-dir&gt;/catalog.yaml</code> or <code>--catalog-yaml</code>). * <code>--catalog-yaml</code> (str): Catalog path to update when <code>--update-catalog</code> is set.</p> <p>Auxiliary Run Parameters: * <code>--threads</code> (int): Threads for tippecanoe. - <code>--tsv-cmap</code> (str): Cluster color map TSV (default: <code>assets/fixed_color_map_60.tsv</code>). - <code>--log</code>, <code>--log-suffix</code>: Write a log next to outputs.</p> <p>Auxiliary Environment Parameters: - <code>--use-parquet-tools</code> (flag): Use <code>parquet-tools csv</code> instead of polars/pigz conversion. * <code>--parquet-tools</code> (str): Path to <code>parquet-tools</code> binary (default: <code>parquet-tools</code>). * <code>--tippecanoe</code> (str): Path to <code>tippecanoe</code> binary (default: <code>tippecanoe</code>). * <code>--pigz</code> (str): Path to <code>pigz</code> binary (default: <code>pigz</code>). * <code>--pigz-threads</code> (int): Threads for pigz (default: 4). * <code>--gzip</code> (str): Path to <code>gzip</code> (default: <code>gzip</code>).</p>"},{"location":"reference/import_square/#outputs","title":"Outputs","text":"<p>Written next to <code>--outprefix</code>:</p> <ul> <li><code>&lt;outprefix&gt;.pmtiles</code>: Square-bin clusters as tiles (one layer per bin size).</li> <li><code>&lt;outprefix&gt;-bulk-de.tsv</code>: Differential expression per cluster.</li> <li><code>&lt;outprefix&gt;-rgb.tsv</code>: Cluster colormap TSV.</li> <li><code>&lt;outprefix&gt;-umap.tsv.gz</code> / <code>&lt;outprefix&gt;-umap.pmtiles</code> / <code>&lt;outprefix&gt;.umap.png</code> / <code>&lt;outprefix&gt;.umap.single.binary.png</code>: UMAP coordinates and visualizations (if <code>--csv-umap</code> provided).</li> <li><code>&lt;outprefix&gt;_assets.json</code>: Square assets manifest referenced by <code>catalog.yaml</code>.</li> </ul> <p>If <code>--update-catalog</code> is set, the manifest is appended to the existing catalog under the provided <code>catalog.yaml</code>.</p>"},{"location":"reference/intro/","title":"Reference Overview","text":"<p>This section documents the <code>CartLoader</code> CLI by task.</p>"},{"location":"reference/intro/#sge-preparation","title":"SGE Preparation","text":"<ul> <li><ul> <li> SGE Format Conversion <p><code>sge_convert</code>: Standardize raw platform outputs into the unified format; optional visualization; optional density-based filtering</p> </li> </ul> Read</li> <li><ul> <li> SGE Preparation Add-ons <p><code>sge_stitch</code>: Stitch &gt;=2 SGEs into one.</p> <p><code>sge_orientate</code>: Reorient SGE by rotation and flips.</p> </li> </ul> Read</li> </ul>"},{"location":"reference/intro/#ficture-analysis","title":"FICTURE Analysis","text":"<ul> <li><ul> <li> Single-sample Analysis <p><code>run_ficture2</code>: Train spatial factors and decode pixels; writes a manifest for packaging</p> </li> </ul> Read</li> <li><ul> <li> Multi-sample Analysis <p><code>run_ficture2_multi</code>: Train spatial factors across &gt;=2 samples and perform per\u2011sample pixel\u2011level decoding, writing individual manifests.</p> </li> </ul> Read</li> <li><ul> <li> Feature Customization <p><code>feature_filtering</code>: Customize the feature set by list, substring, regex, or type for downstream analysis, e.g., FICTURE</p> </li> </ul> Read</li> </ul>"},{"location":"reference/intro/#asset-packaging","title":"Asset Packaging","text":"<ul> <li><ul> <li> Asset Packaging <p><code>run_cartload2</code>: Package SGE and (optionally) FICTURE outputs into PMTiles and write a catalog of layers.</p> </li> </ul> Read</li> <li><ul> <li> Multi-sample Packaging <p><code>run_cartload2_multi</code>: For each sample, package SGE and (optionally) FICTURE outputs into PMTiles and write a catalog of layers.</p> </li> </ul> Read</li> <li><ul> <li> Import Images <p><code>import_image</code>: Convert an image into a georeferenced PMTiles layer (optionally reorient) and register it in the catalog.</p> </li> </ul> Read</li> <li><ul> <li> Import Cell Analysis <p><code>import_xenium_cell</code>, <code>import_visiumhd_cell</code>: Import platform\u2011specific cell analysis outputs and add them to the catalog.</p> </li> </ul> Read</li> </ul>"},{"location":"reference/intro/#data-repository-upload","title":"Data Repository Upload","text":"<ul> <li><ul> <li> AWS Upload <p><code>upload_aws</code>: Upload outputs to an S3 bucket for sharing or web visualization.</p> </li> </ul> Read</li> <li><ul> <li> Zenodo Upload <p><code>upload_zenodo</code>: Upload outputs to a Zenodo deposition, creating a new draft or updating an existing record.</p> </li> </ul> Read</li> </ul>"},{"location":"reference/intro/#platform-specific-modules","title":"Platform-Specific Modules","text":"<ul> <li><ul> <li> Xenium Pipeline <p><code>run_xenium</code>: Xenium Pipeline Orchestrator to run multiple modules together</p> </li> </ul> Read</li> <li><ul> <li> Xenium Pipeline Add-ons <p><code>load_xenium_ranger</code>: Scans Xenium Ranger output and writes a JSON manifest of detected assets.</p> </li> </ul> Read</li> <li><ul> <li> Visium HD Pipeline <p><code>run_visiumhd</code>: Visium HD Pipeline Orchestrator to run multiple modules together</p> </li> </ul> Read</li> <li><ul> <li> Visium HD Pipeline Add-ons <p><code>load_space_ranger</code>: Scans Space Ranger output and writes a JSON manifest of detected assets.</p> </li> </ul> Read</li> </ul>"},{"location":"reference/run_cartload2/","title":"Spatial Asset Packaging","text":""},{"location":"reference/run_cartload2/#overview","title":"Overview","text":"<p>Following spatial factor inference via FICTURE analysis, <code>CartLoader</code> provides the <code>run_cartload2</code> module to package SGE data and spatial factor output from FICTURE analysis into standardized, spatially indexed, and storage\u2011efficient PMTiles, a web\u2011native tiling format. These PMTiles outputs are optimized for downstream analysis, interactive web visualization (e.g., in CartoScope), and data sharing across platforms.</p>"},{"location":"reference/run_cartload2/#requirements","title":"Requirements","text":"<ul> <li>An SGE in the unified format (from SGE format conversion) with a metadata file describing paths to SGE assets (<code>sge_assets.json</code>)</li> <li>(Optional) A completed FICTURE run from <code>run_ficture2</code>, including pixel-level decoding outputs and a metadata file describing the input-output structure (<code>ficture.params.json</code>)</li> <li>(Optional) One or more deployed images with corresponding metadata file(s)</li> <li>(Optional) A set of deployed cell-based analysis results and its metadata file</li> <li>Pre-installed CLI tools: <code>tippecanoe</code>, <code>gdal_translate</code>, <code>gdaladdo</code>, <code>pmtiles</code>, <code>spatula</code>, <code>gzip</code>.</li> </ul>"},{"location":"reference/run_cartload2/#example-usage","title":"Example Usage","text":"<pre><code>DATA_ID=\"dataset_id\"               ## replace dataset_id with the id for your dataset\n\ncartloader run_cartload2 \\\n    --makefn run_cartload2.mk \\\n    --fic-dir /path/to/run_ficture2/results \\\n    --out-dir /path/to/output/directory \\\n    --id ${DATA_ID} \\\n    --colname-count count \\\n    --n-jobs 20  \\\n    --threads 20 \\\n    --spatula /path/to/spatula/binary \\\n    --pmtiles /path/to/pmtiles/binary \\\n    --tippecanoe /path/to/tippecanoe/binary\n</code></pre>"},{"location":"reference/run_cartload2/#actions","title":"Actions","text":"<p>Action Specifications</p> <p>SGE packaging and catalog preparation run by default. Enable optional integration actions using input/output parameters.</p>"},{"location":"reference/run_cartload2/#sge-packaging","title":"SGE Packaging","text":"<p>Converts transcript\u2011level SGE to raster PMTiles, including light and dark modes.</p>"},{"location":"reference/run_cartload2/#ficture-integration-fic-dir","title":"FICTURE Integration (<code>--fic-dir</code>)","text":"<p>If FICTURE results is provided via <code>--fic-dir</code>:   - Converts topic proportions (<code>*.results.tsv.gz</code>) into vector PMTiles for spatial factors.   - Generates raster overlays from decoded pixel\u2011level outputs.   - Builds a joined molecule\u2013factor matrix by associating decoded pixels with molecules based on spatial proximity, then converts it into multi\u2011feature PMTiles.</p>"},{"location":"reference/run_cartload2/#additional-assets-integration-cell-assets-or-background-assets","title":"Additional Assets Integration (<code>--cell-assets</code> or <code>--background-assets</code>)","text":"<p>Includes provided cell assets and background/basemap PMTiles in <code>catalog.yaml</code>; copies asset files into the output directory when they reside elsewhere.</p>"},{"location":"reference/run_cartload2/#catalog-and-metadata-preparation","title":"Catalog and Metadata Preparation","text":"<p>Writes a FICTURE assets JSON (when FICTURE integration is set) and a final <code>catalog.yaml</code> listing all layers.</p>"},{"location":"reference/run_cartload2/#parameters","title":"Parameters","text":"<p>Below are the core parameters. See more details in the collapsible \"Auxiliary Paramaters\" section.</p>"},{"location":"reference/run_cartload2/#inputoutput-parameters","title":"Input/Output Parameters","text":"<p>Must use <code>--sge-dir</code> or <code>--fic-dir</code> to provide SGE data.</p> <ul> <li><code>--sge-dir</code> (str): Path to the input Directory from <code>sge_convert</code>; must include an SGE assets JSON (<code>--in-sge-assets</code>). </li> <li><code>--fic-dir</code> (str): Path to the input Directory from <code>run_ficture2</code>; must include <code>--in-fic-params</code> JSON/YAML.</li> <li><code>--cell-assets</code> (list of str): Optional cell asset JSON/YAML files (e.g., from <code>import_*_cell</code>) to include.</li> <li><code>--background-assets</code> (list of str): Optional basemap assets (e.g., from cell <code>import_image</code>); JSON/YAML or inline specs <code>id:path</code> or <code>id1:id2:path</code>.</li> <li><code>--square-assets</code> (list of str): Optional square asset JSON/YAML files (e.g., from <code>import_visiumhd_square</code>) to include.</li> <li><code>--out-dir</code> (str): Path to the output directory for PMTiles, assets JSON, and catalog YAML.</li> </ul>"},{"location":"reference/run_cartload2/#dataset-id-and-descriptions","title":"Dataset ID and Descriptions","text":"<ul> <li><code>--id</code> (str): Unique dataset identifier (avoid whitespace; use <code>-</code>).</li> <li><code>--title</code> (str): Optional title for the output assets.</li> <li><code>--desc</code> (str): Optional short description for the output assets.</li> </ul> Auxiliary Parameters <p>Recommend to use the default values; override only if needed.</p> <p>Auxiliary Conversion Parameters:</p> <ul> <li><code>--in-sge-assets</code> (str): File name of SGE assets JSON/YAML under <code>--sge-dir</code> specifying paths to transcript, feature, and minmax files (default: <code>sge_assets.json</code>).</li> <li><code>--in-fic-params</code> (str): File name of input JSON/YAML with SGE paths and FICTURE parameters under <code>--fic-dir</code>(default: <code>ficture.params.json</code>).</li> <li><code>--out-fic-assets</code> (str): File name of output JSON/YAML file to write FICTURE assets (default: <code>ficture_assets.json</code>).</li> <li><code>--out-catalog</code> (str): File name of output YAML file for assets (default: <code>catalog.yaml</code>).</li> <li><code>--rename-x</code> (str): Column renaming rule for X axis in <code>tippecanoe</code> (Default: x:lon).</li> <li><code>--rename-y</code> (str): Column renaming rule for Y axis in <code>tippecanoe</code> (Default: y:lat).</li> <li><code>--colname-feature</code> (str): Column name for gene/feature name (default: <code>gene</code>).</li> <li><code>--colname-count</code> (str): Column name for feature count (default: <code>count</code>).</li> <li><code>--out-molecules-id</code> (str): Base name for output molecule PMTiles files (default: <code>genes</code>).</li> <li><code>--max-join-dist-um</code> (float): Maximum join distance (\u00b5m) between molecules and pixels (default: <code>0.1</code>).</li> <li><code>--bin-count</code> (int): Number of bins when splitting input molecules (default: <code>50</code>).</li> <li><code>--join-tile-size</code> (float): Tile size (\u00b5m) for molecule\u2013pixel joining (default: <code>500</code>).</li> <li><code>--max-tile-bytes</code> (int): Maximum allowed tile size in bytes for PMTiles (default: <code>5_000_000</code>).</li> <li><code>--max-feature-counts</code> (int): Maximum number of features per tile (default: <code>500_000</code>).</li> <li><code>--preserve-point-density-thres</code> (int): Threshold to preserve point density in PMTiles (default: <code>1024</code>).</li> <li><code>--transparent-below</code> / <code>--transparent-above</code> (int): Make pixels below/above the threshold transparent for dark/light backgrounds.</li> <li><code>--sge-scale</code> (float): Scales input coordinates to pixels in the output image (default: 1).</li> <li><code>--umap-colname-factor</code> (str): Column name encoding the dominant factor assignment in a UMAP TSV (default: <code>topK</code>).</li> <li><code>--umap-colname-x</code> (str): Column name for the UMAP X coordinate (default: <code>UMAP1</code>).</li> <li><code>--umap-colname-y</code> (str): Column name for the UMAP Y coordinate (default: <code>UMAP2</code>).</li> <li><code>--umap-min-zoom</code> (int): Minimum zoom for generated UMAP PMTiles (default: <code>0</code>).</li> <li><code>--umap-max-zoom</code> (int): Maximum zoom for generated UMAP PMTiles (default: <code>18</code>).</li> <li><code>--keep-intermediate-files</code> (flag): Retain intermediate files generated.</li> <li><code>--skip-raster</code> (flag): Skip raster tile generation and related dependencies.</li> <li><code>--tmp-dir</code> (str): Path to a temporary directory (default: <code>&lt;out-dir&gt;/tmp</code>).</li> </ul> <p>Environment Parameters:</p> <ul> <li><code>--gzip</code> (str): Path to the <code>gzip</code> binary. For faster compression, use <code>pigz -p4</code> (default: <code>gzip</code>).</li> <li><code>--pmtiles</code> (str): Path to the <code>pmtiles</code> binary from go-pmtiles (default: <code>pmtiles</code>).</li> <li><code>--gdal_translate</code> (str): Path to the <code>gdal_translate</code> binary (default: <code>gdal_translate</code>).</li> <li><code>--gdaladdo</code> (str): Path to the <code>gdaladdo</code> binary (default: <code>gdaladdo</code>).</li> <li><code>--tippecanoe</code> (str): Path to the <code>tippecanoe</code> binary (default: <code>tippecanoe</code>).</li> <li><code>--spatula</code> (str): Path to the <code>spatula</code> binary (default: <code>spatula</code>).</li> </ul> <p>Run Parameters:</p> <ul> <li><code>--dry-run</code> (flag): Generate the Makefile; do not execute.</li> <li><code>--restart</code> (flag): Ignore existing outputs and rerun all steps.</li> <li><code>--makefn</code> (str): Makefile name to write (default: <code>run_cartload2.mk</code>).</li> <li><code>--n-jobs</code> (int): Number of parallel jobs (default: 1).</li> <li><code>--threads</code> (int): Max threads per job (tippecanoe, etc.) (default: 4).</li> <li><code>--log</code> (flag): Write logs to a file under the output directory.</li> <li><code>--log-suffix</code> (str): Log filename suffix (default: <code>.log</code>).</li> </ul>"},{"location":"reference/run_cartload2/#output","title":"Output","text":""},{"location":"reference/run_cartload2/#copied-ficture-output","title":"Copied FICTURE Output","text":"<p>Copied FICTURE output from <code>&lt;fic_dir&gt;</code>. See formats in FICTURE analysis.</p>"},{"location":"reference/run_cartload2/#rasterized-transcript-level-sge","title":"Rasterized Transcript-level SGE","text":"<ul> <li>SGE mono PMTiles (<code>sge-mono-dark.pmtiles</code> and <code>sge-mono-light.pmtiles</code>): Rasterized gene expression tiles created from raw SGE for web visualization.</li> </ul>"},{"location":"reference/run_cartload2/#rasterized-spatial-factor-maps","title":"Rasterized Spatial Factor Maps","text":"<ul> <li>Factor probability PMTiles (<code>*-results.pmtiles</code>): Vector tiles encoding posterior topic probabilities per spatial location.</li> <li>Decoded factor PMTiles (<code>*-pixel-raster.pmtiles</code>): Rasterized spatial factor maps derived from pixel-level decoding results.</li> </ul>"},{"location":"reference/run_cartload2/#joined-molecule-factor-pmtiles","title":"Joined Molecule-factor PMTiles","text":"<ul> <li>Joined molecule-factor TSV (<code>transcripts_pixel_joined.tsv.gz</code>): Merged file linking transcript-level SGE with decoded pixel factors.</li> <li>Final molecule PMTiles (<code>genes_bin*.pmtiles</code>, <code>genes_index.tsv</code>, <code>genes_pmtiles_index.tsv</code>, <code>genes_bin_counts.json</code>): Indexed, multi-feature PMTiles built from joined pixel-factor data for CartoScope.</li> </ul>"},{"location":"reference/run_cartload2/#summary-files","title":"Summary Files","text":"<ul> <li>FICTURE assets file (<code>ficture_assets.json</code>): JSON catalog listing all output files and their roles for each trained model.</li> <li>Catalog file (<code>catalog.yaml</code>): Final YAML file summarizing all visual assets and layers for further deployment and visualization.</li> </ul>"},{"location":"reference/run_cartload2_multi/","title":"Multi\u2011Sample Spatial Asset Packaging","text":""},{"location":"reference/run_cartload2_multi/#overview","title":"Overview","text":"<p><code>run_cartload2_multi</code> batches CartLoad2 packaging across multiple samples. This module is specifically designed for packaging jointly FICTURE runs (<code>run_ficture2_multi</code>), which generates per\u2011sample FICTURE assets and want per\u2011sample PMTiles and catalogs.</p> <p>For each sample, it invokes <code>run_cartload2</code> to package SGE and optional FICTURE outputs into PMTiles and a catalog. It generates a Makefile to parallelize work and ensures all per\u2011sample catalogs are produced consistently.</p> <p>Scope and Limitations</p> <p>Convenience wrapper to package SGE and FICTURE outputs produced by <code>run_ficture2_multi</code>. It does not handle cell analysis results or background images (e.g., histology). To include all assets, run <code>run_cartload2</code> per sample or pair <code>run_ficture2_multi</code> with <code>import_image</code> and <code>import_*_cell</code>.</p>"},{"location":"reference/run_cartload2_multi/#requirements","title":"Requirements","text":"<ul> <li>TSV file containing the information for input samples (two to four columns: <code>id</code>, <code>transcript_path</code>, optional <code>title</code>, optional <code>desc</code>)  </li> <li>Per\u2011sample FICTURE outputs under <code>&lt;fic_dir&gt;/samples/&lt;sample_id&gt;/</code> with <code>ficture.params.json</code> (from <code>run_ficture2_multi</code>).</li> <li>Unified SGE and any deployed images/cells (as required by each sample\u2019s <code>run_cartload2</code>).</li> <li>CLI tools used by CartLoad2: <code>tippecanoe</code>, <code>gdal</code>, <code>pmtiles</code>, <code>gzip</code>/<code>pigz</code>, <code>spatula</code>.</li> </ul>"},{"location":"reference/run_cartload2_multi/#example-usage","title":"Example Usage","text":"<pre><code>cartloader run_cartload2_multi \\\n  --in-list /path/to/samples.tsv \\\n  --fic-dir /path/to/run_ficture2_multi/out \\\n  --out-dir /path/to/out/cartload2_multi \\\n  --spatula /path/to/spatula/binary \\\n  --pmtiles /path/to/pmtiles/binary \\\n  --tippecanoe /path/to/tippecanoe/binary \\\n  --n-jobs 10 \\\n  --threads 10\n</code></pre>"},{"location":"reference/run_cartload2_multi/#actions","title":"Actions","text":"<p>For each row in <code>--in-list</code>, apply:</p> <ul> <li>Locate per\u2011sample FICTURE assets at <code>--fic-dir/samples/&lt;id&gt;/ficture.params.json</code>.</li> <li>Run <code>cartloader run_cartload2</code> with <code>--fic-dir</code> set to the sample subfolder and <code>--id</code> normalized from <code>&lt;id&gt;</code> (lowercase, <code>_</code> \u2192 <code>-</code>), and save output to <code>&lt;out-dir&gt;/&lt;id&gt;/</code>.</li> <li>Write a per\u2011sample <code>catalog.yaml</code> (or <code>--out-catalog</code> name) and PMTiles under <code>&lt;out-dir&gt;/&lt;id&gt;/</code>.</li> <li>Emit a top\u2011level Makefile to run samples in parallel.</li> </ul>"},{"location":"reference/run_cartload2_multi/#parameters","title":"Parameters","text":"<p>Below lists the most common parameters. Additional flags are forwarded to per\u2011sample <code>run_cartload2</code>.</p>"},{"location":"reference/run_cartload2_multi/#inputoutput-parameters","title":"Input/Output Parameters","text":"<ul> <li><code>--in-list</code> (str, required): Two\u2011 to four\u2011column TSV: <code>&lt;sample_id&gt; &lt;transcript.tsv[.gz]&gt; [title] [desc]</code>.</li> <li><code>--fic-dir</code> (str, required): FICTURE output root containing <code>samples/&lt;id&gt;/ficture.params.json</code>.</li> <li><code>--out-dir</code> (str, required): Output root for per\u2011sample catalogs and PMTiles.</li> <li><code>--out-catalog</code> (str): Catalog filename per sample (default: <code>catalog.yaml</code>).</li> <li><code>--gdal_translate</code> (str): Path to <code>gdal_translate</code> (forwarded to <code>run_cartload2</code>).</li> </ul> Auxiliary Parameters <p>Recommend to use the default values; override only if needed.</p> <p>Auxiliary Conversion Parameters:</p> <ul> <li><code>--in-fic-params</code> (str): File name of input JSON/YAML with SGE paths and FICTURE parameters under <code>--fic-dir</code>(default: <code>ficture.params.json</code>).</li> <li><code>--out-fic-assets</code> (str): File name of output JSON/YAML file to write FICTURE assets (default: <code>ficture_assets.json</code>).</li> <li><code>--out-catalog</code> (str): File name of output YAML file for assets (default: <code>catalog.yaml</code>).</li> <li><code>--rename-x</code> (str): Column renaming rule for X axis in <code>tippecanoe</code> (Default: x:lon).</li> <li><code>--rename-y</code> (str): Column renaming rule for Y axis in <code>tippecanoe</code> (Default: y:lat).</li> <li><code>--colname-feature</code> (str): Column name for gene/feature name (default: <code>gene</code>).</li> <li><code>--colname-count</code> (str): Column name for feature count (default: <code>count</code>).</li> <li><code>--out-molecules-id</code> (str): Base name for output molecule PMTiles files (default: <code>genes</code>).</li> <li><code>--max-join-dist-um</code> (float): Maximum join distance (\u00b5m) between molecules and pixels (default: <code>0.1</code>).</li> <li><code>--bin-count</code> (int): Number of bins when splitting input molecules (default: <code>50</code>).</li> <li><code>--join-tile-size</code> (float): Tile size (\u00b5m) for molecule\u2013pixel joining (default: <code>500</code>).</li> <li><code>--max-tile-bytes</code> (int): Maximum allowed tile size in bytes for PMTiles (default: <code>5_000_000</code>).</li> <li><code>--max-feature-counts</code> (int): Maximum number of features per tile (default: <code>500_000</code>).</li> <li><code>--preserve-point-density-thres</code> (int): Threshold to preserve point density in PMTiles (default: <code>1024</code>).</li> <li><code>--umap-colname-factor</code> (str): Column name encoding dominant factor in UMAP (default: <code>topK</code>).</li> <li><code>--umap-colname-x</code> (str): Column name for UMAP X coordinate (default: <code>UMAP1</code>).</li> <li><code>--umap-colname-y</code> (str): Column name for UMAP Y coordinate (default: <code>UMAP2</code>).</li> <li><code>--umap-min-zoom</code> (int): Minimum zoom for UMAP PMTiles (default: <code>0</code>).</li> <li><code>--umap-max-zoom</code> (int): Maximum zoom for UMAP PMTiles (default: <code>18</code>).</li> <li><code>--transparent-below</code> / <code>--transparent-above</code> (int): Make pixels below/above the threshold transparent for dark/light backgrounds.</li> <li><code>--keep-intermediate-files</code> (flag): Retain intermediate files generated.</li> <li><code>--skip-raster</code> (flag): Skip raster tile generation and related dependencies.</li> <li><code>--tmp-dir</code> (str): Path to a temporary directory (default: <code>&lt;out-dir&gt;/tmp</code>).</li> </ul> <p>Environment Parameters:</p> <ul> <li><code>--gzip</code> (str): Path to the <code>gzip</code> binary. For faster compression, use <code>pigz -p4</code> (default: <code>gzip</code>).</li> <li><code>--pmtiles</code> (str): Path to the <code>pmtiles</code> binary from go-pmtiles (default: <code>pmtiles</code>).</li> <li><code>--gdal_translate</code> (str): Path to the <code>gdal_translate</code> binary (default: <code>gdal_translate</code>).</li> <li><code>--gdaladdo</code> (str): Path to the <code>gdaladdo</code> binary (default: <code>gdaladdo</code>).</li> <li><code>--tippecanoe</code> (str): Path to the <code>tippecanoe</code> binary (default: <code>tippecanoe</code>).</li> <li><code>--spatula</code> (str): Path to the <code>spatula</code> binary (default: <code>spatula</code>).</li> </ul> <p>Run Parameters:</p> <ul> <li><code>--dry-run</code> (flag): Generate the Makefile; do not execute.</li> <li><code>--restart</code> (flag): Ignore existing outputs and rerun all steps.</li> <li><code>--makefn</code> (str): Makefile name to write (default: <code>run_cartload2.mk</code>).</li> <li><code>--n-jobs</code> (int): Number of parallel jobs (default: 1).</li> <li><code>--threads</code> (int): Max threads per job (tippecanoe, etc.) (default: 4).</li> <li><code>--log</code> (flag): Write logs to a file under the output directory.</li> <li><code>--log-suffix</code> (str): Log filename suffix (default: <code>.log</code>).</li> </ul>"},{"location":"reference/run_cartload2_multi/#output","title":"Output","text":"<p>Outputs are written under <code>--out-dir</code>:</p> <ul> <li>Per\u2011sample catalogs: <code>&lt;out-dir&gt;/&lt;id&gt;/catalog.yaml</code> (or <code>--out-catalog</code> name).</li> <li>Per\u2011sample PMTiles and asset JSONs produced by <code>run_cartload2</code> under <code>&lt;out-dir&gt;/&lt;id&gt;/</code>.</li> <li>Makefile: <code>&lt;out-dir&gt;/&lt;makefn&gt;</code> capturing all per\u2011sample targets.</li> </ul> <p>See <code>run_cartload2.md</code> for detailed CartLoad2 output formats (SGE rasters, factor PMTiles, joined molecule PMTiles, summaries).</p>"},{"location":"reference/run_cartload2_multi/#see-also","title":"See Also","text":"<ul> <li>Reference: <code>run_cartload2.md</code> \u2014 Single\u2011sample packaging and outputs</li> <li>Reference: <code>run_ficture2_multi.md</code> \u2014 Multi\u2011sample FICTURE pipeline</li> </ul>"},{"location":"reference/run_ficture2/","title":"Spatial Factor Inference Analysis using FICTURE","text":""},{"location":"reference/run_ficture2/#overview","title":"Overview","text":"<p>Following format conversion, <code>CartLoader</code> provides the <code>run_ficture2</code> module to run spatial factor inference using <code>FICTURE</code> (Si et al., Nature Methods, 2024). This method infers spatial factors directly at the pixel level with submicron resolution, eliminating the need for segmentation.</p> <p>What is <code>FICTURE</code>?</p> <p><code>FICTURE</code> reconstructs the fine-scale tissue structure by first decomposing gene expression patterns across the tissue section into spatial factors and then assigns each pixel to these factors using local context. Biologically, these inferred factors may correspond to specific cell types, functional or physiological states, subcellular domains, or extracellular transcriptomic signatures.</p> <p>By default, <code>FICTURE</code> learns the spatial factors by implementing a standard latent Dirichlet allocation (LDA) model on a hexagonal grid overlay of the spatial coordinates. Optionally, spatial factors can also be derived from external sources, such as single-cell or single-nucleus RNA-seq reference datasets, or from spatially agnostic factor learning methods (e.g., Seurat, Scanpy).</p> <p>The <code>punkst</code> version of <code>FICTURE</code></p> <p>To efficiently run FICTURE-based inference, <code>CartLoader</code> integrates <code>punkst</code>, an optimized implementation of FICTURE that maintains output equivalence while enhancing computational scalability and performance. </p> <p>Currently, <code>run_ficture2</code> uses the <code>punkst</code> version of <code>FICTURE</code>.</p>"},{"location":"reference/run_ficture2/#requirements","title":"Requirements","text":"<ul> <li>An SGE in the unified format (from SGE format conversion)</li> <li>Pre-installed tools: <code>spatula</code>, <code>punkst</code>, <code>gzip</code>, <code>sort</code>, <code>python</code></li> </ul>"},{"location":"reference/run_ficture2/#example-usage","title":"Example Usage","text":"<pre><code>cartloader run_ficture2 \\\n    --main \\\n    --in-transcript /path/to/converted/transcripts/tsv/file \\\n    --in-feature /path/to/converted/feature/tsv/file \\\n    --in-minmax /path/to/converted/coordinates/minmax/tsv/file \\\n    --cmap-file /path/to/cartloader/assets/fixed_color_map_256.tsv \\\n    --colname-count count \\\n    --out-dir /path/to/output/directory \\\n    --width 18 \\\n    --n-factor 24 \\\n    --spatula /path/to/spatula/binary \\\n    --ficture2 /path/to/punkst/directory \\  \n    --exclude-feature-regex '^(mt-|Gm\\d+$)' \\\n    --n-jobs 20  \\\n    --threads 20 \n</code></pre>"},{"location":"reference/run_ficture2/#actions","title":"Actions","text":"<p>Action Specifications</p> <p>No action runs by default. Activate at least one using the action parameters.</p>"},{"location":"reference/run_ficture2/#tiling-step-tile","title":"Tiling Step (<code>--tile</code>)","text":"<p>The tiling step takes the standardized SGE (from SGE format conversion) as input. It reorganizes input coordinate data into non\u2011overlapping square tiles in a plain TSV format and generates an index file with tile offsets to enable efficient random access.</p>"},{"location":"reference/run_ficture2/#segmentation-step-segment","title":"Segmentation Step (<code>--segment</code>)","text":"<p>The segmentation step starts from the tiled SGE, using the plain TSV file from tiling step as input. It aggregates tiled pixel data into non-overlapping hexagons in a TSV file for spot-level analysis, outputting a tab-delimited file of hexagon records and associated metadata in JSON format.</p>"},{"location":"reference/run_ficture2/#lda-training-step-init-lda","title":"LDA Training Step (<code>--init-lda</code>)","text":"<p>The LDA training step uses the hexagon TSV and JSON file from segmentation step as input, trains a Latent Dirichlet Allocation (LDA) model on sparse gene count data from hexagon units, using metadata to interpret input structure and optionally filter or weight features, producing a factorized topic model in TSV.</p>"},{"location":"reference/run_ficture2/#decoding-step-decode","title":"Decoding Step (<code>--decode</code>)","text":"<p>The decoding step applies a trained LDA model from LDA training step to tiled pixel-level transcript data from tiling step to infer the top spatial factors and their posterior probabilities for each pixel, enabling fine-grained spatial mapping of gene expression. It outputs a pixel-level annotation file in TSV format with coordinates and factor assignments, along with a pseudobulk gene-by-factor matrix in TSV format.</p>"},{"location":"reference/run_ficture2/#umap-visualization-step-umap","title":"UMAP Visualization Step (<code>--umap</code>)","text":"<p>The UMAP visualization step generates UMAP embeddings of factors learned in LDA training, writing both coordinates and plots for reuse downstream.</p>"},{"location":"reference/run_ficture2/#10x-segmentation-step-segment-10x","title":"10x Segmentation Step (<code>--segment-10x</code>)","text":"<p>The 10x segmentation step aggregates tiled pixel data into 10x Genomics-compatible hexagonal bin formats (MEX matrix). This allows the data to be used with tools designed for 10x Visium data.</p>"},{"location":"reference/run_ficture2/#parameters","title":"Parameters","text":"<p>Below are the core parameters. See more details in the collapsible section (\"Auxiliary Paramaters\") below.</p>"},{"location":"reference/run_ficture2/#action-parameters","title":"Action Parameters","text":"<ul> <li><code>--main</code>: Run all of the following five actions.</li> <li><code>--tile</code>: Run tiling step.</li> <li><code>--segment</code>: Run segmentation step.</li> <li><code>--init-lda</code>: Run LDA training step.</li> <li><code>--decode</code>: Run decoding step.</li> <li><code>--umap</code>: Run UMAP step.</li> <li><code>--segment-10x</code>: Run 10x segmentation step.</li> </ul>"},{"location":"reference/run_ficture2/#inputoutput-parameters","title":"Input/Output Parameters","text":"<ul> <li><code>--out-dir</code> (str): Output directory to store all result files.</li> <li><code>--out-json</code> (str): Output JSON file summarizing FICTURE parameters (Default: <code>&lt;out-dir&gt;/ficture.params.json</code>).</li> <li><code>--in-transcript</code> (str): Input transcript-indexed SGE file in TSV format.</li> <li><code>--in-minmax</code> (str): Optional input coordinate min-max file.</li> <li><code>--in-feature</code> (str): Optional input UMI count per gene TSV file.</li> </ul>"},{"location":"reference/run_ficture2/#key-parameters","title":"Key Parameters","text":"<ul> <li><code>--width</code> (str): Comma-separated hexagon flat-to-flat widths (in \u00b5m) for LDA training.</li> <li><code>--n-factor</code> (str): Comma-separated list of factor counts for LDA training.</li> <li><code>--include-feature-regex</code> (str): (Optional) Regex pattern for including features/genes.</li> <li><code>--exclude-feature-regex</code> (str): (Optional) Regex pattern for excluding features/genes.</li> <li><code>--cmap-file</code> (str): (Optional) Path to fixed color map TSV file. If not provided, FICTURE will generate a color map.</li> <li><code>--segment-width-10x</code> (str): Comma-separated hexagon flat-to-flat widths (\u00b5m) in 10x format (required if <code>--segment-10x</code>).</li> </ul> Auxiliary Paramaters <p>Auxiliary Input Parameters</p> <ul> <li><code>--in-feature-ficture</code> (str): (Optional) A separate feature file applied to FICTURE analysis. Alternative to customizing via auxiliary parameters.</li> <li><code>--colidx-x</code> (int): Column index of X in the transcript file (Default: 1).</li> <li><code>--colidx-y</code> (int): Column index of Y in the transcript file (Default: 2).</li> <li><code>--colname-count</code> (str): Column name to use as count value (Default: count).</li> <li><code>--colname-feature</code> (str): Column name for gene/feature name (Default: gene).</li> </ul> <p>Auxiliary FICTURE Parameters:</p> <ul> <li>Tiling-specific parameters:<ul> <li><code>--tile-size</code> (int): Size of tiles for processing (Default: 500).</li> <li><code>--tile-buffer</code> (int): Buffer zone around each tile (Default: 1000).</li> </ul> </li> <li>Segmentation-specific parameters:<ul> <li><code>--min-ct-per-unit-hexagon</code> (int): Minimum count per hexagon (Default: 50).</li> <li><code>--minibatch-size</code> (int): Minibatch size for preprocessing (Default: 500).</li> </ul> </li> <li>LDA training-specific parameters:<ul> <li><code>--min-ct-per-unit-train</code> (int): Minimum count for training (Default: 50).</li> <li><code>--train-epoch</code> (int): Number of epochs to train LDA model (Default: 2).</li> </ul> </li> <li>Decoding-specific parameters:<ul> <li><code>--fit-width</code> (int): Hexagon width (in \u00b5m) for model fitting (Default: same as train width). </li> <li><code>--anchor-res</code> (int): Anchor resolution used in decoding (Default: 6).</li> <li><code>--radius-buffer</code> (int): Buffer added to anchor resolution for decoding (Default: 1). </li> <li><code>--decode-scale</code> (int): Scales input coordinates to pixels in the output image (Default: 1)</li> </ul> </li> <li>Shared paramaters across steps:<ul> <li><code>--seed</code> (int): Random seed for reproducibility (Default: 1).</li> <li><code>--min-ct-per-feature</code> (int): Minimum count per feature for LDA and decoding (Default: 20).</li> <li><code>--de-max-pval</code> (float): p-value cutoff for differential expression (Default: 1e-3).</li> <li><code>--de-min-fold</code> (float): Fold-change threshold for differential expression (Default: 1.5).</li> </ul> </li> </ul> <p>Feature Filtering Parameters:</p> <ul> <li><code>--include-feature-regex</code> (str): Regex of feature names to include.</li> <li><code>--exclude-feature-regex</code> (str): Regex of feature names to exclude.</li> </ul> <p>Environment Parameters: For tools that require specifying the path to their executable binaries, you may omit the path if the binary is already included in your system's <code>PATH</code>.</p> <ul> <li><code>--gzip</code> (str): Path to <code>gzip</code> binary; consider <code>pigz -p 4</code> for speed (Default: <code>gzip</code>).</li> <li><code>--sort</code> (str): Path to <code>sort</code> binary (Default: <code>sort</code>).</li> <li><code>--sort-mem</code> (str): Memory allocated per <code>sort</code> process (Default: <code>1G</code>).</li> <li><code>--spatula</code> (str): Path to <code>spatula</code> binary (Default: <code>spatula</code>).</li> <li><code>--ficture2</code> (str): Path to the <code>punkst</code> repository (Default to <code>punkst</code> directory in <code>submodules</code>)</li> <li><code>--python</code> (str): Path to Python 3 binary (Default: <code>python3</code>).</li> <li><code>--R</code> (str): Path to <code>R</code> binary for UMAP generation (default: <code>R</code>).</li> </ul> <p> Run Parameters:</p> <ul> <li><code>--dry-run</code> (flag): Generate the Makefile; do not execute.</li> <li><code>--restart</code> (flag): Ignore existing outputs and rerun all steps.</li> <li><code>--makefn</code> (str): Makefile name to write (default: <code>run_ficture2.mk</code>).</li> <li><code>--n-jobs</code> (int): Number of parallel jobs (default: 1).</li> <li><code>--threads</code> (int): Max threads per job (default: 4).</li> </ul>"},{"location":"reference/run_ficture2/#output","title":"Output","text":""},{"location":"reference/run_ficture2/#tiling-output","title":"Tiling Output","text":"<ul> <li><code>transcripts.tiled.tsv</code>: A tab-delimited TSV file where each line records a tile with X and Y coordinates, a feature name (e.g., gene), and its associated count.     <pre><code>3815.69 491.9   Arfgef1 1\n</code></pre></li> <li><code>transcripts.tiled.index</code>: An index file that records the byte offsets of each tile in the tiled TSV file, enabling fast random access to tile-specific data. It includes comment lines with metadata (tile size, pixel count, min/max X and Y coordinates) and data lines listing the offset positions for each tile.     <pre><code># tilesize  500\n# npixels   333021294\n# xmin  0.28\n# xmax  19851.1\n# ymin  0.5\n# ymax  13476.4\n0   7   0           13103550    569474\n0   8   13103550    40259340    1180529\n</code></pre></li> <li><code>transcripts.tiled.coord_range.tsv</code>: A tab-delimited TSV file provides xmin, xmax, ymin, and ymax as key\u2013value pairs.     <pre><code>xmin    0.28\nxmax    19851.1\nymin    0.5\nymax    13476.4\n</code></pre></li> <li><code>transcripts.tiled.features.tsv</code>: A tab-delimited TSV file listing each feature name and its expression count per line.     <pre><code>1810009J06Rik   1\nGm48545         1\n</code></pre></li> </ul>"},{"location":"reference/run_ficture2/#segmentation-output","title":"Segmentation Output","text":"<ul> <li> <p><code>hexagon_d_{width}.randomized.tsv</code>: A plain-text TSV file that stores sparse feature representations for hexagon units, with each line corresponding to one hexagon.</p> <p>File Format</p> <p>This is not a regular table\u2014the number of columns varies across lines depending on the number of features present in each hexagon.</p> <pre><code>00001c64  18999.0000  9773.9627  227  244   2417 1  10469 2  2448 1  543 1   10935 1  6460 1  1797 1  6517 1  1094 1  9872 1  8587 1  7137 1  8786 1  10564 1  2127 1  439 1   1529 1  8432 1   1304 1  1739 1   3012 1  6434 1  5297 1  10017 1  2567 1  4771 1  5644 1  6415 1  5258 1   258 1   2314 1  6378 1  8843 1  7386 1  3322 1  2041 1  4735 1  9755 1  8614 1   4665 1  5693 1  2194 1  1680 1  10406 1  2696 1  7250 1  2367 1  7189 1  1616 1  10721 1  441 1   9981 1   8696 1  1012 1  8545 1  835 1   6550 1  4409 1  1860 1  575 1   139 1   5473 1  10172 1  7316 1  5260 1  180 1   2068 1  10806 1  8817 1  1621 1  4542 1  6193 1  440 1   6608 1  6989 1  4782 1  3258 1  5205 1  1093 1  9060 1  1921 1  6333 1   846 1   10575 1  2608 1  10186 1  932 1   2217 1  5392 1  2275 1  4845 1   8401 1  341 1   2810 1   754 1   4501 1  1160 1  5354 1  5097 1  3713 1  1619 1  9843 1  2749 1  1207 1  7384 1  2758 1  445 1   9040 1  45 1    2517 1   11255 1  8161 1  393 1   2963 1  3457 1  4481 1  10649 1  6954 2  2842 1  7982 1  2034 1  2849 2  5393 1  5257 1  773 1   1030 1  5455 1  2380 1  7079 1  1491 1  353 1    5343 1  1231 1  178 1   8659 1  10994 1  6168 1  267 1    6770 1   9083 1   2691 1  2423 2  3058 3  6921 1  1778 1  236 1   7175 1  7683 1   47 1    9094 2  1898 1  6524 1  5640 1  6668 1   6411 1  3536 1  10475 2  6538 1  1443 1  2728 1  7717 1  4633 1  6634 1   5349 1  11215 2  9159 1  2129 1  5984 1  8584 2  7042 1  3819 2  7931 1  2343 1  1182 2  2724 1  1871 1  716 1   1744 1  263 1   7459 1  6737 1  4654 1   9023 1  775 2    1546 1  1512 1  6395 1  5624 1  1560 2  8919 2  4689 1  2403 1  4163 1  5705 1  1260 1  8068 1  1900 1  1701 1  1187 1  8172 1  5955 1  494 1   428 1   6082 1  479 1   5362 1   11273 1  1764 1   9546 1  8261 1  11088 1  6262 1  2154 1  612 1   6777 2  866 1    10850 1  4168 1  9334 1  9077 2   3818 1  732 1   6386 1  989 1   1277 1  319 1   6230 1\n</code></pre> <ul> <li>1st column (str): Random identifier for the hexagon</li> <li>2nd and 3rd columns (float): Axial coordinates in the hexagonal coordinate system</li> <li>4th and 5th columns (int): Number of unique features and total counts, repeated per modality (for K modalities)</li> <li>6th column onward (integer integer): Index\u2013count pairs for non-zero features, using 0-based indices from --feature-dict or as provided in the input file</li> </ul> </li> <li> <p><code>hexagon_d_{width}.json</code>: The meta data for the hexagons. such as, , hexagon size, x and y column indices (), number of features, number of modalities, and number of hexagons (<code>n_units</code>),     <pre><code>{\n\"dictionary\": {\n    \"A2m\": 9636,\n    \"AA986860\": 6486,\n    ...\n    },\n    \"header_info\": [\n        \"random_key\",\n        \"x\",\n        \"y\"\n    ],\n    \"hex_size\": 10.392304845413264,\n    \"icol_x\": 1,\n    \"icol_y\": 2,\n    \"n_features\": 11319,\n    \"n_modalities\": 1,\n    \"n_units\": 498019,\n    \"offset_data\": 3,\n    \"random_key\": 0\n}\n</code></pre></p> <ul> <li><code>dictionary</code>: The feature name-idex pairs</li> <li><code>header_info</code>: Header information</li> <li><code>hex_size</code>: Size of hexagons</li> <li><code>icol_x</code> and <code>icol_y</code>: Indices of X and Y coordinates</li> <li><code>n_features</code>: Number of features</li> <li><code>n_modalities</code>: Number of modalities</li> <li><code>n_units</code>: Number of hexagons</li> <li><code>offset_data</code>: ?</li> <li><code>random_key</code>: the random seed for reproduction</li> </ul> </li> </ul>"},{"location":"reference/run_ficture2/#lda-training-output","title":"LDA Training Output","text":"<ul> <li><code>t{width}_f{n_factor}.model.tsv</code>: A matrix to store the learned topic-word distribution.     <pre><code>Feature  0        1      2      3      4      5      6         7      8      9      10        11       12     13     14        15     16     17     18      19     20      21     22     23\nNeu4     481.168  0.042  0.042  0.042  0.042  0.042  1828.293  0.042  0.042  0.042  2290.443  836.722  0.042  0.042  1704.589  0.042  0.042  0.042  29.738  0.042  24.854  0.042  0.042  0.042\n</code></pre><ul> <li>Rows (str): LDA topics or spatial factors</li> <li>Columns (int): Feature identifiers (e.g., gene names or indices)</li> <li>Values (float): Probability or weight of a feature under each topic <code>(P(feature | topic))</code></li> </ul> </li> <li><code>t{width}_f{n_factor}.results.tsv.gz</code>: A tab-delimited file containing the posterior topic distributions for each hexagon. <pre><code>x           y          0       1       2       3       4       5       6       7       8       9       10      11      12      13      14      15      16      17      18      19      20      21      22      23      topK  topP\n14202.0000  5393.6062  0.0000  0.5087  0.0860  0.0000  0.0269  0.0000  0.0136  0.0000  0.0000  0.0179  0.0153  0.0000  0.0490  0.0000  0.0982  0.0000  0.0911  0.0199  0.0143  0.0189  0.0373  0.0000  0.0030  0.0000  1     0.5087\n</code></pre><ul> <li><code>x</code> and <code>y</code> (float): X Y coordinates of the hexagon.</li> <li>Columns <code>0</code> to <code>{n_factor-1}</code> (float): Posterior probabilities for each latent factor <code>(P(topic | hexagon))</code></li> <li><code>topK</code> (int): Index of the most probable factor</li> <li><code>topP</code> (float): Posterior probability of the top factor</li> </ul> </li> <li> <p><code>t{width}_f{n_factor}.bulk_chisq.tsv</code> <pre><code>gene  factor  Chi2      pval      FoldChange  gene_total  log10pval\nApp   0       864182.5  0.00e+00  4.41        1422353     187657.91\n</code></pre></p> <ul> <li><code>gene</code> (str): Gene names.</li> <li><code>factor</code> (int): Factor IDs.</li> <li><code>Chi2</code> (float): Chi-squared test statistic comparing the expression in the target factor and the rest.</li> <li><code>pval</code> (float): P-value associated with the chi-squared test.</li> <li><code>FoldChange</code> (float): Ratio of gene expression inside versus outside the factor\u2019s high-loading region.</li> <li><code>gene_total</code> (int): Total count of the gene in the dataset.</li> <li><code>log10pval</code> (float): Base-10 logarithm of the inverse p-value (i.e., -log10(pval)), useful for ranking significant genes.</li> </ul> </li> <li> <p><code>t{width}_f{n_factor}.factor.info.tsv</code> and <code>t{width}_f{n_factor}.factor.info.html</code>: A TSV and HTML file providing the information for each factor per line.     <pre><code>Factor  RGB          Weight   PostUMI   TopGene_pval                                                                                                                                       TopGene_fc                                                                                                                                           TopGene_weight\n0       255,101,101  0.11279  82949360  App, Snrpn, Calm3, Eef1a2, Dctn1, Ptprn2, Akt3, Tmem181a, Sgtb, Ncdn, Selenow, Atp6v0a1, Cacng8, Atp2a2, Stub1, Akap5, Cmip, Cap1, Rundc3a, Ptprn  Sgtb, Map3k9, Cmip, Vps51, Ptprn2, Zscan2, Ppp2cb, Cacng8, Als2, Eif4e3, Ubxn2a, Gabrb2, Pms1, Rnpc3, Prepl, Zfp418, Tmem181a, Akap5, Dctn1, Atp2b3  App, Calm3, Selenow, Camk2n1, Snrpn, Ncdn, Atp2a2, Eef1a2, Uchl1, Ndfip1, Snap25, Stxbp1, Ywhag, Arf3, Serinc1, Atp6v1b2, Maged1, Atp6v0a1, Dnm1, Rab6b\n</code></pre></p> <ul> <li><code>Factor</code> (int): Factor IDs</li> <li><code>RGB</code> (str): Comma-separated RGB values</li> <li><code>Weight</code> (float): Proportion of the total factor signal explained by this factor</li> <li><code>PostUMI</code> (int): Sum of posterior UMI counts across all spatial locations for this factor</li> <li><code>TopGene_pval</code>, <code>TopGene_fc</code>, <code>TopGene_weight</code> (str): Top marker genes per factor ranked by significance (p-value), fold change, or weight</li> </ul> </li> <li><code>t{width}_f{n_factor}.cmap.tsv</code>: a color map.     <pre><code>R    G    B    Color_hex  Name\n255  101  101  #ff6565    0\n</code></pre><ul> <li><code>Name</code> (int): Factor IDs</li> <li><code>Color_hex</code> (str): Color HEX code</li> <li><code>R</code>, <code>G</code>, <code>B</code> (float): Red, Green, and Blue channel values (range: 0.0 to 1.0)</li> </ul> </li> </ul>"},{"location":"reference/run_ficture2/#decoding-output","title":"Decoding Output","text":"<ul> <li> <p><code>t{width}_f{n_factor}_p{width}_a{anchor_res}.tsv.gz</code>: A tab-delimited file where each line represents a pixel\u2013feature pair, recording the pixel\u2019s coordinates, the expressed feature and its count, along with the top three most probable latent factors (<code>K1</code>\u2013<code>K3</code>) and their corresponding probabilities (<code>P1</code>\u2013<code>P3</code>).     <pre><code>#x         y         feature  ct  K1  K2  K3  P1          P2          P3\n5159.4800  450.1500  Retreg2  1   0   19  9   9.5073e-01  4.8011e-02  5.0298e-04\n</code></pre></p> <ul> <li><code>x</code> and <code>y</code> (float): X Y coordinates</li> <li><code>feature</code> (str): feature names.</li> <li><code>ct</code> (int): count</li> <li><code>K1</code> (int) and <code>P1</code> (float): The most probable factor and its probability</li> <li><code>K2</code> (int) and <code>P2</code> (float): The 2nd most probable factor and its probability</li> <li><code>K3</code> (int) and <code>P3</code> (float): The 3rd most probable factor and its probability</li> </ul> </li> <li> <p><code>t{width}_f{n_factor}_p{width}_a{anchor_res}.index</code>: An index file for <code>t{width}_f{n_factor}_p{width}_a{anchor_res}.tsv.gz</code>.</p> </li> <li><code>t{width}_f{n_factor}_p{width}_a{anchor_res}.json</code>: A JSON file to provide header information for <code>t{width}_f{n_factor}_p{width}_a{anchor_res}.tsv.gz</code>.     <pre><code>{\n    \"K1\": 4,\n    \"K2\": 5,\n    \"K3\": 6,\n    \"P1\": 7,\n    \"P2\": 8,\n    \"P3\": 9,\n    \"ct\": 3,\n    \"feature\": 2,\n    \"x\": 0,\n    \"y\": 1\n}\n</code></pre></li> <li><code>t{width}_f{n_factor}_p{width}_a{anchor_res}.png</code>: A PNG file to visualize the spatial factors distribution at pixel level.</li> <li> <p><code>t{width}_f{n_factor}_p{width}_a{anchor_res}.pseudobulk.tsv</code>: A feature-by-factor matrix showing feature distribution across topics.     <pre><code>Feature  0         1       2       3       4       5       6          7       8       9       10         11        12      13      14        15      16      17      18       19      20       21      22      23\nNeu4     648.5156  0.0000  0.9999  0.0000  0.0000  2.1425  1316.2651  0.0000  0.0000  0.0000  1114.2935  527.5519  0.0000  0.0000  820.3735  0.0000  0.0000  3.3504  30.4680  0.0000  38.0400  0.0000  0.0000  0.0000\n</code></pre></p> <ul> <li>Rows (str): LDA topics or spatial factors</li> <li>Columns (int): Feature identifiers (e.g., gene names or indices)</li> <li>Values (float): Posterior probability of a feature in a factor.</li> </ul> </li> <li> <p><code>t{width}_f{n_factor}_p{width}_a{anchor_.res}.bulk_chisq.tsv</code>: Same format as the <code>t{width}_f{n_factor}.bulk_chisq.tsv</code></p> </li> <li><code>t{width}_f{n_factor}_p{width}_a{anchor_res}.factor.info.tsv</code>:  Same format as the <code>t{width}_f{n_factor}.factor.info.tsv</code></li> <li><code>t{width}_f{n_factor}_p{width}_a{anchor_res}.factor.info.html</code>: Same format as the <code>t{width}_f{n_factor}.factor.info.html</code></li> </ul>"},{"location":"reference/run_ficture2/#summarization-output","title":"Summarization Output","text":"<ul> <li><code>ficture.params.json</code>: A JSON file to summarize the path to input, output, and paramaters.     <pre><code>{\n\"in_sge\": {\n    \"in_transcript\": \"/path/to/transcripts.unsorted.tsv.gz\",\n    \"in_feature\": \"/path/to/transcripts.tiled.features.hdr.tsv\",\n    \"in_minmax\": \"/path/to/coordinate_minmax.tsv\"\n},\n\"in_feature_ficture\": \"/path/to/transcripts.tiled.overlapping_features.min100.hdr.tsv\", # if available\n\"train_params\": [\n    {\n        \"model_type\": \"lda\",\n        \"model_id\": \"t{width}_f{n_factor}\",\n        \"model_path\": \"/path/to/t{width}_f{n_factor}.model.tsv\",\n        \"train_width\": width,\n        \"n_factor\": n_factor,\n        \"cmap\": \"/path/to/t{width}_f{n_factor}.cmap.tsv\",\n        \"decode_params\": [\n            {\n                \"decode_id\": \"t{width}_f{n_factor}_p{width}_a{anchor_res}\",\n                \"fit_width\": width,\n                \"anchor_res\": anchor_res\n            }\n        ]\n    }\n]\n}\n</code></pre></li> </ul>"},{"location":"reference/run_ficture2/#umap-output","title":"UMAP Output","text":"<ul> <li><code>t{width}_f{n_factor}.umap.tsv.gz</code>: UMAP coordinates per factor with factor IDs and colors; can be reused by downstream pipelines (e.g., upload optional files).</li> <li><code>t{width}_f{n_factor}.umap.png</code>: A UMAP plot that visualizes the relationships between spatial factors.</li> <li><code>t{width}_f{n_factor}.umap.single.prob.png</code>: A gallery of images, with each image showing a single factor color-coded by probability.</li> </ul>"},{"location":"reference/run_ficture2_multi/","title":"Multi-Sample Spatial Factor Inference Analysis with FICTURE","text":""},{"location":"reference/run_ficture2_multi/#overview","title":"Overview","text":"<p><code>run_ficture2_multi</code> orchestrates joint FICTURE analysis on &gt;=2 samples. It tiles each sample, builds joint hex grids (one or more widths), trains LDA models cross samples per width/factor count, decodes per sample, and writes per\u2011sample JSON manifests summarizing results.</p> <p>Use this when processing multiple samples together to learn shared spatial factors and generate per\u2011sample outputs in a single, parallelizable pipeline.</p>"},{"location":"reference/run_ficture2_multi/#requirements","title":"Requirements","text":"<ul> <li>TSV file where the first two columns per line are the sample ID and the path to the transcript\u2011indexed SGE file  </li> <li>FICTURE2 repository with <code>bin/punkst</code> and Python utilities (e.g., <code>ext/py/factor_report.py</code>)</li> <li>Pre-installed tools: <code>gzip</code>, <code>python</code>, <code>punkst</code>, <code>spatula</code></li> </ul>"},{"location":"reference/run_ficture2_multi/#example-usage","title":"Example Usage","text":"<pre><code>cartloader run_ficture2_multi \\\n  --in-list /path/to/samples.tsv \\\n  --out-dir /path/to/out/ficture_multi \\\n  --width 12 \\\n  --n-factor 12,24 \\\n  --exclude-feature-regex \"^(Blank-.*$)\" \\\n  --redo-merge-units \\\n  --spatula /path/to/spatula/binary \\\n  --ficture2 /path/to/FICTURE2 \\\n  --cmap-file /path/to/colormap.tsv \\\n  --threads 8 \\\n  --n-jobs 4\n</code></pre>"},{"location":"reference/run_ficture2_multi/#actions","title":"Actions","text":"<p>All actions run by default (UMAPs can be skipped with <code>--skip-umap</code>):</p> <ul> <li>Multisample prepare: tiles inputs, builds joint hex grids at requested <code>--width</code> values</li> <li>LDA training: trains LDA models for each <code>(width, n-factor)</code> pair</li> <li>Decode: applies trained models per sample; produces pixel\u2011level factors and summaries</li> <li>Write per\u2011sample JSON: consolidates paths and metadata for downstream consumption</li> </ul>"},{"location":"reference/run_ficture2_multi/#parameters","title":"Parameters","text":"<p>Below are the core arguments you\u2019ll typically set. Flag names and behavior follow <code>run_ficture2_multi.py</code>.</p>"},{"location":"reference/run_ficture2_multi/#inputoutput","title":"Input/Output","text":"<ul> <li><code>--in-list</code> (str, required): TSV with at least two columns per line: <code>&lt;sample_id&gt;</code> and <code>&lt;path_to_transcript_TSV&gt;</code> .</li> <li><code>--out-dir</code> (str, required): Output directory.</li> <li><code>--out-json</code> (str): Top\u2011level JSON (defaults to <code>&lt;out-dir&gt;/ficture.params.json</code>).</li> </ul>"},{"location":"reference/run_ficture2_multi/#hex-tiling-preprocessing","title":"Hex Tiling / Preprocessing","text":"<ul> <li><code>--colidx-x</code>, <code>--colidx-y</code> (int, 1\u2011based): X/Y column indices in the transcript TSV.</li> <li><code>--colidx-feature</code>, <code>--colidx-count</code> (int, 1\u2011based): Feature and count indices.</li> <li><code>--tile-size</code> (int): Tile size for preprocessing.</li> <li><code>--tile-buffer</code> (int): Buffer size for tiling.</li> <li><code>--width</code> (str): Comma\u2011separated hex widths in \u00b5m (e.g., <code>8,16</code>).</li> <li><code>--min-count</code> (int): Minimum count per unit hexagon.</li> <li><code>--min-total-count-per-sample</code> (int): Minimum per\u2011sample transcript count to retain in the joint set.</li> <li><code>--include-feature-regex</code> / <code>--exclude-feature-regex</code> (str): Feature filters.</li> <li><code>--redo-merge-units</code> (flag): Rebuild merged units per width (temporary bug workaround).</li> </ul>"},{"location":"reference/run_ficture2_multi/#training-decoding","title":"Training / Decoding","text":"<ul> <li><code>--n-factor</code> (str): Comma\u2011separated factor counts for training (e.g., <code>12,24</code>).</li> <li><code>--anchor-res</code> (int): Anchor resolution used in decode IDs (see outputs).</li> <li><code>--cmap-file</code> (str, defaults to fixed_color_map_256.tsv): Colormap TSV used to colorize factors.</li> <li><code>--umap</code> (flag): Generate UMAP embeddings/plots for each LDA model (on by default).</li> <li><code>--skip-umap</code> (flag): Skip UMAP generation (overrides <code>--umap</code>).</li> </ul>"},{"location":"reference/run_ficture2_multi/#run-options","title":"Run Options","text":"<ul> <li><code>--dry-run</code> (flag): Generate Makefile and print commands only.</li> <li><code>--restart</code> (flag): Ignore existing outputs and rerun steps.</li> <li><code>--threads</code> (int): Max threads per job (default: 8).</li> <li><code>--n-jobs</code> (int): Parallel jobs for the Makefile.</li> </ul>"},{"location":"reference/run_ficture2_multi/#environment-tools","title":"Environment / Tools","text":"<ul> <li><code>--ficture2</code> (str, required): Path to FICTURE2 repo containing <code>bin/punkst</code>.</li> <li><code>--python</code> (str): Python executable (used for reporting utilities).</li> <li><code>--gzip</code> (str): Path to <code>gzip</code> binary.</li> </ul>"},{"location":"reference/run_ficture2_multi/#output","title":"Output","text":"<p>Outputs are written under <code>--out-dir</code>.</p> <ul> <li> <p>Multisample prepare (joint):</p> <ul> <li><code>multi.features.tsv</code>: Joint (tiled) features table.</li> <li><code>multi.hex_&lt;width&gt;.txt</code> and <code>multi.hex_&lt;width&gt;.json</code>: Hex grid and metadata per width.</li> </ul> </li> <li> <p>LDA training (per width \u00d7 n\u2011factor): prefix <code>t{width}_f{n_factor}</code></p> <ul> <li><code>.model.tsv</code>: Topic\u2013feature weights (factors).</li> <li><code>.results.tsv.gz</code>: Posterior per unit (hex/pixel) with top factor columns.</li> <li><code>.bulk_chisq.tsv</code>: Per\u2011factor differential feature table.</li> <li><code>.factor.info.tsv</code> and optional <code>.factor.info.html</code>: Factor summaries and colors.</li> <li><code>.umap.tsv.gz</code>, <code>.umap.png</code>, <code>.umap.single.prob.png</code>: UMAP coordinates and plots for factors (written unless <code>--skip-umap</code>).</li> </ul> </li> <li> <p>Decode (per sample \u00d7 model/width): prefix <code>&lt;sample&gt;.&lt;decode_id&gt;</code></p> <ul> <li><code>.tsv.gz</code>: Pixel\u2011level decode with posterior/assignments.</li> <li><code>.png</code>: Quick\u2011look image per decode.</li> <li><code>.pseudobulk.tsv.gz</code>: Aggregated counts by factor.</li> <li><code>.bulk_chisq.tsv</code>, <code>.factor.info.tsv</code>: Per\u2011decode summaries.</li> </ul> </li> <li> <p>Per\u2011sample JSONs</p> <ul> <li><code>samples/&lt;sample&gt;/ficture.params.json</code>: Consolidates sample feature paths, LDA and decode outputs for downstream steps.</li> </ul> </li> </ul>"},{"location":"reference/run_ficture2_multi/#see-also","title":"See Also","text":"<ul> <li>Reference: <code>run_ficture2.md</code> \u2014 Single\u2011sample FICTURE2 runner and file formats</li> </ul>"},{"location":"reference/run_visiumhd/","title":"Visium HD Pipeline Orchestrator","text":""},{"location":"reference/run_visiumhd/#overview","title":"Overview","text":"<p>An end\u2011to\u2011end workflow for 10x Visium HD data using <code>CartLoader</code> to run steps (including load Space Ranger assets, convert SGE, run FICTURE, import cells, square-bin outputs with optional UMAPs, background images, package assets, and upload for sharing) as needed.</p>"},{"location":"reference/run_visiumhd/#requirements","title":"Requirements","text":"<ul> <li>Space Ranger output</li> <li>Pre-installed tools depending on the actions: <code>spatula</code>, <code>punkst</code>, <code>gzip</code>, <code>sort</code>, <code>python</code>, <code>go-pmtiles</code>, <code>gdal</code>, <code>tippecanoe</code>, <code>parquet-tools</code>, <code>aws</code></li> </ul>"},{"location":"reference/run_visiumhd/#example-usage","title":"Example Usage","text":"Run all modules together <pre><code>cartloader run_visiumhd \\\n  --load-space-ranger \\\n  --sge-convert \\\n  --run-ficture2 \\\n  --import-cells \\\n  --import-images \\\n  --run-cartload2 \\\n  --upload-aws \\\n  --space-ranger-dir /path/to/space/ranger/output \\\n  --out-dir /path/to/out/dir \\\n  --s3-dir s3://example_bucket/example-id \\\n  --width 12 \\\n  --n-factor 12 \\\n  --id example-id \\\n  --spatula /path/to/spatula/binary \\\n  --ficture2 /path/to/punkst/directory \\  \n  --pmtiles /path/to/pmtiles/binary \\\n  --tippecanoe /path/to/tippecanoe/binary \\\n  --aws /path/to/aws/cli/binary \\\n  --n-jobs 10 \\\n  --threads 10\n</code></pre>"},{"location":"reference/run_visiumhd/#actions","title":"Actions","text":"<p>Action Specifications</p> <p><code>run_visiumhd</code> orchestrates multiple <code>CartLoader</code> modules; enable and combine actions with flags.</p> <p>No action runs by default. Activate at least one action flag.</p> <p>See details for each flag:</p> <ul> <li><code>--load-space-ranger</code></li> <li><code>--sge-convert</code></li> <li><code>--run-ficture2</code></li> <li><code>--import-cells</code></li> <li><code>--import-squares</code>: Import Space Ranger square bins (multi-resolution) including optional UMAP coordinates per bin size; writes square assets JSONs and updates <code>catalog.yaml</code>.</li> <li><code>--import-images</code></li> <li><code>--run-cartload2</code></li> <li><code>--upload-aws</code></li> <li><code>--upload-zenodo</code></li> </ul>"},{"location":"reference/run_visiumhd/#parameters","title":"Parameters","text":"<p>Below are the core arguments you\u2019ll typically set. For all other options, expand the collapsible \"Auxiliary Parameters\" section.</p>"},{"location":"reference/run_visiumhd/#action-parameters","title":"Action Parameters","text":"<p>See Action.</p>"},{"location":"reference/run_visiumhd/#inputoutput-parameters","title":"Input/Output Parameters","text":"<ul> <li><code>--space-ranger-dir</code>: Space Ranger output directory (required for manual mode or with <code>--load-space-ranger</code>)</li> <li><code>--out-dir</code>: Output root directory; writes <code>sge/</code>, <code>ficture2/</code>, <code>cartload2/</code> (required)</li> <li><code>--space-ranger-assets</code>: Path to assets JSON from <code>--load-space-ranger</code> (default: <code>&lt;out_dir&gt;/space_ranger_assets.json</code>)</li> <li><code>--ext-fic-dir</code>: External FICTURE directory to import when using <code>--import-ext-ficture2</code></li> </ul>"},{"location":"reference/run_visiumhd/#sge-convert-with-sge-convert","title":"SGE Convert (with <code>--sge-convert</code>)","text":"<ul> <li><code>--units-per-um</code>: Coordinate units per micron in raw SGE (float)</li> <li><code>--exclude-feature-regex</code>: Regex for features to exclude (e.g., controls)</li> <li><code>--filter-by-density</code>: Enable density-based filtering (bool)</li> </ul> <p>If using JSON mode (with <code>--load-space-ranger</code>), SGE inputs are discovered from <code>--space-ranger-assets</code>. In manual mode, provide inputs relative to <code>--space-ranger-dir</code>: - <code>--mex-transcript</code>: Transcript MEX directory (<code>square_002um/filtered_feature_bc_matrix</code>) - <code>--parquet-position</code>: Path to <code>square_002um/spatial/tissue_positions.parquet</code> - <code>--json-scale</code> or <code>--units-per-um</code>: Pixel\u2011to\u2011\u00b5m scale source</p>"},{"location":"reference/run_visiumhd/#ficture-with-run-ficture2","title":"FICTURE (with <code>--run-ficture2</code>)","text":"<ul> <li><code>--width</code>: Comma\u2011separated hexagon widths in \u00b5m for train/projection (required)</li> <li><code>--n-factor</code>: Comma\u2011separated factor counts for training (required)</li> <li><code>--colname-feature</code>: Feature column name (default: <code>gene</code>)</li> <li><code>--colname-count</code>: Count column name (default: <code>count</code>)</li> <li><code>--fic-include-feature-regex</code> (str): Regex of feature names to include in FICTURE analysis.</li> <li><code>--fic-exclude-feature-regex</code> (str): Regex of feature names to exclude in FICTURE analysis.</li> </ul>"},{"location":"reference/run_visiumhd/#import-cells-with-import-cells","title":"Import Cells (with <code>--import-cells</code>)","text":"<ul> <li><code>--cell-id</code>: Asset ID/prefix for cell outputs</li> <li><code>--cell-name</code>: Human\u2011readable name (defaults to <code>--cell-id</code>)</li> <li><code>--tsv-cmap</code>: TSV colormap for cluster colors</li> </ul> <p>Manual mode inputs (relative to <code>--space-ranger-dir</code>): - <code>--csv-clust</code>: Cluster assignments CSV - <code>--csv-diffexp</code>: Differential expression CSV</p>"},{"location":"reference/run_visiumhd/#import-squares-with-import-squares","title":"Import Squares (with <code>--import-squares</code>)","text":"<ul> <li><code>--square-id</code>: Prefix for square-bin assets (default: <code>spaceranger</code>)</li> <li><code>--use-parquet-tools</code>: Use <code>parquet-tools</code> instead of polars/pigz for Parquet\u2192CSV conversion (slower on large files)</li> <li><code>--square-input</code>: Manual mode only: one or more square bin definitions, each as <code>bin_size,bin_pos_parquet,bin_csv_cluster,bin_csv_diffexp,bin_scale_json,bin_csv_umap</code>. UMAP CSV is optional; include to expose 2D embeddings per bin size.</li> </ul>"},{"location":"reference/run_visiumhd/#import-images-with-import-images","title":"Import Images (with <code>--import-images</code>)","text":"<ul> <li><code>--image-ids</code>: One or more image IDs to import (e.g., <code>HnE_BTF</code>)</li> <li><code>--all-images</code>: Import all images listed in <code>--space-ranger-assets</code></li> <li><code>--transparent-below</code>: Make pixels below value transparent (0\u2013255; default: 1)</li> </ul> <p>Manual mode inputs (relative to <code>--space-ranger-dir</code>): - <code>--tifs</code>: One or more BTF/TIFF paths</p>"},{"location":"reference/run_visiumhd/#cartload2-with-run-cartload2","title":"CartLoad2 (with <code>--run-cartload2</code>)","text":"<ul> <li><code>--id</code>: Catalog ID; no whitespace; prefer <code>-</code> over <code>_</code> (required)</li> <li><code>--title</code>: Human\u2011readable title (quote if spaces)</li> <li><code>--desc</code>: Short description (quote if spaces)</li> </ul>"},{"location":"reference/run_visiumhd/#upload-with-upload-aws-upload-zenodo","title":"Upload (with <code>--upload-aws</code> / <code>--upload-zenodo</code>)","text":"<ul> <li><code>--s3-dir</code>: S3 destination, e.g., <code>s3://bucket/prefix</code> (required for AWS)</li> <li><code>--zenodo-token</code>: Path to file containing Zenodo token (required for Zenodo)</li> <li><code>--zenodo-deposition-id</code>: Existing deposition ID (omit to create new)</li> <li><code>--zenodo-title</code>: Deposition title (defaults to <code>--title</code>)</li> <li><code>--creators</code>: One or more <code>\"Lastname, Firstname\"</code> entries (each quoted)</li> </ul> Auxiliary Parameters"},{"location":"reference/run_visiumhd/#run-options","title":"Run Options","text":"<ul> <li><code>--dry-run</code>: Print commands without executing (bool; default: false)</li> <li><code>--restart</code>: Ignore existing outputs and rerun steps (bool; default: false)</li> <li><code>--n-jobs</code>, <code>-j</code>: Parallel jobs to run (int; default: 1)</li> <li><code>--threads</code>: Max threads per job, e.g., tippecanoe (int; default: 4)</li> </ul>"},{"location":"reference/run_visiumhd/#environment-tools","title":"Environment / Tools","text":"<ul> <li><code>--pmtiles</code>: Path to <code>pmtiles</code> binary (default: <code>pmtiles</code>)</li> <li><code>--gdal_translate</code>: Path to <code>gdal_translate</code> (default: <code>gdal_translate</code>)</li> <li><code>--gdaladdo</code>: Path to <code>gdaladdo</code> (default: <code>gdaladdo</code>)</li> <li><code>--gdalwarp</code>: Path to <code>gdalwarp</code> (default: <code>gdalwarp</code>)</li> <li><code>--tippecanoe</code>: Path to <code>tippecanoe</code> (default: repo submodule)</li> <li><code>--spatula</code>: Path to <code>spatula</code> (default: <code>spatula</code>)</li> <li><code>--parquet-tools</code>: Path to <code>parquet-tools</code> (default: <code>parquet-tools</code>)</li> <li><code>--ficture2</code>: Path to punkst/FICTURE repo (default: repo submodule)</li> <li><code>--aws</code>: Path to AWS CLI (default: <code>aws</code>)</li> </ul>"},{"location":"reference/run_visiumhd/#output","title":"Output","text":"<p>Outputs depend on the enabled action flags. Refer to each module page for full output details and file formats.</p> <ul> <li><code>--load-space-ranger</code>: A Space Ranger assets JSON summarizing detected inputs (path: <code>--space-ranger-assets</code>). See an example in the Visium HD pipeline vignette.</li> <li><code>--sge-convert</code>: Unified SGE files and an assets manifest (<code>sge_assets.json</code>). See details in sge_convert reference</li> <li><code>--run-ficture2</code> or <code>--import-ext-ficture2</code>: Generates FICTURE analysis artifacts (factor models, decoded maps, PMTiles, summaries). See details in run_ficture2 reference</li> <li><code>--import-cells</code>: Cells PMTiles, boundaries GeoJSON, and summaries under <code>cartload2/</code>. See details in import_cells reference.</li> <li><code>--import-squares</code>: Square-bin PMTiles plus assets JSONs per bin size (e.g., <code>&lt;square-id&gt;-sq050_assets.json</code>), including optional UMAP TSVs when provided.</li> <li><code>--import-images</code>: Background image PMTiles (and intermediates) under <code>cartload2/</code>. See details in import_images reference.</li> <li><code>--run-cartload2</code>: Sources packaged into PMTiles and a <code>catalog.yaml</code>. See details in run_cartload2 reference.</li> <li><code>--upload-aws</code>: Uploads generated assets and <code>catalog.yaml</code> to the specified S3 path.</li> <li><code>--upload-zenodo</code>: Uploads <code>catalog.yaml</code> and selected assets to Zenodo.</li> </ul>"},{"location":"reference/run_xenium/","title":"Xenium Pipeline Orchestrator","text":""},{"location":"reference/run_xenium/#overview","title":"Overview","text":"<p>An end\u2011to\u2011end workflow for 10x Xenium data using <code>CartLoader</code> to run steps (including convert inputs, run FICTURE, convert cell analysis results, convert background images, package assets, and upload for sharing) as needed.</p>"},{"location":"reference/run_xenium/#requirements","title":"Requirements","text":"<ul> <li>Xenium Ranger output</li> <li>Pre-installed tools depending on the actions: <code>spatula</code>, <code>punkst</code>, <code>gzip</code>, <code>sort</code>, <code>python</code>, <code>go-pmtiles</code>, <code>gdal</code>, <code>tippecanoe</code>, <code>parquet-tools</code>, <code>aws</code></li> </ul>"},{"location":"reference/run_xenium/#example-usages","title":"Example Usages","text":"<p>Replace placeholders</p> <p>Replace placeholder paths (e.g., <code>/path/to/xenium/ranger/output</code>) or example values (e.g., <code>example-id</code> and <code>12</code>) before execution.</p> All modules (end\u2011to\u2011end)FICTURE training + packagingPackage SGE/cells/images <p>The example below imports only the <code>OME_DAPI</code> image for illustration.</p> <pre><code>cartloader run_xenium \\\n  --load-xenium-ranger \\\n  --sge-convert \\\n  --run-ficture2 \\\n  --import-cells \\\n  --import-images \\\n  --run-cartload2 \\\n  --upload-aws \\\n  --xenium-ranger-dir /path/to/xenium/ranger/output \\\n  --out-dir /path/to/out/dir \\\n  --s3-dir s3://example_bucket/example-id \\\n  --width 12 \\\n  --n-factor 12 \\\n  --id example-id \\\n  --image-ids OME_DAPI \\\n  --spatula /path/to/spatula/binary \\\n  --ficture2 /path/to/punkst/directory \\  \n  --pmtiles /path/to/pmtiles/binary \\\n  --tippecanoe /path/to/tippecanoe/binary \\\n  --aws /path/to/aws/cli/binary \\\n  --n-jobs 10 \\\n  --threads 10\n</code></pre> <pre><code>cartloader run_xenium \\\n  --load-xenium-ranger \\\n  --sge-convert \\\n  --run-ficture2 \\\n  --run-cartload2 \\\n  --upload-aws \\\n  --xenium-ranger-dir /path/to/xenium/ranger/output \\\n  --out-dir /path/to/out/dir \\\n  --s3-dir s3://example_bucket/example-id \\\n  --width 12 \\\n  --n-factor 12 \\\n  --id example-id \\\n  --spatula /path/to/spatula/binary \\\n  --ficture2 /path/to/punkst/directory \\  \n  --pmtiles /path/to/pmtiles/binary \\\n  --tippecanoe /path/to/tippecanoe/binary \\\n  --aws /path/to/aws/cli/binary \\\n  --n-jobs 10 \\\n  --threads 10\n</code></pre> <pre><code>cartloader run_xenium \\\n  --load-xenium-ranger \\\n  --sge-convert \\\n  --import-cells \\\n  --import-images \\\n  --run-cartload2 \\\n  --upload-aws \\\n  --xenium-ranger-dir /path/to/xenium/ranger/output \\\n  --out-dir /path/to/out/dir \\\n  --s3-dir s3://example_bucket/example-id \\\n  --id example-id \\\n  --image-ids OME_DAPI \\\n  --spatula /path/to/spatula/binary \\\n  --pmtiles /path/to/pmtiles/binary \\\n  --tippecanoe /path/to/tippecanoe/binary \\\n  --aws /path/to/aws/cli/binary \\\n  --n-jobs 10 \\\n  --threads 10\n</code></pre>"},{"location":"reference/run_xenium/#action","title":"Action","text":"<p>Action Specifications</p> <p><code>run_xenium</code> orchestrates multiple <code>CartLoader</code> modules; enable and combine actions with flags.</p> <p>No action runs by default. Activate at least one action flag.</p> <p>Click to see action details per flag:</p> <ul> <li><code>--load-xenium-ranger</code></li> <li><code>--sge-convert</code></li> <li><code>--run-ficture2</code></li> <li><code>--import-cells</code></li> <li><code>--import-images</code></li> <li><code>--run-cartload2</code></li> <li><code>--upload-aws</code></li> <li><code>--upload-zenodo</code></li> </ul>"},{"location":"reference/run_xenium/#parameters","title":"Parameters","text":""},{"location":"reference/run_xenium/#action-parameters","title":"Action Parameters","text":"<p>See Action.</p>"},{"location":"reference/run_xenium/#inputoutput-parameters","title":"Input/Output Parameters","text":"<ul> <li><code>--xenium-ranger-dir</code>: Xenium Ranger output directory (required for manual mode or with <code>--load-xenium-ranger</code>)</li> <li><code>--out-dir</code>: Output root directory; writes <code>sge/</code>, <code>ficture2/</code>, <code>cartload2/</code> (required)</li> <li><code>--xenium-ranger-assets</code>: Path to assets JSON from <code>--load-xenium-ranger</code> (default: <code>&lt;out_dir&gt;/xenium_ranger_assets.json</code>)</li> <li><code>--ext-fic-dir</code>: External FICTURE directory to import when using <code>--import-ext-ficture2</code></li> </ul>"},{"location":"reference/run_xenium/#sge-convert-with-sge-convert","title":"SGE Convert (with <code>--sge-convert</code>)","text":"<ul> <li><code>--units-per-um</code>: Coordinate units per micron in raw SGE (float; default: 1.0)</li> <li><code>--filter-by-density</code>: Enable density-based filtering (bool)</li> <li><code>--exclude-feature-regex</code>: Regex for features to exclude (default: <code>^(BLANK_|DeprecatedCodeword_|NegCon|UnassignedCodeword_)</code>)</li> </ul>"},{"location":"reference/run_xenium/#ficture-with-run-ficture2","title":"FICTURE (with <code>--run-ficture2</code>)","text":"<ul> <li><code>--width</code>: Comma-separated hexagon widths in \u00b5m for train/projection (required)</li> <li><code>--n-factor</code>: Comma-separated factor counts for training (required)</li> <li><code>--colname-feature</code>: Feature column name (default: <code>gene</code>)</li> <li><code>--colname-count</code>: Count column name (default: <code>count</code>)</li> </ul>"},{"location":"reference/run_xenium/#import-cells-with-import-cells","title":"Import Cells (with <code>--import-cells</code>)","text":"<ul> <li><code>--cell-id</code>: Asset ID/prefix for cell outputs (default: <code>xeniumranger</code>)</li> <li><code>--cell-name</code>: Human-readable name (defaults to <code>--cell-id</code> if omitted)</li> <li><code>--tsv-cmap</code>: TSV colormap for cluster colors</li> </ul>"},{"location":"reference/run_xenium/#import-images-with-import-images","title":"Import Images (with <code>--import-images</code>)","text":"<ul> <li><code>--image-ids</code>: One or more image IDs to import (default: <code>DAPI_OME BOUNDARY_OME INTERIOR_RNA_OME INTERIOR_PROTEIN_OME DAPI_MIP_OME</code>)</li> <li><code>--image-colors</code>: HEX colors matching <code>--image-ids</code> order (defaults cover up to 10 images)</li> <li><code>--all-images</code>: Import all images listed in <code>--xenium-ranger-assets</code></li> <li><code>--transparent-below</code>: Make pixels below value transparent (0\u2013255; default: 1)</li> </ul>"},{"location":"reference/run_xenium/#cartload2-with-run-cartload2","title":"CartLoad2 (with <code>--run-cartload2</code>)","text":"<ul> <li><code>--id</code>: Catalog ID; no whitespace; prefer <code>-</code> (required)</li> <li><code>--title</code>: Human-readable title (quote if spaces)</li> <li><code>--desc</code>: Short description (quote if spaces)</li> </ul>"},{"location":"reference/run_xenium/#upload-with-upload-aws-upload-zenodo","title":"Upload (with <code>--upload-aws</code> / <code>--upload-zenodo</code>)","text":"<ul> <li><code>--s3-dir</code>: S3 destination, e.g., <code>s3://bucket/prefix</code> (required for AWS)</li> <li><code>--zenodo-token</code>: Path to file containing Zenodo token (required for Zenodo)</li> <li><code>--zenodo-deposition-id</code>: Existing deposition ID (omit to create new)</li> <li><code>--zenodo-title</code>: Deposition title (defaults to <code>--title</code>)</li> <li><code>--creators</code>: One or more <code>\"Lastname, Firstname\"</code> entries (each quoted)</li> </ul>"},{"location":"reference/run_xenium/#manual-input-enables-manual-mode","title":"Manual Input (enables manual mode)","text":"<ul> <li><code>--csv-transcript</code>: Transcript CSV/Parquet relative to <code>--xenium-ranger-dir</code> (used by <code>--sge-convert</code>)</li> <li><code>--csv-cells</code>: Cell locations CSV/Parquet relative to <code>--xenium-ranger-dir</code> (used by <code>--import-cells</code>)</li> <li><code>--csv-boundaries</code>: Cell boundary CSV relative to <code>--xenium-ranger-dir</code> (used by <code>--import-cells</code>)</li> <li><code>--csv-clust</code>: Cluster assignments CSV relative to <code>--xenium-ranger-dir</code> (used by <code>--import-cells</code>)</li> <li><code>--csv-diffexp</code>: Differential expression CSV relative to <code>--xenium-ranger-dir</code> (used by <code>--import-cells</code>)</li> <li><code>--ome-tifs</code>: One or more OME\u2011TIFF paths relative to <code>--xenium-ranger-dir</code> (used by <code>--import-images</code>)</li> </ul> Auxiliary Parameters"},{"location":"reference/run_xenium/#run-options","title":"Run Options","text":"<ul> <li><code>--dry-run</code>: Print commands without executing (bool; default: false)</li> <li><code>--restart</code>: Ignore existing outputs and rerun steps (bool; default: false)</li> <li><code>--n-jobs</code>, <code>-j</code>: Parallel jobs to run (int; default: 1)</li> <li><code>--threads</code>: Max threads per job, e.g., tippecanoe (int; default: 4)</li> </ul>"},{"location":"reference/run_xenium/#environment-tools","title":"Environment / Tools","text":"<ul> <li><code>--pmtiles</code>: Path to <code>pmtiles</code> binary (default: <code>pmtiles</code>)</li> <li><code>--gdal_translate</code>: Path to <code>gdal_translate</code> (default: <code>gdal_translate</code>)</li> <li><code>--gdaladdo</code>: Path to <code>gdaladdo</code> (default: <code>gdaladdo</code>)</li> <li><code>--gdalwarp</code>: Path to <code>gdalwarp</code> (default: <code>gdalwarp</code>)</li> <li><code>--tippecanoe</code>: Path to <code>tippecanoe</code> (default: repo submodule)</li> <li><code>--spatula</code>: Path to <code>spatula</code> (default: <code>spatula</code>)</li> <li><code>--parquet-tools</code>: Path to <code>parquet-tools</code> (default: <code>parquet-tools</code>)</li> <li><code>--ficture2</code>: Path to punkst/FICTURE repo (default: repo submodule)</li> <li><code>--aws</code>: Path to AWS CLI (default: <code>aws</code>)</li> </ul>"},{"location":"reference/run_xenium/#output","title":"Output","text":"<p>Outputs depend on the enabled action flags. Refer to each module page for full output details and file formats.</p> <ul> <li><code>--load-xenium-ranger</code>: A Xenium assets JSON summarizing detected inputs (path: <code>--xenium-ranger-assets</code>). See example structure in the Xenium pipeline vignette.</li> <li><code>--sge-convert</code>: Unified SGE files and an assets manifest (<code>sge_assets.json</code>). See details in sge_convert reference</li> <li><code>--run-ficture2</code> or <code>--import-ext-ficture2</code>: Generates FICTURE analysis artifacts (factor models, decoded maps, PMTiles, summaries). See details in run_ficture2 reference</li> <li><code>--import-cells</code>: Cells PMTiles, boundaries GeoJSON, and summaries under <code>cartload2/</code>. See details in import_cells reference.</li> <li><code>--import-images</code>: Background image PMTiles (and intermediates) under <code>cartload2/</code>. See details in import_images reference.</li> <li><code>--run-cartload2</code>: Sources packaged into PMTiles and a <code>catalog.yaml</code>. See details in run_cartload2 reference.</li> <li><code>--upload-aws</code>: Uploads generated assets and <code>catalog.yaml</code> to the specified S3 path.</li> <li><code>--upload-zenodo</code>: Uploads <code>catalog.yaml</code> and selected assets to Zenodo.</li> </ul> <p>See also example output in Xenium end-to-end tutorial</p>"},{"location":"reference/sge_addon/","title":"SGE Add-on Modules","text":""},{"location":"reference/sge_addon/#overview","title":"Overview","text":"<p><code>CartLoader</code> provides add-on modules to support specialized SGE preparation tasks that complement <code>sge_convert</code>:</p> <ul> <li><code>sge_orientate</code>: Rotate/flip SGE coordinates (e.g., to match image orientation).</li> <li><code>sge_stitch</code>: Stitch two or more SGE datasets into one.</li> </ul>"},{"location":"reference/sge_addon/#requirements","title":"Requirements","text":"<ul> <li>Input SGE(s) in the unified format (from SGE format conversion)</li> <li>Pre-installed tools: <code>gzip</code>, <code>spatula</code>, <code>gdal_translate</code>, <code>gdalwarp</code></li> </ul>"},{"location":"reference/sge_addon/#add-on-functions","title":"Add-on Functions","text":"Reorient SGEStitch multiple SGE datasets"},{"location":"reference/sge_addon/#reorient-sge-sge_orientate","title":"Reorient SGE (<code>sge_orientate</code>)","text":""},{"location":"reference/sge_addon/#action","title":"Action","text":"<p>Rotations are clockwise; flips are applied after rotation.</p>"},{"location":"reference/sge_addon/#example-usage","title":"Example Usage","text":"<p>Below is an example with 90\u00b0 rotation and a horizontal flip.</p> <pre><code>OUT_PREFIX=r90_hflip                # Replace r90_hflip to your prefix\ncartloader sge_orientate  \\\n    --in-transcript /path/to/transcripts.unsorted.tsv.gz \\\n    --in-feature  /path/to/feature.clean.tsv.gz \\\n    --in-minmax /path/to/coordinate_minmax.tsv \\\n    --out-transcript /path/to/${OUT_PREFIX}.transcripts.unsorted.tsv.gz \\\n    --out-feature /path/to/${OUT_PREFIX}.feature.clean.tsv.gz \\\n    --out-minmax  /path/to/${OUT_PREFIX}.coordinate_minmax.tsv \\\n    --rotate 90 \\\n    --flip-horizontal\n</code></pre>"},{"location":"reference/sge_addon/#parameters","title":"Parameters","text":""},{"location":"reference/sge_addon/#inputoutput-parameters","title":"Input/Output Parameters","text":"<ul> <li><code>--in-transcript</code> (str): Path to input transcript SGE TSV (gzipped).</li> <li><code>--in-feature</code> (str): Path to input feature TSV (gzipped).</li> <li><code>--in-minmax</code> (str): Path to input coordinate min/max TSV.</li> <li><code>--out-transcript</code> (str): Output path for oriented transcript SGE TSV (gzipped).\u00e5</li> <li><code>--out-feature</code> (str): Output path for feature TSV (copied from input).</li> <li><code>--out-minmax</code> (str): Output path for oriented min/max TSV.</li> </ul>"},{"location":"reference/sge_addon/#key-parameters","title":"Key Parameters","text":"<ul> <li><code>--rotate</code> (90|180|270): Rotate clockwise (applied before flips).</li> <li><code>--flip-vertical</code> (flag): Flip vertically (flipped along the Y\u2011axis; applied after rotation).</li> <li><code>--flip-horizontal</code> (flag): Flip horizontally (flipped along the X\u2011axis; applied after rotation).</li> <li><code>--chunk-size</code> (int, default: 1_000_000): Rows per chunk when processing the transcript TSV.</li> </ul>"},{"location":"reference/sge_addon/#output","title":"Output","text":"<p>An output SGE matrix after orientation.</p>"},{"location":"reference/sge_addon/#stitch-multiple-sge-datasets-sge_stitch","title":"Stitch multiple SGE datasets (<code>sge_stitch</code>)","text":""},{"location":"reference/sge_addon/#action_1","title":"Action","text":"<p>Stitch two or more SGE datasets into a single SGE, with optionally per\u2011tile orientation. Can also run density\u2011based filtering and quick visualization.</p>"},{"location":"reference/sge_addon/#example-usage_1","title":"Example Usage","text":"<p>Define each input tile as a CSV of paths and tile metadata:</p> <pre><code>cartloader sge_stitch \\\n--in-tiles \\\n    \"/path/to/tileA/transcripts.unsorted.tsv.gz,/path/to/tileA/feature.clean.tsv.gz,/path/to/tileA/coordinate_minmax.tsv,0,0,0,false,false\" \\\n    \"/path/to/tileB/transcripts.unsorted.tsv.gz,/path/to/tileB/feature.clean.tsv.gz,/path/to/tileB/coordinate_minmax.tsv,0,1,90,false,true\" \\\n--out-dir /path/to/output/dir \\\n--units-per-um 1.0 \\\n--precision 2 \n</code></pre>"},{"location":"reference/sge_addon/#parameters_1","title":"Parameters","text":""},{"location":"reference/sge_addon/#sge-stitch","title":"SGE Stitch","text":"<ul> <li><code>--out-dir</code> (str): Output directory for stitched (filtered) SGE, visualizations, and Makefile.</li> <li><code>--in-tiles</code> (list of str): One or more tile tuples describing each input tile.</li> </ul> <p>Input Tile Tuple Format</p> <p>Each tile tuple should provide in the following format. Recommend to quote each tuple <pre><code>\"transcript_path,feature_path,minmax_path,row,col,rotate,vertical_flip,horizontal_flip\"\n</code></pre></p> <ul> <li><code>transcript_path</code> (str): Path to the tile\u2019s transcript\u2011indexed SGE TSV.gz.</li> <li><code>feature_path</code> (str): Path to the tile\u2019s per\u2011gene UMI count TSV.gz.</li> <li><code>minmax_path</code> (str): Path to the tile\u2019s coordinate min/max TSV.</li> <li><code>row</code>, <code>col</code> (int): Integer grid indices (0\u2011based) locating the tile within the stitched mosaic (row = tile grid row, col = tile grid column).</li> <li><code>rotate</code> (int): One of <code>0</code>, <code>90</code>, <code>180</code>, <code>270</code> (clockwise rotation).</li> <li><code>vertical_flip</code>, <code>horizontal_flip</code>: Boolean flags <code>true</code>/<code>false</code> (case\u2011insensitive); flips are applied after rotation.</li> </ul> Auxiliary SGE Stitching Parameters <p>We recommend using default values; override only if needed.</p> <p>Auxiliary Output Parameters: </p> <ul> <li><code>--out-transcript</code> (str): Output transcript\u2011indexed SGE under <code>--out-dir</code> (default: <code>transcripts.unsorted.tsv.gz</code>).</li> <li><code>--out-feature</code> (str): Output per\u2011gene UMI counts under <code>--out-dir</code> (default: <code>feature.clean.tsv.gz</code>).</li> <li><code>--out-minmax</code> (str): Output coordinate min/max TSV under <code>--out-dir</code> (default: <code>coordinate_minmax.tsv</code>).</li> <li><code>--out-tile-minmax</code> (str): Output per\u2011tile min/max TSV (default: <code>coordinate_minmax_per_tile.tsv</code>).</li> <li><code>--out-json</code> (str): Output JSON summarizing SGE assets (default: <code>&lt;out-dir&gt;/sge_assets.json</code>).</li> </ul> <p>Auxiliary Colname Parameters: </p> <ul> <li><code>--colname-count</code> (str): Column name of the UMI count (default: count), </li> <li><code>--colname-feature-name</code> (str): Column name of feature name, typically gene (default: gene), </li> <li><code>--colname-x</code> (str): Column name of X coordinates (default: X), </li> <li><code>--colname-y</code> (str): Column name of Y coordinates (default: Y), </li> <li><code>--colnames-others</code> (list): Column names of other information to keep .</li> </ul> <p>Auxiliary Scale and Precision Parameters: </p> <ul> <li><code>--units-per-um</code> (float): Coordinate units per \u00b5m for global transform (default: 1.0). If input SGE is generated by <code>sge_convert</code>, use the default value.</li> <li><code>--precision</code> (int): Decimal precision for stitched coordinates (default: 2).</li> </ul>"},{"location":"reference/sge_addon/#densitybased-filtering","title":"Density\u2011based Filtering","text":"<ul> <li><code>--filter-by-density</code> (flag): Enable SGE filtering by density.</li> <li><code>--out-filtered-prefix</code> (str): Prefix for output filtered SGE files (default: filtered).</li> </ul> Auxiliary Density\u2011based Filtering Parameters <p>We recommend using default values; override only if needed.</p> <ul> <li><code>--radius</code> (int): Radius for the polygon area calculation (default: 15).</li> <li><code>--quartile</code> (int): Quartile for the polygon area calculation (default: 2).</li> <li><code>--hex-n-move</code> (int): Sliding step (default: 1).</li> <li><code>--polygon-min-size</code> (int): Minimum polygon size (default: 500).</li> </ul>"},{"location":"reference/sge_addon/#sge-visualization","title":"SGE Visualization","text":"<ul> <li><code>--sge-visual</code> (flag): Enable SGE visualization.</li> <li><code>--north-up</code> (flag): Enable north\u2011up orientation for the SGE visualization.</li> </ul> Auxiliary SGE Visualization Parameters <p>We recommend using default values; override only if needed.</p> <ul> <li><code>--out-xy</code> (str): File name for output SGE visualization image (default: <code>xy.png</code>).</li> <li><code>--out-northup-tif</code> (str): File name for output north\u2011up oriented image (default: <code>xy_northup.tif</code>).</li> <li><code>--srs</code> (str): Spatial reference system (used with <code>--north-up</code>; default: EPSG:3857).</li> <li><code>--resample</code> (str): Resampling method (used with <code>--north-up</code>; options: near, bilinear, cubic, etc.; default: cubic).</li> <li><code>--gdal_translate</code> (str): Path to <code>gdal_translate</code> binary (used with <code>--north-up</code>; default: <code>gdal_translate</code>)</li> <li><code>--gdalwarp</code> (str): Path to <code>gdalwarp</code> binary (used with <code>--north-up</code>; default: <code>gdalwarp</code>)</li> </ul>"},{"location":"reference/sge_addon/#environment-parameters","title":"Environment Parameters","text":"<ul> <li><code>--gzip</code> (str): Path to gzip binary (default: gzip).</li> <li><code>--spatula</code> (str): Path to spatula binary (default: spatula).</li> </ul>"},{"location":"reference/sge_addon/#output_1","title":"Output","text":"<p>An SGE matrix consisting of all input SGE and in a specific layout. In addition:</p> <ul> <li>If <code>--filter-by-density</code> is enabled, a polygon-based filtered SGE matrix will be created from the stitched SGE.</li> <li>If <code>--sge-visual</code> is enabled, a monochrome PNG image is generated to visualize the stitched SGE.</li> <li>If <code>--north-up</code> is enabled, a georeferenced TIFF image is produced with a north-up orientation.</li> </ul>"},{"location":"reference/sge_convert/","title":"Spatial Gene Expression Format Conversion","text":""},{"location":"reference/sge_convert/#overview","title":"Overview","text":"<p>SGE datasets vary widely in format and resolution across platforms. Since <code>FICTURE</code> requires SGE in a specific format, <code>CartLoader</code> toolkit provides the <code>sge_convert</code> module to standardize raw, platform-specific SGE into a FICTURE-compatible format.</p>"},{"location":"reference/sge_convert/#requirements","title":"Requirements","text":"<p>Input Data Requirements</p> <p>Ensure the input data (raw, platform\u2011specific SGE) is transcript\u2011indexed and contains at least the following fields:</p> <ul> <li>Spatial coordinates (X, Y)</li> <li>Feature metadata (such as gene symbols)</li> <li>Expression counts</li> </ul> <p>Platform Compatibility</p> <p>The current <code>sge_convert</code> supports standardizing SGE from the following platforms:</p> Source <code>--platform</code> Option Required Input Files 10x Visium HD <code>10x_visium_hd</code> <code>--in-mex</code>, <code>--pos-parquet</code>, <code>--scale-json</code> Seq-Scope <code>seqscope</code> <code>--in-mex</code> 10x Xenium <code>10x_xenium</code> <code>--in-csv</code> (common); <code>--in-parquet</code> also supported. Stereo-seq <code>bgi_stereoseq</code> <code>--in-csv</code> CosMx SMI <code>cosmx_smi</code> <code>--in-csv</code> Vizgen MERSCOPE <code>vizgen_merscope</code> <code>--in-csv</code> Pixel-seq <code>pixel_seq</code> <code>--in-csv</code> Nova-ST <code>nova_st</code> <code>--in-csv</code> Generic CSV/TSV input <sup>1</sup> <code>generic</code> <code>--in-csv</code> <p><sub><sup>1</sup>: For SGE from platforms not yet explicitly supported by <code>CartLoader</code>, or from custom/preprocessed sources, <code>sge_convert</code> provides a <code>generic</code> option that accepts CSV/TSV files with basic required fields (e.g., gene, spatial coordinates, expression count) for standardization and processing. <p>Pre-installed tools</p> <ul> <li><code>gzip</code> (or pigz)</li> <li><code>spatula</code> (required if <code>--sge-visual</code> is set)</li> <li><code>gdal_translate</code>, <code>gdalwarp</code> (required if <code>--sge-visual</code> is set with <code>--north-up</code>)</li> </ul>"},{"location":"reference/sge_convert/#example-usage","title":"Example Usage","text":""},{"location":"reference/sge_convert/#1-input-sge-in-mex-format","title":"1) Input SGE in MEX Format","text":""},{"location":"reference/sge_convert/#11-seq-scope","title":"1.1) Seq-Scope","text":"<pre><code>cartloader sge_convert \\\n    --platform seqscope \\\n    --in-mex /path/to/input/dir/of/mex \\   \n    --units-per-um 1000 \\\n    --icols-mtx 1 \\\n    --out-dir /path/to/output/dir \\\n    --colnames-count count \\\n    --filter-by-density \\\n    --out-filtered-prefix filtered \\\n    --genomic-feature count \\\n    --sge-visual \\\n    --north-up \\\n    --spatula /path/to/spatula/binary \n</code></pre>"},{"location":"reference/sge_convert/#12-10x-visium-hd","title":"1.2) 10x Visium HD","text":"<pre><code>cartloader sge_convert \\\n    --platform 10x_visium_hd \\\n    --in-mex /path/to/input/dir/of/mex \\   \n    --in-parquet /path/to/input/parquet/file \\\n    --scale-json /path/to/input/json/file \\\n    --exclude-feature-regex '^(BLANK.*$|NegCon.*$|NegPrb.*$)' \\\n    --out-dir /path/to/output/dir \\\n    --spatula /path/to/spatula/binary \\\n    --sge-visual \n</code></pre>"},{"location":"reference/sge_convert/#2-input-sge-in-tsvcsv-format","title":"2) Input SGE in TSV/CSV Format","text":"<p>This applies to input SGE in TSV/CSV format from platforms. Below is an example converting SGE from Stere-seq.</p> <pre><code>cartloader sge_convert \\\n    --platform bgi_stereoseq \\\n    --in-csv /path/to/input/csv/file \\\n    --units-per-um 28.75 \\\n    --out-dir /path/to/output/dir \\\n    --colnames-count count \\\n    --exclude-feature-regex '^(BLANK.*$|NegCon.*$|NegPrb.*$)' \\\n    --filter-by-density \\\n    --out-filtered-prefix filtered \\\n    --genomic-feature count \\\n    --sge-visual \\\n    --north-up \\\n    --spatula /path/to/spatula/binary \n</code></pre> <p>Verify Your Input Structure</p> <p>Always double-check the column names and metadata format of your input files. If they differ from the expected defaults, override them using <code>--csv-*</code> and <code>--min-phred-score</code> options.</p> <p>Platform-specific Default Settings</p> <p>To streamline the process, <code>sge_convert</code> automatically applies platform\u2011dependent defaults for CSV/TSV parsing based on known file formats and column conventions. Below summarizes the default values for key parameters per supported platform:</p> Platform <code>--csv-comment</code><sup>1</sup> <code>--csv-delim</code> <code>--csv-colname-x</code> <code>--csv-colname-y</code> <code>--csv-colnames-count</code> <code>--csv-colname-feature-name</code> 10x Xenium<sup>2</sup> <code>False</code> <code>,</code> <code>x_location</code> <code>y_location</code> - <code>feature_name</code> StereoSeq <code>False</code> <code>\\t</code> <code>x</code> <code>y</code> <code>MIDCounts</code> <code>geneID</code> CosMx SMI <code>False</code> <code>,</code> <code>x_local_px</code> <code>y_local_px</code> - <code>target</code> MERSCOPE <code>False</code> <code>,</code> <code>global_x</code> <code>global_y</code> - <code>gene</code> Pixel-seq <code>False</code> <code>\\t</code> <code>xcoord</code> <code>ycoord</code> - <code>geneName</code> <p><sub><sup>1</sup> <code>--csv-comment</code>: If <code>True</code>, the lines starts with <code>#</code> will be treated as comments and will be skipped. <p><sub><sup>2</sup> 10x Xenium: Besides the above default settings, for 10x Xenium data, <code>sge_convert</code> also applies <code>--csv-colname-phredscore qv</code> and <code>--min-phred-score 20</code>."},{"location":"reference/sge_convert/#actions","title":"Actions","text":"<p>Action Specifications</p> <p>SGE conversion runs by default. If needed, activate other options: <code>--filter-by-density</code> and <code>--sge-visual</code>.</p>"},{"location":"reference/sge_convert/#sge-conversion-always-runs","title":"SGE Conversion (always runs)","text":"<p>Converting SGE into a FICTURE-compatible TSV format. During conversion, SGE coordinates are rescaled to micrometer units based on the pixel resolution specified in the input. It's also available to apply feature (typically, genes) filtering.</p>"},{"location":"reference/sge_convert/#density-based-filtering-filter-by-density","title":"Density-based Filtering (<code>--filter-by-density</code>)","text":"<p>If <code>--filter-by-density</code> is set, automatically identify and retain high-quality tissue regions based on transcript density and spatial structure. This step takes the format-standardized SGE as input and generate a density-based filtered SGE.</p>"},{"location":"reference/sge_convert/#sge-visualization-sge-visual","title":"SGE Visualization (<code>--sge-visual</code>)","text":"<p>If <code>--sge-visual</code> is set, draws an image of 2D points provided as an input. In this step, it is optional to enable the <code>--north-up</code> option to ensuring correct spatial orientation (i.e., Y-axis increases upward/north and X-axis increases to the right/east).</p>"},{"location":"reference/sge_convert/#parameters","title":"Parameters","text":"<p>Below are the core parameters. See more details in the collapsible sections below.</p>"},{"location":"reference/sge_convert/#sge-conversion","title":"SGE Conversion","text":"<ul> <li><code>--platform</code> (str): Source platform to infer input format and defaults. Options: <code>10x_visium_hd</code>, <code>seqscope</code>, <code>10x_xenium</code>, <code>bgi_stereoseq</code>, <code>cosmx_smi</code>, <code>vizgen_merscope</code>, <code>pixel_seq</code>, <code>nova_st</code>, <code>generic</code>.</li> <li><code>--in-json</code> (str): Input manifest JSON. If set, can skip <code>--in-mex/--in-parquet/--in-csv/--pos-parquet/--scale-json</code> (platforms: 10x_xenium, 10x_visium_hd).</li> <li><code>--in-mex</code> (str): Path to input MEX directory (platforms: 10x Visium HD, SeqScope).</li> <li><code>--in-csv</code> (str): Path to input CSV/TSV (platforms: 10x Xenium, BGI Stereo\u2011seq, CosMx SMI, Vizgen MERSCOPE, Pixel\u2011seq, Nova\u2011ST, generic).</li> <li><code>--in-parquet</code> (str): Path to input transcript parquet (platform: 10x Xenium).</li> <li><code>--pos-parquet</code> (str): Path to position parquet with spatial coordinates (platform: 10x Visium HD; typical: <code>tissue_positions.parquet</code>).</li> <li><code>--scale-json</code> (str): Path to scale JSON; if set, derives <code>--units-per-um</code> from <code>microns_per_pixel</code> (platform: 10x Visium HD; typical: <code>scalefactors_json.json</code>).</li> <li><code>--units-per-um</code> (float): Coordinate units per \u00b5m (default: 1.00). Prefer <code>--scale-json</code> for 10x Visium HD.</li> <li><code>--out-dir</code> (str): Output directory.</li> <li><code>--include-feature-regex</code> (regex): Regex of feature/gene names to include.</li> <li><code>--exclude-feature-regex</code> (regex): Regex of feature/gene names to exclude.</li> </ul> Auxiliary SGE Conversion Paramaters <p>Recommend to use the default values; override only if needed. See more details by running: <pre><code>CartLoadersge_convert --help\n</code></pre></p> <p>Auxiliary Input MEX Parameters:</p> <ul> <li><code>--icols-mtx</code> (int or comma-spearated list): Comma-separated, 1-based indices of the target genomic features among the count columns in the input matrix file (default: 1)</li> <li><code>--colnames-count</code> (string or comma-spearated list): Comma-separated output column names for the specified genomic features (default: count). The number of names specified by <code>--colnames-count</code> must match the number of indices provided in <code>--icols-mtx</code>.</li> </ul> <p>Auxiliary Input CSV/TSV Parameters:</p> <ul> <li><code>--csv-comment</code> (flag): If enabled, lines starting with <code>#</code> are skipped (default: <code>False</code> for 10x Xenium, Stereo\u2011seq, CosMx SMI, MERSCOPE, and Pixel\u2011seq).</li> <li><code>--csv-delim</code> (str): Delimiter for the input file (default: <code>\",\"</code> for 10x Xenium, CosMx SMI, and MERSCOPE; <code>\"\\t\"</code> for Stereo\u2011seq, Pixel\u2011seq).</li> <li><code>--csv-colname-x</code> (str): Column name for X coordinates (default: <code>x_location</code> for 10x Xenium; <code>x</code> for Stereo\u2011seq; <code>x_local_px</code> for CosMx SMI; <code>global_x</code> for MERSCOPE; <code>xcoord</code> for Pixel\u2011seq).</li> <li><code>--csv-colname-y</code> (str): Column name for Y coordinates (default: <code>y_location</code> for 10x Xenium; <code>y</code> for Stereo\u2011seq; <code>y_local_px</code> for CosMx SMI; <code>global_y</code> for MERSCOPE; <code>ycoord</code> for Pixel\u2011seq).</li> <li><code>--csv-colnames-count</code> (str): Comma\u2011separated column names for expression count. If not provided, defaults to a count of 1 per transcript (default: <code>MIDCounts</code> for Stereo\u2011seq).</li> <li><code>--csv-colname-feature-name</code> (str): Column name for gene name (default: <code>feature_name</code> for 10x Xenium; <code>geneID</code> for Stereo\u2011seq; <code>target</code> for CosMx SMI; <code>gene</code> for MERSCOPE; <code>geneName</code> for Pixel\u2011seq).</li> <li><code>--csv-colnames-others</code> (str): Column names to keep.</li> <li><code>--csv-colname-phredscore</code> (str): Column name for Phred\u2011scaled quality value estimating the probability of incorrect calls (default: <code>qv</code> for 10x Xenium).</li> <li><code>--min-phred-score</code> (float): Minimum Q-score to retain a transcript.<ul> <li>Default for <code>10x_xenium</code>: 20.0</li> <li>Default for others: 0.0</li> </ul> </li> </ul> <p>Auxiliary Output Parameters: </p> <ul> <li><code>--out-transcript</code> (str): File name for output compressed transcript-indexed SGE file in TSV format (default: <code>transcripts.unsorted.tsv.gz</code>).</li> <li><code>--out-minmax</code> (str): File name for coordinate min\u2013max values in TSV format (default: <code>coordinate_minmax.tsv</code>).</li> <li><code>--out-feature</code> (str): File name for compressed UMI count per gene in TSV format (default: <code>feature.clean.tsv.gz</code>).</li> <li><code>--precision-um</code> (int): Decimal precision for transcript coordinates; set to <code>0</code> to round to integers (default: 2).</li> <li><code>--colname-x</code> (str): Column name for the X-coordinate in the output SGE (default: X).</li> <li><code>--colname-y</code> (str): Column name for the Y-coordinate in the output SGE (default: Y).</li> <li><code>--colname-count</code> (str): Comma\u2011separated column names for count in the output SGE (default: count).</li> <li><code>--colname-feature-name</code> (str): Column name for the gene name in the output SGE (default: gene).</li> <li><code>--out-json</code> (str): Output JSON manifest of SGE paths (default: <code>&lt;out-dir&gt;/sge_assets.json</code>).</li> </ul> <p>Environment Parameters If the binaries are already available in your system's <code>PATH</code>, you may omit these options.</p> <ul> <li><code>--gzip</code> (str): Path to <code>gzip</code> binary (default: <code>gzip</code>).</li> <li><code>--pigz</code> (str): Path to <code>pigz</code> binary for parallel gzip compression (default: <code>pigz</code>).</li> <li><code>--pigz-threads</code> (int): Number of threads for <code>pigz</code> (default: 4).</li> <li><code>--spatula</code> (str): Path to <code>spatula</code> binary (default: <code>spatula</code>)</li> <li><code>--parquet-tools</code> (str): Path to <code>parquet-tools</code> binary (used with --in-parquet or --pos-parquet; default: <code>parquet-tools</code>)</li> </ul> <p>Run Parameters:</p> <ul> <li><code>--dry-run</code> (flag): Generate the Makefile; do not execute.</li> <li><code>--restart</code> (flag): Ignore existing outputs and rerun all steps.</li> <li><code>--makefn</code> (str): Makefile name to write (default: <code>sge_convert.mk</code>).</li> <li><code>--n-jobs</code> (int): Number of parallel jobs (default: 1).</li> </ul>"},{"location":"reference/sge_convert/#densitybased-filtering","title":"Density\u2011based Filtering","text":"<ul> <li><code>--filter-by-density</code> (flag): Enable SGE filtering by density.</li> <li><code>--out-filtered-prefix</code> (str): Prefix for output filtered SGE files (default: filtered).</li> </ul> Auxiliary Density\u2011based Filtering Parameters <p>We recommend using default values; override only if needed.</p> <ul> <li><code>--radius</code> (int): Radius for the polygon area calculation (default: 15).</li> <li><code>--quartile</code> (int): Quartile for the polygon area calculation (default: 2).</li> <li><code>--hex-n-move</code> (int): Sliding step (default: 1).</li> <li><code>--polygon-min-size</code> (int): Minimum polygon size (default: 500).</li> </ul>"},{"location":"reference/sge_convert/#sge-visualization","title":"SGE Visualization","text":"<ul> <li><code>--sge-visual</code> (flag): Enable SGE visualization.</li> <li><code>--north-up</code> (flag): Enable north\u2011up orientation for the SGE visualization.</li> </ul> Auxiliary SGE Visualization Parameters <p>We recommend using default values; override only if needed.</p> <ul> <li><code>--out-xy</code> (str): File name for output SGE visualization image (default: <code>xy.png</code>).</li> <li><code>--out-northup-tif</code> (str): File name for output north\u2011up oriented image (default: <code>xy_northup.tif</code>).</li> <li><code>--srs</code> (str): Spatial reference system (used with <code>--north-up</code>; default: EPSG:3857).</li> <li><code>--resample</code> (str): Resampling method (used with <code>--north-up</code>; options: near, bilinear, cubic, etc.; default: cubic).</li> <li><code>--gdal_translate</code> (str): Path to <code>gdal_translate</code> binary (used with <code>--north-up</code>; default: <code>gdal_translate</code>)</li> <li><code>--gdalwarp</code> (str): Path to <code>gdalwarp</code> binary (used with <code>--north-up</code>; default: <code>gdalwarp</code>)</li> </ul>"},{"location":"reference/sge_convert/#output","title":"Output","text":"<p><code>CartLoader</code> generates the following harmonized outputs:</p>"},{"location":"reference/sge_convert/#unified-sge-matrix","title":"Unified SGE matrix","text":"<p>Both SGE conversion and density-based filtering generate a unified SGE matrix, consisting of:</p> <code>transcripts.unsorted.tsv.gz</code>: transcript-indexed SGE in TSV <pre><code>X        Y        gene     count\n295.29   1422.35  Myo3a    0\n1745.54  1110.72  Med14    1\n1745.54  1110.72  Ntpcr    1\n</code></pre> <ul> <li><code>X</code>: X coordinates in um</li> <li><code>Y</code>: Y coordinates in um</li> <li><code>gene</code>: gene symbols</li> <li><code>count</code>: expression count per pixel per gene</li> </ul> <code>feature.clean.tsv.gz</code>: UMI counts on a per-gene basis in TSV <p><pre><code>gene           gene_id             count\nGm29155        ENSMUSG00000100764  1\nPcmtd1         ENSMUSG00000051285  431\nGm26901        ENSMUSG00000097797  1\n</code></pre> * <code>gene</code>: gene symbols * <code>gene_id</code>: gene IDs * <code>count</code>: expression count per gene</p> <code>coordinate_minmax.tsv</code>: X Y min/max coordinates <pre><code>xmin    0.14\nxmax    2359.90\nymin    0.23\nymax    1439.95\n</code></pre> <ul> <li><code>xmin</code> <code>xmax</code>: min and max X coordinates in um</li> <li><code>ymin</code> <code>ymax</code>: min and max Y coordinates in um</li> </ul>"},{"location":"reference/sge_convert/#sge-images","title":"SGE Images","text":"<ul> <li>When <code>--sge-visual</code> is enabled, a monochrome PNG image is generated to visualize the SGE data.</li> <li>When <code>--north-up</code> is enabled, a georeferenced TIFF image is produced with a north-up orientation.</li> </ul>"},{"location":"reference/upload_aws/","title":"Upload to AWS S3","text":""},{"location":"reference/upload_aws/#overview","title":"Overview","text":"<p>Use <code>upload_aws</code> to publish <code>CartLoader</code> outputs (PMTiles, decoded spatial factors, and the catalog) to Amazon S3 for sharing or deployment. Supports single\u2011dataset uploads and collection uploads (multiple datasets via <code>--in-list</code>). File lists are taken from <code>catalog.yaml</code> and split into cartload basics (required outputs), cartload optional files (e.g., UMAP, alias), and additional basemaps (non-SGE PMTiles).</p>"},{"location":"reference/upload_aws/#action","title":"Action","text":"<p>Upload <code>CartLoader</code> outputs (including <code>catalog.yaml</code>) to a specified S3 path for a single dataset or a collection (<code>--in-list</code>).</p>"},{"location":"reference/upload_aws/#requirements","title":"Requirements","text":"<ul> <li>A completed run of <code>run_cartload2</code> or <code>run_cartload2_multi</code>, which include:<ul> <li>Rasterized SGE tiles</li> <li>(Optional) Decoded spatial factor maps</li> <li>(Optional) Joined molecule-factor outputs</li> <li>(Optional) Cell assets</li> <li>(Optional) Background assets, such as histology</li> <li>A catalog file (<code>catalog.yaml</code>) summarizing the output structure and metadata</li> </ul> </li> <li>AWS CLI installed and configured (e.g., <code>aws configure</code>).</li> </ul>"},{"location":"reference/upload_aws/#example-usage","title":"Example Usage","text":"Single Dataset UploadCollection Upload (Multiple Datasets) <pre><code>AWS_DIR=\"s3://example/aws/prefix\"   # S3 prefix that will contain the dataset\nDATA_ID=\"EXAMPLE_ID\"                # dataset identifier\n\ncartloader upload_aws \\\n  --in-dir /path/to/cartload2/output \\\n  --s3-dir \"${AWS_DIR}/${DATA_ID}\" \\\n  --n-jobs 10\n</code></pre> <pre><code>AWS_DIR=\"s3://example/aws/prefix\"        # S3 prefix that will contain the collection\nCOLLECTION_ID=\"EXAMPLE_COLLECTION_ID\"    # collection identifier\nIN_LIST=/path/to/samples.tsv             # one sample ID per line; no header\ncartloader upload_aws \\\n  --in-dir /path/to/parent_cartload_outputs \\\n  --s3-dir \"${AWS_DIR}/${COLLECTION_ID}\" \\\n  --in-list ${IN_LIST} \\\n  --n-jobs 10\n</code></pre> <p>Collection Structure</p> <p>The examples below show input and S3 output layouts for a collection upload.</p> <p>Input Collection</p> <ul> <li>Generated by <code>cartloader run_cartload2_multi</code>.</li> <li><code>--in-dir</code> is a parent directory containing one subdirectory per sample.</li> <li>Each subdirectory must include its own <code>catalog.yaml</code>.</li> </ul> <pre><code>/path/to/parent_cartload_outputs/   # defined by `--in-dir`\n\u251c\u2500\u2500 SAMPLE_001      # SAMPLE 1; sample ID appears in `--in-list`\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 catalog.yaml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ...         # SGE assets (e.g., genes_all.pmtiles)\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ...         # FICTURE assets (e.g., *-model.tsv, *-pseudobulk.tsv.gz, *-bulk-de.tsv, *-info.tsv, *.pmtiles, *rgb.tsv)\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ...         # Background assets (e.g., from `cartloader import_image`)\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 ...         # Cell assets (e.g., from `import_*_cell`)\n\u251c\u2500\u2500 SAMPLE_002      # SAMPLE 2\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 ...         \n\u251c\u2500\u2500 SAMPLE_003      # SAMPLE 3\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 ...   \n\u2514\u2500\u2500 SAMPLE_004      # SAMPLE 4\n\u00a0\u00a0 \u2514\u2500\u2500 ...   \n</code></pre> <p>Output S3 Collection</p> <ul> <li><code>--s3-dir</code> is the collection prefix (e.g., <code>s3://bucket/collection-id</code>).</li> <li>Each dataset uploads to a subdirectory under that prefix: <code>.../&lt;s3_id&gt;/</code>.</li> <li>Subdirectory naming: use <code>catalog.yaml:id</code> when available; otherwise lowercase the sample ID from <code>--in-list</code> and replace underscores with hyphens.</li> </ul> <pre><code>/path/to/parent_s3_directory/   # defined by `--s3-dir` (often the collection ID)\n\u251c\u2500\u2500 sample-001      # SAMPLE 1; `&lt;s3_id&gt;` from catalog `id`, else lowercased sample ID with underscores \u2192 hyphens\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 catalog.yaml\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 ...         # \n\u251c\u2500\u2500 sample-002      # SAMPLE 2\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 ...         \n\u251c\u2500\u2500 sample-003      # SAMPLE 3\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 ...   \n\u2514\u2500\u2500 sample-004      # SAMPLE 4\n\u00a0\u00a0 \u2514\u2500\u2500 ...   \n</code></pre>"},{"location":"reference/upload_aws/#parameters","title":"Parameters","text":""},{"location":"reference/upload_aws/#inputoutput","title":"Input/Output","text":"<ul> <li><code>--in-dir</code> (str): Input dir (single) or parent dir with per-sample subdirs (collection).</li> <li><code>--catalog-yaml</code> (str): Path to catalog.yaml (single mode only; default: <code>&lt;in_dir&gt;/catalog.yaml</code>; not valid with <code>--in-list</code>).</li> <li><code>--upload-basics-only</code> (flag): Upload only cartload-generated basic files (skip optional and additional basemaps).</li> <li><code>--upload-optional-only</code> (flag): Upload only cartload-generated optional files, such as UMAP and alias (skip basics and basemaps).</li> <li><code>--upload-basemap-only</code> (flag): Upload only additional basemap PMTiles (skip basics and optionals).</li> </ul>"},{"location":"reference/upload_aws/#collection-parameters","title":"Collection Parameters","text":"<ul> <li><code>--in-list</code> (str): TSV of sample IDs (no header); enables collection mode. Use the same TSV you pass as <code>--in-list</code> to <code>run_ficture2_multi</code> and <code>run_cartload2_multi</code>.</li> </ul>"},{"location":"reference/upload_aws/#aws-configuration","title":"AWS Configuration","text":"<ul> <li><code>--s3-dir</code> (str): S3 destination (single) or parent prefix for per-sample outputs (collection).</li> <li><code>--aws</code> (str): aws CLI executable (default: <code>aws</code>).</li> </ul>"},{"location":"reference/upload_aws/#run-parameters","title":"Run Parameters","text":"<ul> <li><code>--dry-run</code> (flag): Generate the Makefile; do not execute.</li> <li><code>--restart</code> (flag): Ignore existing outputs and rerun from scratch.</li> <li><code>--n-jobs</code> (int): Number of parallel jobs (default: 2).</li> <li><code>--makefn</code> (str): Name of the generated Makefile (default: <code>upload_aws.mk</code>, written inside <code>--in-dir</code>).</li> </ul>"},{"location":"reference/upload_zenodo/","title":"Upload to Zenodo","text":""},{"location":"reference/upload_zenodo/#overview","title":"Overview","text":"<p>Use <code>upload_zenodo</code> to publish <code>CartLoader</code> outputs \u2014 including PMTiles, decoded spatial factors, and the catalog \u2014 to a Zenodo deposition, either an existing one or a newly created draft. In catalog mode, files are pulled from <code>catalog.yaml</code> and grouped into cartload basics, cartload optional files (e.g., UMAP, alias), and additional basemaps (non-SGE PMTiles).</p>"},{"location":"reference/upload_zenodo/#action","title":"Action","text":"<p>Upload selected files to a Zenodo deposition (existing or new) using <code>all</code>, <code>catalog</code>, or <code>files</code> selection modes.</p>"},{"location":"reference/upload_zenodo/#requirements","title":"Requirements","text":"<ul> <li>A completed run of <code>run_cartload2</code>, which produces:<ul> <li>Rasterized SGE tiles</li> <li>(Optional) Decoded spatial factor maps</li> <li>(Optional) Joined molecule-factor outputs</li> <li>(Optional) Cell assets</li> <li>(Optional) Background assets, such as histology</li> <li>A catalog file (<code>catalog.yaml</code>) summarizing the output structure and metadata</li> </ul> </li> <li>A Zenodo access token saved in a file (for API authentication).</li> <li>(Optional) A Zenodo deposition ID to upload to an existing deposition.</li> </ul>"},{"location":"reference/upload_zenodo/#behavior-highlights","title":"Behavior Highlights","text":"<ul> <li>If <code>--zenodo-deposition-id</code> points to a published record, a new draft version is created automatically before upload; drafts are reused as-is.</li> <li>When a deposition already has metadata, provided flags override specific fields and the metadata is updated before uploading files.</li> <li><code>--upload-method catalog</code> uploads cartload basics first, then basemaps, then optional files. A <code>cartload.zenodo.done</code> marker is written after basics succeed.</li> <li>Existing files are skipped by default; add <code>--restart</code> to re-upload overlapping files. <code>--dry-run</code> lists actions without uploading. Upload aborts if the expected total file count exceeds Zenodo\u2019s limit (100).</li> </ul> <p>What are the Zenodo token and deposition ID, and how do you get them?</p> <p>Zenodo Token File</p> <p><code>CartLoader</code> uses the Zenodo API for uploading files. To authenticate, Zenodo requires an access token.</p> <p>To obtain a token for use with <code>CartLoader</code>:</p> <ol> <li>Log in to Zenodo.</li> <li>Go to your applications page.</li> <li>Click \"New Token\" and select appropriate scopes (e.g., <code>deposit:write</code>, <code>deposit:actions</code>).</li> <li>Copy the generated token.</li> <li>Save the token in a plain text file and pass the file path to <code>--zenodo-token</code> when running <code>CartLoader</code>.</li> </ol> <p>Zenodo Deposition ID</p> <p>A deposition ID is a unique numeric identifier assigned to a deposition (i.e., a dataset record) you create on Zenodo. This ID specifies where your uploaded files will be stored. If you\u2019ve already created a deposition, you can find its ID at the end of the URL. For example: <pre><code>https://zenodo.org/deposit/1234567\n                                    \u2191\n                            This is the deposition ID\n</code></pre></p>"},{"location":"reference/upload_zenodo/#example-usage","title":"Example Usage","text":"Upload to an existing depositionCreate a new deposition to uploadUpload explicit files <pre><code>zenodo_deposition_id=DEPOSITION_ID                # replace with your deposition ID (published IDs get a new draft automatically)\n\ncartloader upload_zenodo \\\n  --upload-method catalog \\\n  --in-dir /path/to/run_cartload2/output/directory \\\n  --zenodo-token /path/to/zenodo_token.txt \\\n  --zenodo-deposition-id ${zenodo_deposition_id}\n</code></pre> <p>Recommended: provide metadata.</p> <pre><code>cartloader upload_zenodo \\\n  --upload-method catalog \\\n  --in-dir /path/to/run_cartload2/output/directory \\\n  --zenodo-token /path/to/zenodo_token.txt \\\n  --title  \"Title Info\" \\\n  --creators \"Creator Name\" \\\n  --description \"Description Info\"\n</code></pre> <pre><code>cartloader upload_zenodo \\\n  --upload-method files \\\n  --in-dir /path/to/run_cartload2/output/directory \\\n  --files catalog.yaml genes_all.pmtiles some_factor.pmtiles \\\n  --zenodo-token /path/to/zenodo_token.txt \\\n  --zenodo-deposition-id ${zenodo_deposition_id}\n</code></pre>"},{"location":"reference/upload_zenodo/#parameters","title":"Parameters","text":""},{"location":"reference/upload_zenodo/#input-selection","title":"Input Selection","text":"<ul> <li><code>--in-dir</code> (str): Path to the directory containing <code>run_cartload2</code> outputs.</li> <li> <p><code>--upload-method</code> (str, default: <code>all</code>): Which files to upload. </p> <p><code>--upload-method</code> Options</p> <ul> <li><code>all</code>: Upload every file in <code>--in-dir</code>,</li> <li><code>catalog</code>: Upload files listed in a <code>catalog.yaml</code>,</li> <li><code>files</code>: Upload only the filenames provided via <code>--files</code>.</li> </ul> </li> <li> <p><code>--files FILE [FILE ...]</code>: Filenames to upload (relative to <code>--in-dir</code> or absolute). Use with <code>--upload-method files</code>.</p> </li> <li><code>--catalog-yaml</code> (str): Path to a <code>catalog.yaml</code>. Required if <code>--upload-method catalog</code>. If omitted, uses <code>&lt;in-dir&gt;/catalog.yaml</code>.</li> </ul>"},{"location":"reference/upload_zenodo/#zenodo-configuration","title":"Zenodo Configuration","text":"<ul> <li><code>--zenodo-token</code> (str): Path to your Zenodo access token file.</li> <li><code>--zenodo-deposition-id</code> (str): Zenodo deposition ID to upload files to. If the ID is for a published deposition, a new draft version is created automatically. If omitted, a new draft deposition is created. </li> <li><code>--publish</code> (flag): Publish the deposition automatically after upload. Recommended to publish manually after reviewing via the Zenodo web interface.</li> </ul>"},{"location":"reference/upload_zenodo/#zenodo-metadata","title":"Zenodo Metadata","text":"<ul> <li><code>--title</code> (str): Title for Zenodo deposition. Required only when creating a new deposition (i.e., if <code>--zenodo-deposition-id</code> is not provided or the existing deposition lacks these fields).</li> <li><code>--upload-type</code> (str, default: dataset): One of: dataset, software, publication, poster, presentation, image, video, lesson, other.</li> <li><code>--creators</code> (list of str): Creators in \"Lastname, Firstname\" format.</li> </ul>"},{"location":"reference/upload_zenodo/#behavior-flags","title":"Behavior Flags","text":"<ul> <li><code>--dry-run</code> (flag): Simulate and print operations; do not execute uploads.</li> <li><code>--restart</code> (flag): Re-upload overlapping files instead of skipping existing ones.</li> </ul>"},{"location":"reference/visiumhd_addon/","title":"Visium HD Pipeline Add-ons Modules","text":""},{"location":"reference/visiumhd_addon/#overview","title":"Overview","text":"<p><code>CartLoader</code> provides add-on modules to support Visium HD pipeline orchestrator:</p> <ul> <li><code>load_space_ranger</code> scans a 10x Visium HD Space Ranger output directory and writes a JSON manifest of detected assets.</li> </ul>"},{"location":"reference/visiumhd_addon/#add-on-modules","title":"Add-on Modules","text":"Load Space Ranger"},{"location":"reference/visiumhd_addon/#introduction","title":"Introduction","text":"<p>Create a manifest consolidates locations for SGE inputs (binned features and spatial metadata), segmented cell analysis outputs, hex-binned analysis at 8 \u00b5m and 16 \u00b5m, and optional tissue images. </p> <p>Typical next steps use this manifest as input for <code>sge_convert</code>, <code>import_cell</code>, <code>import_image</code>, or an end\u2011to\u2011end pipeline.</p>"},{"location":"reference/visiumhd_addon/#requirements","title":"Requirements","text":"<ul> <li>Space Ranger output directory (unpacked) containing standard files and subfolders.</li> <li>Optional: a writable directory for temporary archive extraction when using <code>--unzip-dir</code>.</li> </ul>"},{"location":"reference/visiumhd_addon/#example-usage","title":"Example Usage","text":"<pre><code>cartloader load_space_ranger \\\n  --in-dir /path/to/SpaceRanger_*_outs \\\n  --out-json /path/to/out/visiumhd_space_ranger_assets.json \n</code></pre>"},{"location":"reference/visiumhd_addon/#actions","title":"Actions","text":"<p>Detect standard Space Ranger assets under <code>--in-dir</code> and build a structured JSON manifest. Paths are resolved from files and supported archives (via <code>--unzip-dir</code>); only present items are included.</p> <ul> <li> <p>SGE (required keys):</p> <ul> <li><code>TRANSCRIPT_MEX</code>: <code>square_002um/filtered_feature_bc_matrix</code> or <code>binned_outputs/square_002um/filtered_feature_bc_matrix</code> (also in <code>*_square_002um_binned_outputs.tar.gz</code> or <code>*_binned_outputs.tar.gz</code>)</li> <li><code>SCALE</code>: <code>square_002um/spatial/scalefactors_json.json</code> or <code>binned_outputs/square_002um/spatial/scalefactors_json.json</code> (same archives)</li> <li><code>POSITION</code>: <code>square_002um/spatial/tissue_positions.parquet</code> or <code>binned_outputs/square_002um/spatial/tissue_positions.parquet</code> (same archives)</li> </ul> </li> <li> <p>CELLS (segmented outputs):</p> <ul> <li>Required: <code>CELL_FEATURE_MEX</code> \u2014 <code>segmented_outputs/filtered_feature_cell_matrix</code> (also in <code>*_segmented_outputs.tar.gz</code>)</li> <li>Required: <code>CELL_GEOJSON</code> \u2014 <code>segmented_outputs/cell_segmentations.geojson</code> (also in <code>*_segmented_outputs.tar.gz</code>)</li> <li>Optional: <code>NUCLEUS_GEOJSON</code> \u2014 <code>segmented_outputs/nucleus_segmentations.geojson</code> (also in <code>*_segmented_outputs.tar.gz</code>)</li> <li>Required: <code>CLUSTER</code> \u2014 <code>segmented_outputs/analysis/clustering/gene_expression_graphclust/clusters.csv</code> (also in <code>*_segmented_outputs.tar.gz</code>)</li> <li>Required: <code>DE</code> \u2014 <code>segmented_outputs/analysis/diffexp/gene_expression_graphclust/differential_expression.csv</code> (also in <code>*_segmented_outputs.tar.gz</code>)</li> <li>Optional: <code>PCA_PROJ</code> \u2014 <code>segmented_outputs/analysis/pca/gene_expression_10_components/projection.csv</code> (also in <code>*_segmented_outputs.tar.gz</code>)</li> <li>Optional: <code>PCA_VAR</code> \u2014 <code>segmented_outputs/analysis/pca/gene_expression_10_components/variance.csv</code> (also in <code>*_segmented_outputs.tar.gz</code>)</li> <li>Optional: <code>UMAP_PROJ</code> \u2014 <code>segmented_outputs/analysis/umap/gene_expression_2_components/projection.csv</code> (also in <code>*_segmented_outputs.tar.gz</code>)</li> </ul> </li> <li> <p>GRID_8um and GRID_16um (hex\u2011binned; all optional):</p> <ul> <li><code>GRID_FEATURE_MEX</code>: <code>&lt;square_008um|square_016um&gt;/filtered_feature_bc_matrix</code> or <code>binned_outputs/&lt;square_...&gt;/filtered_feature_bc_matrix</code> (also in <code>*_square_00[8|16]um_binned_outputs.tar.gz</code> or <code>*_binned_outputs.tar.gz</code>)</li> <li><code>SCALE</code>: <code>&lt;square_...&gt;/spatial/scalefactors_json.json</code> (same archive support)</li> <li><code>POSITION</code>: <code>&lt;square_...&gt;/spatial/tissue_positions.parquet</code> (same archive support)</li> <li><code>CLUSTER</code>: <code>&lt;square_...&gt;/analysis/clustering/gene_expression_graphclust/clusters.csv</code> (same archive support)</li> <li><code>DE</code>: <code>&lt;square_...&gt;/analysis/diffexp/gene_expression_graphclust/differential_expression.csv</code> (same archive support)</li> <li><code>PCA_PROJ</code>: <code>&lt;square_...&gt;/analysis/pca/gene_expression_10_components/projection.csv</code> (same archive support)</li> <li><code>PCA_VAR</code>: <code>&lt;square_...&gt;/analysis/pca/gene_expression_10_components/variance.csv</code> (same archive support)</li> <li><code>UMAP_PROJ</code>: <code>&lt;square_...&gt;/analysis/umap/gene_expression_2_components/projection.csv</code> (same archive support)</li> </ul> </li> <li> <p>IMAGES (optional):</p> <ul> <li><code>HnE_BTF</code>: Matches files with suffix <code>_tissue_image.btf</code> (also found within <code>*_square_002um_binned_outputs.tar.gz</code> or <code>*_binned_outputs.tar.gz</code>)</li> </ul> </li> </ul> <p>Note: Exact availability varies by dataset and pipeline options. Missing entries are omitted.</p>"},{"location":"reference/visiumhd_addon/#parameters","title":"Parameters","text":"<ul> <li><code>--in-dir</code> (str, required): Space Ranger output directory to scan.</li> <li><code>--out-json</code> (str, required): Path to write the generated assets JSON.</li> <li><code>--unzip-dir</code> (str, optional): Directory to extract archives found under <code>--in-dir</code> (defaults to <code>--in-dir</code>).</li> <li><code>--overwrite</code> (flag): Overwrite <code>--out-json</code> if it already exists.</li> </ul>"},{"location":"reference/visiumhd_addon/#output","title":"Output","text":"<p>Writes a JSON manifest at <code>--out-json</code>.</p> <p>Example: <code>includes/visiumhd_space_ranger_assets.visiumhd_3prime_mouse_brain.json</code></p> <pre><code>{\n    \"SGE\": {\n        \"TRANSCRIPT_MEX\": \"/example_dir/Visium_HD_3prime_Mouse_Brain/binned_outputs/square_002um/filtered_feature_bc_matrix\",\n        \"SCALE\": \"/example_dir/Visium_HD_3prime_Mouse_Brain/binned_outputs/square_002um/spatial/scalefactors_json.json\",\n        \"POSITION\": \"/example_dir/Visium_HD_3prime_Mouse_Brain/binned_outputs/square_002um/spatial/tissue_positions.parquet\"\n    },\n    \"CELLS\": {\n        \"CELL_FEATURE_MEX\": \"/example_dir/Visium_HD_3prime_Mouse_Brain/segmented_outputs/filtered_feature_cell_matrix\",\n        \"CELL_GEOJSON\": \"/example_dir/Visium_HD_3prime_Mouse_Brain/segmented_outputs/cell_segmentations.geojson\",\n        \"NUCLEUS_GEOJSON\": \"/example_dir/Visium_HD_3prime_Mouse_Brain/segmented_outputs/nucleus_segmentations.geojson\",\n        \"CLUSTER\": \"/example_dir/Visium_HD_3prime_Mouse_Brain/segmented_outputs/analysis/clustering/gene_expression_graphclust/clusters.csv\",\n        \"DE\": \"/example_dir/Visium_HD_3prime_Mouse_Brain/segmented_outputs/analysis/diffexp/gene_expression_graphclust/differential_expression.csv\",\n        \"PCA_PROJ\": \"/example_dir/Visium_HD_3prime_Mouse_Brain/segmented_outputs/analysis/pca/gene_expression_10_components/projection.csv\",\n        \"PCA_VAR\": \"/example_dir/Visium_HD_3prime_Mouse_Brain/segmented_outputs/analysis/pca/gene_expression_10_components/variance.csv\",\n        \"UMAP_PROJ\": \"/example_dir/Visium_HD_3prime_Mouse_Brain/segmented_outputs/analysis/umap/gene_expression_2_components/projection.csv\"\n    },\n    \"GRID_8um\": {\n        \"GRID_FEATURE_MEX\": \"/example_dir/Visium_HD_3prime_Mouse_Brain/binned_outputs/square_008um/filtered_feature_bc_matrix\",\n        \"SCALE\": \"/example_dir/Visium_HD_3prime_Mouse_Brain/binned_outputs/square_008um/spatial/scalefactors_json.json\",\n        \"POSITION\": \"/example_dir/Visium_HD_3prime_Mouse_Brain/binned_outputs/square_008um/spatial/tissue_positions.parquet\",\n        \"CLUSTER\": \"/example_dir/Visium_HD_3prime_Mouse_Brain/binned_outputs/square_008um/analysis/clustering/gene_expression_graphclust/clusters.csv\",\n        \"DE\": \"/example_dir/Visium_HD_3prime_Mouse_Brain/binned_outputs/square_008um/analysis/diffexp/gene_expression_graphclust/differential_expression.csv\",\n        \"PCA_PROJ\": \"/example_dir/Visium_HD_3prime_Mouse_Brain/binned_outputs/square_008um/analysis/pca/gene_expression_10_components/projection.csv\",\n        \"PCA_VAR\": \"/example_dir/Visium_HD_3prime_Mouse_Brain/binned_outputs/square_008um/analysis/pca/gene_expression_10_components/variance.csv\",\n        \"UMAP_PROJ\": \"/example_dir/Visium_HD_3prime_Mouse_Brain/binned_outputs/square_008um/analysis/umap/gene_expression_2_components/projection.csv\"\n    },\n    \"GRID_16um\": {\n        \"GRID_FEATURE_MEX\": \"/example_dir/Visium_HD_3prime_Mouse_Brain/binned_outputs/square_016um/filtered_feature_bc_matrix\",\n        \"SCALE\": \"/example_dir/Visium_HD_3prime_Mouse_Brain/binned_outputs/square_016um/spatial/scalefactors_json.json\",\n        \"POSITION\": \"/example_dir/Visium_HD_3prime_Mouse_Brain/binned_outputs/square_016um/spatial/tissue_positions.parquet\",\n        \"CLUSTER\": \"/example_dir/Visium_HD_3prime_Mouse_Brain/binned_outputs/square_016um/analysis/clustering/gene_expression_graphclust/clusters.csv\",\n        \"DE\": \"/example_dir/Visium_HD_3prime_Mouse_Brain/binned_outputs/square_016um/analysis/diffexp/gene_expression_graphclust/differential_expression.csv\",\n        \"PCA_PROJ\": \"/example_dir/Visium_HD_3prime_Mouse_Brain/binned_outputs/square_016um/analysis/pca/gene_expression_10_components/projection.csv\",\n        \"PCA_VAR\": \"/example_dir/Visium_HD_3prime_Mouse_Brain/binned_outputs/square_016um/analysis/pca/gene_expression_10_components/variance.csv\",\n        \"UMAP_PROJ\": \"/example_dir/Visium_HD_3prime_Mouse_Brain/binned_outputs/square_016um/analysis/umap/gene_expression_2_components/projection.csv\"\n    },\n    \"IMAGES\": {\n        \"HnE_BTF\": \"/example_dir/Visium_HD_3prime_Mouse_Brain/Visium_HD_3prime_Mouse_Brain_tissue_image.btf\"\n    }\n}\n</code></pre>"},{"location":"reference/xenium_addon/","title":"Xenium Pipeline Add-on Modules","text":""},{"location":"reference/xenium_addon/#overview","title":"Overview","text":"<p><code>CartLoader</code> provides add-on modules to support the Xenium pipeline orchestrator:</p> <ul> <li><code>load_xenium_ranger</code> scans a 10x Xenium Ranger output directory and writes a JSON manifest of detected assets.</li> </ul>"},{"location":"reference/xenium_addon/#add-on-modules","title":"Add-on Modules","text":"Load Xenium Ranger"},{"location":"reference/xenium_addon/#introduction","title":"Introduction","text":"<p><code>load_xenium_ranger</code> scans a 10x Xenium Ranger output directory and writes a JSON manifest of detected assets. The manifest consolidates paths for Spatial Gene Expression (SGE), cell analysis outputs (cells, boundaries, clusters, DE, embeddings), and morphology images (OME\u2011TIFFs).</p> <p>Typical next steps use this manifest as input for downstream commands such as <code>run_xenium</code>, <code>sge_convert</code>, <code>import_cell</code>, and <code>import_image</code>.</p>"},{"location":"reference/xenium_addon/#requirements","title":"Requirements","text":"<ul> <li>Xenium Ranger output directory (unpacked) containing standard files and subfolders.</li> <li>Optional: a writable directory for temporary archive extraction when using <code>--unzip-dir</code>.</li> </ul>"},{"location":"reference/xenium_addon/#example-usage","title":"Example Usage","text":"<pre><code>cartloader load_xenium_ranger \\\n  --in-dir /path/to/xenium/ranger/output \\\n  --out-json /path/to/out/xenium_ranger_assets.json \\\n  --unzip-dir /path/to/out/tmp\n</code></pre>"},{"location":"reference/xenium_addon/#actions","title":"Actions","text":"<p>Detect standard Xenium Ranger assets under <code>--in-dir</code> and build a structured JSON manifest (SGE, CELLS, IMAGES). Paths are resolved from files and supported archives (via <code>--unzip-dir</code>); only present items are included:</p> <ul> <li>SGE:<ul> <li>Required: <code>TRANSCRIPT</code> \u2014 <code>transcripts.csv.gz</code> or <code>transcripts.parquet</code></li> </ul> </li> <li>CELLS:<ul> <li>Required: <code>CELL</code> \u2014 <code>cells.csv.gz</code> or <code>cells.parquet</code></li> <li>Required: <code>BOUNDARY</code> \u2014 <code>cell_boundaries.csv.gz</code></li> <li>Optional: <code>CELL_FEATURE_MEX</code> \u2014 <code>cell_feature_matrix/</code> (also <code>cell_feature_matrix.tar.gz</code>)</li> <li>Required: <code>CLUSTER</code> \u2014 <code>analysis/clustering/gene_expression_graphclust/clusters.csv</code> (also within <code>analysis.tar.gz</code>)</li> <li>Required: <code>DE</code> \u2014 <code>analysis/diffexp/gene_expression_graphclust/differential_expression.csv</code> (also within <code>analysis.tar.gz</code>)</li> <li>Optional: <code>PCA_PROJ</code> \u2014 <code>analysis/pca/gene_expression_*/projection.csv</code> (also within <code>analysis.tar.gz</code>)</li> <li>Optional: <code>PCA_VAR</code> \u2014 <code>analysis/pca/gene_expression_*/variance.csv</code> (also within <code>analysis.tar.gz</code>)</li> <li>Optional: <code>UMAP_PROJ</code> \u2014 <code>analysis/umap/gene_expression_*/projection.csv</code> (also within <code>analysis.tar.gz</code>)</li> </ul> </li> <li>IMAGES (OME\u2011TIFF, all optional):<ul> <li><code>DAPI_OME</code> \u2014 <code>morphology_focus.ome.tif</code> or <code>morphology_focus/morphology_focus_0000.ome.tif</code></li> <li><code>BOUNDARY_OME</code> \u2014 <code>morphology_focus/morphology_focus_0001.ome.tif</code></li> <li><code>INTERIOR_RNA_OME</code> \u2014 <code>morphology_focus/morphology_focus_0002.ome.tif</code></li> <li><code>INTERIOR_PROTEIN_OME</code> \u2014 <code>morphology_focus/morphology_focus_0003.ome.tif</code></li> <li><code>DAPI_MIP_OME</code> \u2014 <code>morphology_mip.ome.tif</code> </li> </ul> </li> </ul> <p>Note: Exact availability varies by dataset and pipeline options. Missing entries are omitted; zip archives listed above are unpacked or scanned when <code>--unzip-dir</code> is provided.</p>"},{"location":"reference/xenium_addon/#parameters","title":"Parameters","text":"<ul> <li><code>--in-dir</code> (str, required): Xenium Ranger output directory to scan.</li> <li><code>--out-json</code> (str, required): Path to write the generated assets JSON.</li> <li><code>--unzip-dir</code> (str, optional): Directory to extract archives found under <code>--in-dir</code> (defaults to <code>--in-dir</code>).</li> <li><code>--overwrite</code> (flag): Overwrite <code>--out-json</code> if it already exists.</li> </ul>"},{"location":"reference/xenium_addon/#output","title":"Output","text":"<p>Writes a JSON manifest at <code>--out-json</code>. </p> <p>Example: <code>includes/xenium_ranger_assets.human_lung_cancer.json</code></p> <pre><code>{\n    \"SGE\": {\n        \"TRANSCRIPT\": \"/example_dir/Xenium_V1_humanLung_Cancer_FFPE_outs/transcripts.csv.gz\"\n    },\n    \"CELLS\": {\n        \"CELL\": \"/example_dir/Xenium_V1_humanLung_Cancer_FFPE_outs/cells.csv.gz\",\n        \"BOUNDARY\": \"/example_dir/Xenium_V1_humanLung_Cancer_FFPE_outs/cell_boundaries.csv.gz\",\n        \"CELL_FEATURE_MEX\": \"/example_dir/Xenium_V1_humanLung_Cancer_FFPE_outs/cell_feature_matrix\",\n        \"CLUSTER\": \"/example_dir/Xenium_V1_humanLung_Cancer_FFPE_outs/analysis/clustering/gene_expression_graphclust/clusters.csv\",\n        \"DE\": \"/example_dir/Xenium_V1_humanLung_Cancer_FFPE_outs/analysis/diffexp/gene_expression_graphclust/differential_expression.csv\",\n        \"PCA_PROJ\": \"/example_dir/Xenium_V1_humanLung_Cancer_FFPE_outs/analysis/pca/gene_expression_10_components/projection.csv\",\n        \"PCA_VAR\": \"/example_dir/Xenium_V1_humanLung_Cancer_FFPE_outs/analysis/pca/gene_expression_10_components/variance.csv\",\n        \"UMAP_PROJ\": \"/example_dir/Xenium_V1_humanLung_Cancer_FFPE_outs/analysis/umap/gene_expression_2_components/projection.csv\"\n    },\n    \"IMAGES\": {\n        \"DAPI_OME\": \"/example_dir/Xenium_V1_humanLung_Cancer_FFPE_outs/morphology_focus/morphology_focus_0000.ome.tif\",\n        \"BOUNDARY_OME\": \"/example_dir/Xenium_V1_humanLung_Cancer_FFPE_outs/morphology_focus/morphology_focus_0001.ome.tif\",\n        \"INTERIOR_RNA_OME\": \"/example_dir/Xenium_V1_humanLung_Cancer_FFPE_outs/morphology_focus/morphology_focus_0002.ome.tif\",\n        \"INTERIOR_PROTEIN_OME\": \"/example_dir/Xenium_V1_humanLung_Cancer_FFPE_outs/morphology_focus/morphology_focus_0003.ome.tif\",\n        \"DAPI_3D_OME\": \"/example_dir/Xenium_V1_humanLung_Cancer_FFPE_outs/morphology.ome.tif\"\n    }\n}\n</code></pre>"},{"location":"vignettes/intro/","title":"Vignettes","text":"<p>Explore a series of tutorials that help you learn <code>CartLoader</code> \u2014 from quick, getting\u2011started examples to processing full\u2011scale ST datasets.</p> <p>To view details of a specific module, see Reference section.</p>"},{"location":"vignettes/intro/#quick-start","title":"Quick Start","text":"<p>If you\u2019re new to <code>CartLoader</code>, start with the Quick Start tutorial, a beginner\u2011friendly walkthrough using a small mouse hippocampus dataset to core <code>CartLoader</code> functions.</p> <ul> <li> <p> Quick Start Tutorial </p> <p>Read</p> </li> </ul>"},{"location":"vignettes/intro/#getting-started-per-platform","title":"Getting Started per Platform","text":"<p>These tutorials demonstrate how to run <code>CartLoader</code> on a variety of ST platforms using small, representative datasets.</p> <p>Warning</p> <p>For consistency, we use mouse hippocampus when available. </p> <p>Each tutorial begins with data in the platform\u2019s native format.</p>"},{"location":"vignettes/intro/#sequencing-based-platforms","title":"Sequencing-based Platforms","text":"<ul> <li> <p> SeqScope Starter Guide </p> <p>Read</p> </li> <li> <p> 10x Visium HD Starter Guide </p> <p>Read</p> </li> <li> <p> StereoSeq Starter Guide </p> <p>Read</p> </li> <li> <p> Pixel-seq Starter Guide </p> <p>Read</p> </li> </ul>"},{"location":"vignettes/intro/#imaging-based-platforms","title":"Imaging-based Platforms","text":"<ul> <li> <p> 10x Xenium Starter Guide </p> <p>Read</p> </li> <li> <p> Vizgen MERSCOPE Starter Guide </p> <p>Read</p> </li> <li> <p> CosMX SMI Starter Guide </p> <p>Read</p> </li> </ul>"},{"location":"vignettes/intro/#endtoend-workflows-by-platform","title":"End\u2011to\u2011end workflows by platform","text":"<p>These examples show how to process real\u2011world ST datasets from different platform using end-to-end workflow from <code>CartLoader</code>.</p> <ul> <li> <p> 10x Xenium Pipeline Guide </p> <p>Read</p> </li> <li> <p> Visium HD Pipeline Guide </p> <p>Read</p> </li> </ul>"},{"location":"vignettes/intro/#multisample-analysis","title":"Multi\u2011Sample Analysis","text":"<p>Warning</p> <p>This section is under active development.</p> <p>Upcoming content will cover how to process multiple samples in a single batch, including cross\u2011sample analysis.</p>"},{"location":"vignettes/multi_sample/","title":"Human Cortex Multi\u2011Sample Spatial Factor Analysis Tutorial","text":""},{"location":"vignettes/multi_sample/#overview","title":"Overview","text":"<p>This tutorial demonstrates how to run multi\u2011sample FICTURE analysis and package results using <code>run_ficture2_multi</code> and <code>run_cartload2_multi</code>.</p> <p>Why use Multi\u2011Sample FICTURE Analysis?</p> <p><code>CartLoader</code> supports analyzing \u22652 samples in two ways:</p> <ul> <li>Multi\u2011sample FICTURE analysis (<code>run_ficture2_multi</code>): Jointly learns spatial factors across all samples and writes per\u2011sample outputs in one parallelizable run.</li> <li>SGE stitch + single\u2011sample analysis (<code>sge_stitch</code> \u2192 <code>run_ficture2</code>): Stitch multiple SGEs into a single mosaic, then train one model on that mosaic.</li> </ul> <p>What to expect</p> <ul> <li>Shared factors/comparability: <code>run_ficture2_multi</code> learns a cohort\u2011wide latent basis and returns per\u2011sample decodes for direct comparison. The stitch approach yields a single model over the merged mosaic; useful when you need a unified coordinate system (e.g., tiling adjacent sections).</li> <li>Efficiency and scale: <code>run_ficture2_multi</code> fits once for the cohort and decodes per sample, avoiding repeated runs and post\u2011hoc alignment. Stitching can be simpler for mosaics but often increases I/O and memory due to very large merged files.</li> </ul> <p>Recommendation:</p> <ul> <li>Prefer <code>run_ficture2_multi</code> for most cohorts for clean per\u2011sample outputs and better computational efficiency; use stitching when a single shared coordinate frame is required.</li> <li>If you choose stitching, plan for higher resource usage (RAM, disk, and I/O). Large mosaics can be slow to generate and train on, and may require substantially more memory and temporary storage than per\u2011sample runs.</li> </ul>"},{"location":"vignettes/multi_sample/#input-data","title":"Input Data","text":"<p>This tutorial uses a series of four human cortex ST datasets from Walsh et al. Nature 2025, generated using MERFISH.</p> <p>File Format</p> <p><code>detected_transcripts.csv.gz</code></p> <pre><code>,barcode_id,global_x,global_y,global_z,x,y,fov,gene,transcript_id,cell_id\n36,0,154.75854,8197.335,0.0,1790.1895,303.81055,0,HS3ST1,ENST00000002596,224295401131100634\n53,0,157.40007,8211.97,0.0,1814.648,439.31885,0,HS3ST1,ENST00000002596,-1\n76,0,154.28473,8230.835,0.0,1785.8022,614.0,0,HS3ST1,ENST00000002596,224295401131100700\n</code></pre> <ul> <li>Column 1: Unique numeric index for each transcript within a field of view (non-consecutive, ascending).</li> <li><code>barcode_id</code>: Zero-based index of the transcript barcode in the codebook; forms a composite key with <code>fov</code>.</li> <li><code>global_x</code>: Transcript x coordinates (\u00b5m) in the experimental region; may be negative due to alignment.</li> <li><code>global_y</code>: Transcript y coordinates (\u00b5m) in the experimental region; may be negative due to alignment.</li> <li><code>global_z</code>: Zero\u2011based z\u2011position index.</li> <li><code>x</code>: The x-coordinate of the transcript (\u00b5m), within the coordinate space of the field of view.</li> <li><code>y</code>: The y-coordinate of the transcript (\u00b5m), within the coordinate space of the field of view.</li> <li><code>fov</code>: Zero-based field of view index; forms a composite key with <code>barcode_id</code>.</li> <li><code>gene</code>: Gene name.</li> <li><code>transcript_id</code>: Unique identifier for the transcript.</li> <li><code>cell_id</code>: Unique identifier for cell.</li> </ul> <p>Data Access</p> <p>Follow the commands below to download the source data.</p> <pre><code>work_dir=/path/to/work/directory\nmkdir -p ${work_dir}/raw\ncd ${work_dir}/raw\n\nwget https://zenodo.org/records/15127709/files/FB080_O1a.zip?download=1\nunzip FB080_O1a.zip\n\nwget https://zenodo.org/records/15127709/files/FB080_O1b.zip?download=1\nunzip FB080_O1b.zip\n\nwget https://zenodo.org/records/15127709/files/FB080_O1c.zip?download=1\nunzip FB080_O1c.zip\n\nwget https://zenodo.org/records/15127709/files/FB080_O1d.zip?download=1\nunzip FB080_O1d.zip\n</code></pre>"},{"location":"vignettes/multi_sample/#set-up-the-environment","title":"Set Up the Environment","text":"<p>Pre-installed tools</p> <p>Please ensure you have installed all required tools (See Installation).</p> <p>Define paths to all required binaries and resources. Optionally, specify a fixed color map for consistent rendering.</p> <pre><code># ====\n# Replace each placeholder with the actual path on your system.  \n# ====\n\nwork_dir=/path/to/work/directory        # path to work directory that contains the downloaded input data\ncd $work_dir\n\n# Define paths to required binaries and resources\nspatula=/path/to/spatula/binary         # path to spatula executable\npunkst=/path/to/punkst/binary           # path to FICTURE2 (punkst) executable\ntippecanoe=/path/to/tippecanoe/binary   # path to tippecanoe executable\npmtiles=/path/to/pmtiles/binary         # path to pmtiles executable\naws=/path/to/aws/cli/binary             # path to AWS CLI binary\n\n# (Optional) Define path to color map. \ncmap=/path/to/color/map                 # Path to fixed color map. `CartLoader` includes one at cartloader/assets/fixed_color_map_256.tsv.\n\n# Number of jobs\nn_jobs=10                               # If not specified, the number of jobs defaults to 1.\n\n# Activate the bioconda environment\nconda activate ENV_NAME                 # replace ENV_NAME with your conda environment name\n</code></pre> <p>Define data ID and analysis parameters:</p> <pre><code># Unique identifier for your collection\nCOLLECTION_ID=\"walsh2025-human-cortex-fb080-O1\" # change this to reflect your dataset name\nPLATFORM=\"generic\"                      # platform information\nSCALE=1                                 # coordinate to micrometer scaling factor\n\n# LDA parameters\ntrain_width=18                           # define LDA training hexagon width (comma-separated if multiple widths are applied)\nn_factor=48,96                           # define number of factors in LDA training (comma-separated if multiple n-factor are applied)\n</code></pre> <p>Prepare a working directory:</p> <pre><code>work_dir=/path/to/work/dir/${COLLECTION_ID}\ncd ${work_dir}\n</code></pre>"},{"location":"vignettes/multi_sample/#sge-format-conversion","title":"SGE Format Conversion","text":"<p>For each sample, convert its transcript\u2011indexed SGE file to be the <code>CartLoader</code> format.</p> <p>Below use FB080_O1a as an example.</p> <pre><code>sample_id=FB080_O1a\nmkdir -p ./sge/${sample_id}\n\ncartloader sge_convert \\\n  --in-csv ./raw/${sample_id}/detected_transcripts.csv.gz \\\n  --platform generic \\\n  --out-dir ./sge/${sample_id} \\\n  --csv-delim \",\" \\\n  --csv-colname-x global_x \\\n  --csv-colname-y global_y \\\n  --csv-colname-feature-name gene \\\n  --csv-colnames-others cell_id,global_z \\\n  --sge-visual \n</code></pre> <p>Alternatively, if you don\u2019t need SGE visualization or density/feature\u2011based filtering, you can directly generate a CartLoader\u2011compatible SGE with fixed column names (the raw SGE is already in micrometers):</p> <pre><code>sample_id=FB080_O1a\nmkdir -p ./sge/${sample_id}\n\n(echo -e \"X\\tY\\tgene\\tcount\\tcell_id\\tZ\";gzip -cd ./raw/${sample_id}/detected_transcripts.csv.gz | tail -n +2| tr , '\\t' | perl -lane 'print join(\"\\t\",$F[2],$F[3],$F[8],1,$F[10],$F[4]);';) | gzip &gt; ./sge/${sample_id}/transcripts.unsorted.tsv.gz\n</code></pre>"},{"location":"vignettes/multi_sample/#prepare-input-list","title":"Prepare Input List","text":"<p>Create a tab\u2011separated TSV file (e.g., <code>input.tsv</code>) with one sample per line. The TSV should have no header and contain two to four columns.</p> <p>Example Input List: <code>input.tsv</code></p> <pre><code>FB080_O1a /path/to/FB080_O1a/transcripts.unsorted.tsv.gz\nFB080_O1b /path/to/FB080_O1b/transcripts.unsorted.tsv.gz\nFB080_O1c /path/to/FB080_O1c/transcripts.unsorted.tsv.gz\nFB080_O1d /path/to/FB080_O1d/transcripts.unsorted.tsv.gz\n</code></pre> <ul> <li><code>1st Column</code> (required, str): Unique dataset identifier (avoid whitespace; prefer <code>-</code> to <code>_</code>).</li> <li><code>2nd Column</code> (required, str): Path to the transcript\u2011indexed SGE file in <code>CartLoader</code> format, generated from SGE Format Conversion.</li> <li><code>3rd Column</code>  (optional, str): Dataset title. Quote the value when whitespace is involved.</li> <li><code>4th Column</code>  (optional, str): Dataset description. Quote the value when whitespace is involved.</li> </ul>"},{"location":"vignettes/multi_sample/#multisample-ficture-analysis","title":"Multi\u2011Sample FICTURE Analysis","text":"<p>Trains LDA models across samples for each parameter setting (width and n\u2011factor), decodes per sample, and writes per\u2011sample JSON manifests summarizing results.</p> <p>Outputs are written under <code>ficture2/&lt;sample_id&gt;/</code>. See details in run_ficture2_multi.</p> <pre><code>cartloader run_ficture2_multi \\\n  --in-list ./input.tsv \\\n  --out-dir ./ficture2 \\\n  --width 18 \\\n  --n-factor 48,96 \\\n  --exclude-feature-regex \"^(Blank-.*$)\" \\\n  --redo-merge-units \\\n  --ficture2 ${PUNKST} \\\n  --spatula ${SPATULA} \\\n  --threads 12 \\\n  --n-jobs 10 \n</code></pre>"},{"location":"vignettes/multi_sample/#multisample-asset-packaging","title":"Multi\u2011Sample Asset Packaging","text":"<p>Package per\u2011sample outputs from <code>ficture2/&lt;sample_id&gt;/</code> into web\u2011ready PMTiles and catalogs.</p> <p>Outputs are written under <code>cartload2/&lt;sample_id&gt;/</code>. See details in run_cartload2_multi.</p> <pre><code>cartloader run_cartload2_multi \\\n  --in-list ./input.tsv \\\n  --fic-dir ./ficture2 \\\n  --out-dir ./cartload2 \\\n  --spatula ${SPATULA} \\\n  --tippecanoe ${TIPPECANOE} \\\n  --threads 12 \\\n  --n-jobs 10 \n</code></pre>"},{"location":"vignettes/multi_sample/#upload-to-aws","title":"Upload to AWS","text":"<p>Upload the generated <code>CartLoader</code> outputs from above to your designated AWS S3 directory \u2014 either the whole collection at once or each sample individually. For full details, see upload_aws.</p> Upload a collectionUpload a single sample <pre><code>AWS_DIR=s3://your-bucket/${COLLECTION_ID} # Recommend to use COLLECTION_ID as directory name, this will create a subdirectory for each sample\n\ncartloader upload_aws \\\n  --in-dir ./cartload2 \\\n  --s3-dir ${AWS_DIR} \\\n  --in-list ./input.tsv \n</code></pre> <p>Below use FB080_O1a as an example.</p> <pre><code>AWS_DIR=s3://your-bucket/${COLLECTION_ID} # Recommend to use COLLECTION_ID as directory name, this will create a subdirectory for each sample\n\ncartloader upload_aws \\\n  --in-dir ./cartload2/FB080_O1a \\\n  --s3-dir ${AWS_DIR}/fb080-01a\n</code></pre>"},{"location":"vignettes/multi_sample/#output-summary","title":"Output Summary","text":"<p>See more details of output at the Reference pages for run_ficture2 and run_cartload2.</p>"},{"location":"vignettes/multi_sample/#viewexplore","title":"View/Explore","text":"<p>The output are available in both CartoScope. </p> <p>Explore in CartoScope</p>"},{"location":"vignettes/pipelines/visiumhd/","title":"Visium HD End-to-End Pipeline","text":""},{"location":"vignettes/pipelines/visiumhd/#overview","title":"Overview","text":"<p>This tutorial walks through end\u2011to\u2011end processing of 10x Visium HD data with <code>CartLoader</code>: converting inputs, running FICTURE, importing cell results and histology, packaging assets, and uploading for sharing.</p>"},{"location":"vignettes/pipelines/visiumhd/#input-data","title":"Input Data","text":"<p>Data Structure and Format</p> <p>See Space Ranger output details in the official documentation: Space Ranger Outputs</p> RAW Data StructureSGE FormatCell Analysis Result Format <pre><code>\u251c\u2500\u2500 binned_outputs\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 square_002um\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 filtered_feature_bc_matrix\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 barcodes.tsv.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 features.tsv.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 matrix.mtx.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 ...\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 spatial\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 aligned_fiducials.jpg\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 aligned_tissue_image.jpg\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 cytassist_image.tiff\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 detected_tissue_image.jpg\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 scalefactors_json.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 tissue_hires_image.png\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 tissue_lowres_image.png\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 tissue_positions.parquet\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 square_008um\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 analysis\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 clustering\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 gene_expression_graphclust\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 clusters.csv\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 ...\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 diffexp\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 gene_expression_graphclust\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 differential_expression.csv\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 ...\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 pca\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 gene_expression_10_components\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 projection.csv\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 variance.csv\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 ...\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 umap\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 gene_expression_2_components\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0         \u2514\u2500\u2500 projection.csv\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 filtered_feature_bc_matrix\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 ...     # Mirrors binned_outputs/square_002um/filtered_feature_bc_matrix\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 ...\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 spatial\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 ...     # Mirrors binned_outputs/square_002um/spatial\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 square_016um\n\u2502\u00a0\u00a0  \u00a0\u00a0 \u2514\u2500\u2500 ...         # Mirrors square_008um (analysis, spatial, filtered_feature_bc_matrix)\n\u251c\u2500\u2500 segmented_outputs\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 cell_segmentations.geojson\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 ...             # Mirrors binned_outputs/square_008um (analysis, spatial, filtered_feature_bc_matrix)\n\u2514\u2500\u2500 ...\n</code></pre> <p>Visium HD slides use a 2\u00d72\u202f\u00b5m grid of barcoded squares (<code>square_002um</code>) for high-resolution spatial gene mapping. Use <code>filtered_feature_bc_matrix</code> to only process tissue-associated signals. </p> <p>ATTENTION</p> <p>The file\u2011format examples below use a sample Visium HD dataset. Paths, IDs, and values are illustrative and may not match the dataset used in this tutorial.</p> <p>SGE comprises several key files as below: </p> <code>filtered_feature_bc_matrix/barcodes.tsv.gz</code> \u2013 spatial barcode for tissue locations  <pre><code>s_002um_00639_00600-1\ns_002um_00923_01639-1\ns_002um_01050_01530-1\n</code></pre> <ul> <li>Column 1: Spatial barcodes corresponding to specific locations on the tissue section.</li> </ul> <code>filtered_feature_bc_matrix/features.tsv.gz</code> \u2013 feature metadata  <pre><code>ENSMUSG00000051951  Xkr4    Gene Expression\nENSMUSG00000025900  Rp1     Gene Expression\nENSMUSG00000025902  Sox17   Gene Expression\n</code></pre> <ul> <li>Column 1: Feature ID</li> <li>Column 2: Feature symbol</li> <li>Column 3: Feature type</li> </ul> <code>filtered_feature_bc_matrix/matrix.mtx.gz</code> \u2013 expression count matrix  <pre><code>%%MatrixMarket matrix coordinate integer general\n%\n19059 869411 11376563\n3606 1 1\n8957 1 1\n9733 1 1\n</code></pre> <ul> <li><code>Header</code>: Initial lines form the header, declaring the matrix's adherence to the Market Matrix (MTX) format, outlining its traits. This may include comments (lines beginning with <code>%</code>) for extra metadata, all marked by a \u201c%\u201d.</li> <li><code>Dimensions</code>: Following the header, the first line details the matrix dimensions: the count of rows (features), columns (barcodes), and non-zero entries.</li> <li><code>Data Entries</code>: Post-dimensions, subsequent lines enumerate non-zero entries in seven columns: row index (feature index), column index (barcode index), and one value presenting the expression count per barcode per feature.</li> </ul> <code>tissue_positions.parquet</code> \u2013 spatial barcode metadata  <pre><code>barcode                 in_tissue   array_row   array_col   pxl_row_in_fullres  pxl_col_in_fullres\ns_002um_00434_01637-1   1           434         1637        3396.371014         9125.919898\n</code></pre> <ul> <li><code>barcode</code>: Unique spatial barcode associated with each capture spot.</li> <li><code>in_tissue</code>: Binary flag (1 = in tissue, 0 = background) indicating whether the spot falls within the tissue boundary.</li> <li><code>array_row</code>, <code>array_col</code>: Integer indices representing the position of the spot on the capture array grid.</li> <li><code>pxl_row_in_fullres</code>, <code>pxl_col_in_fullres</code>: Floating point coordinates locating the spot in full-resolution tissue image pixels.</li> </ul> <code>scalefactors_json.json</code> \u2013 pixel-to-micrometer scaling factors  <pre><code>{\n    \"spot_diameter_fullres\": 7.303953797779634,\n    \"bin_size_um\": 2.0,\n    \"microns_per_pixel\": 0.2738242950835738,\n    \"regist_target_img_scalef\": 0.2505533,\n    \"tissue_lowres_scalef\": 0.02505533,\n    \"fiducial_diameter_fullres\": 1205.1523766336395,\n    \"tissue_hires_scalef\": 0.2505533\n}\n</code></pre> <ul> <li><code>spot_diameter_fullres</code>: Estimated diameter of a barcoded spot in full-resolution pixels.</li> <li><code>bin_size_um</code>: Physical size (in micrometers) of the smallest bin, typically 2.0\u202f\u00b5m for Visium HD.</li> <li><code>microns_per_pixel</code>: Resolution of the full-res image, used to convert pixel distances to micrometers.</li> <li><code>regist_target_img_scalef</code>: Scaling factor applied during image registration to the target image.</li> <li><code>tissue_lowres_scalef</code>: Downscaling factor from full-res to low-resolution tissue image.</li> <li><code>fiducial_diameter_fullres</code>: Diameter of fiducial markers in full-resolution pixels, useful for alignment.</li> <li><code>tissue_hires_scalef</code>: Downscaling factor from full-res to high-resolution tissue image.</li> </ul> <p>Cell Segmentation Mask</p> <p>Location: <code>segmented_outputs/cell_segmentations.geojson</code> <pre><code>\"cell_id\",\"x_centroid\",\"y_centroid\",\"transcript_counts\",\"control_probe_counts\",\"genomic_control_counts\",\"control_codeword_counts\",\"unassigned_codeword_counts\",\"deprecated_codeword_counts\",\"total_counts\",\"cell_area\",\"nucleus_area\",\"nucleus_count\",\"segmentation_method\"\n\"aaaagkdm-1\",170.85508728027344,2017.2412109375,1,0,0,0,0,0,1,46.285157930105925,NaN,0,\"Segmented by boundary stain (ATP1A1+CD45+E-Cadherin)\"\n\"aaaamcnn-1\",141.60569763183594,2481.442138671875,341,0,0,0,0,1,342,111.5359415486455,50.484689332544804,1,\"Segmented by boundary stain (ATP1A1+CD45+E-Cadherin)\"\n</code></pre></p> <p>Cell Feature Matrix</p> <p>Location: <code>segmented_outputs/filtered_feature_cell_matrix</code></p> <p>This contains <code>barcodes.tsv.gz</code>,<code>features.tsv.gz</code>, <code>matrix.mtx.gz</code>, providing cell id, feature information, and expression count matrix, respectively.</p> <p>Clusters</p> <p>Location: <code>segmented_outputs/analysis/clustering/gene_expression_graphclust/clusters.csv</code> <pre><code>Barcode,Cluster\ncellid_000000001-1,22\ncellid_000000002-1,22\n</code></pre></p> <p>Differentially Expressed Genes</p> <p>Location: <code>segmented_outputs/analysis/diffexp/gene_expression_graphclust/differential_expression.csv</code> <pre><code>Feature ID,Feature Name,Cluster 1 Mean Counts,Cluster 1 Log2 fold change,Cluster 1 Adjusted p value,Cluster 2 Mean Counts,Cluster 2 Log2 fold change,Cluster 2 Adjusted p value,Cluster 3 Mean Counts,Cluster 3 Log2 fold change,Cluster 3 Adjusted p value,Cluster 4 Mean Counts,Cluster 4 Log2 fold change,Cluster 4 Adjusted p value,Cluster 5 Mean Counts,Cluster 5 Log2 fold change,Cluster 5 Adjusted p value,Cluster 6 Mean Counts,Cluster 6 Log2 fold change,Cluster 6 Adjusted p value,Cluster 7 Mean Counts,Cluster 7 Log2 fold change,Cluster 7 Adjusted p value,Cluster 8 Mean Counts,Cluster 8 Log2 fold change,Cluster 8 Adjusted p value,Cluster 9 Mean Counts,Cluster 9 Log2 fold change,Cluster 9 Adjusted p value,Cluster 10 Mean Counts,Cluster 10 Log2 fold change,Cluster 10 Adjusted p value,Cluster 11 Mean Counts,Cluster 11 Log2 fold change,Cluster 11 Adjusted p value,Cluster 12 Mean Counts,Cluster 12 Log2 fold change,Cluster 12 Adjusted p value,Cluster 13 Mean Counts,Cluster 13 Log2 fold change,Cluster 13 Adjusted p value,Cluster 14 Mean Counts,Cluster 14 Log2 fold change,Cluster 14 Adjusted p value,Cluster 15 Mean Counts,Cluster 15 Log2 fold change,Cluster 15 Adjusted p value,Cluster 16 Mean Counts,Cluster 16 Log2 fold change,Cluster 16 Adjusted p value,Cluster 17 Mean Counts,Cluster 17 Log2 fold change,Cluster 17 Adjusted p value,Cluster 18 Mean Counts,Cluster 18 Log2 fold change,Cluster 18 Adjusted p value,Cluster 19 Mean Counts,Cluster 19 Log2 fold change,Cluster 19 Adjusted p value,Cluster 20 Mean Counts,Cluster 20 Log2 fold change,Cluster 20 Adjusted p value,Cluster 21 Mean Counts,Cluster 21 Log2 fold change,Cluster 21 Adjusted p value,Cluster 22 Mean Counts,Cluster 22 Log2 fold change,Cluster 22 Adjusted p value,Cluster 23 Mean Counts,Cluster 23 Log2 fold change,Cluster 23 Adjusted p value,Cluster 24 Mean Counts,Cluster 24 Log2 fold change,Cluster 24 Adjusted p value\nENSMUSG00000051951,Xkr4,0.0020893375742615837,0.542453177216764,0.16305286911324085,0.0019306072327678393,0.34251290321116556,0.628624629681027,0.0009020306879791494,-0.677062452566048,0.6057595443651351,0.0008575468486789855,-0.53825692400323,1,0.0018835945742411177,0.3347722133550999,1,0.0017232930683496192,0.30174489068131116,1,0.0008765004215231041,-0.6062657172996246,1,0.0006958304617047569,-0.669599363115374,1,0.0021901445815864866,0.5424639235287998,0.6460045298567026,0,-0.513593267969263,1,0.000450562773540615,-0.8809942923847434,1,0.0006856395158652269,-0.2651228613954135,1,0.0008800111512863451,-0.49971125727530463,1,0.0026227703011305675,1.0167399161570962,1,0.002277387540951688,0.7536928538206205,1,0,-1.333742893536682,1,0.0007018464992057343,-0.23097850703201495,1,0.0005602354699616488,-0.560849410646286,1,0.0015894120085537071,0.37398251412889394,1,0,1.526558986825357,1,0,-0.5313075119163866,1,0,4.9659921506021,1,0,1.1981124565354708,1,0,1.1280527529013042,1\nENSMUSG00000089699,Gm1992,0.00003369899313325135,2.372528175774452,0.49812531917443914,0,1.0054779159335947,1,0,2.907900048155108,1,0,3.8795955908826674,1,0,2.9741824980986316,1,0,3.8867073914024672,1,0,3.4811971239507127,1,0,4.171702890865568,1,0,2.5799386289474633,1,0,5.929350227879466,1,0,4.553633935251982,1,0,5.16950536624131,1,0,3.9181412576105927,1,0,5.104202757407435,1,0,4.56960978938165,1,0,5.109200602312047,1,0,5.203649720604709,1,0,4.873778816990438,1,0,4.791835029014791,1,0,7.969502482674086,1,0,5.911635983932342,1,0,11.408935646450828,1,0,7.641055952384198,1,0,7.570996248750033,1\n</code></pre></p> <p>Data Access</p> <p>Downloaded the ST data from 10x Genomics Dataset portal.</p>"},{"location":"vignettes/pipelines/visiumhd/#set-up-the-environment","title":"Set Up the Environment","text":"<p>Pre-installed tools</p> <p>Please ensure you have installed all required tools (See Installation).</p> <p>Define paths to all required binaries and resources. Optionally, specify a fixed color map for consistent rendering.</p> <pre><code># ====\n# Replace each placeholder with the actual path on your system.  \n# ====\n\nwork_dir=/path/to/work/directory        # path to work directory that contains the downloaded input data\ncd $work_dir\n\n# Define paths to required binaries and resources\nspatula=/path/to/spatula/binary         # path to spatula executable\npunkst=/path/to/punkst/binary           # path to FICTURE2 (punkst) executable\ntippecanoe=/path/to/tippecanoe/binary   # path to tippecanoe executable\npmtiles=/path/to/pmtiles/binary         # path to pmtiles executable\naws=/path/to/aws/cli/binary             # path to AWS CLI binary\n\n# (Optional) Define path to color map. \ncmap=/path/to/color/map                 # Path to fixed color map. `CartLoader` includes one at cartloader/assets/fixed_color_map_256.tsv.\n\n# Number of jobs\nn_jobs=10                               # If not specified, the number of jobs defaults to 1.\n\n# Activate the bioconda environment\nconda activate ENV_NAME                 # replace ENV_NAME with your conda environment name\n</code></pre> <p>Define data ID and analysis parameters:</p> <pre><code># Unique identifier for your dataset\nDATA_ID=\"visiumhd_3prime_mouse_brain\"    # change this to reflect your dataset name\n\n# LDA parameters\ntrain_width=18                           # define LDA training hexagon width (comma-separated if multiple widths are applied)\nn_factor=6,12                            # define number of factors in LDA training (comma-separated if multiple n-factor are applied)\n\n# Path to AWS S3 directory\nS3_DIR=/s3/path/to/s3/dir                # Recommend to use DATA_ID as directory name, such as s3://bucket-name/visiumhd-3prime-mouse-brain\n</code></pre> <p>How to define scaling for Visium HD?</p> <p>10x Visium HD provides <code>scalefactors_json.json</code> (pixel\u2011to\u2011\u00b5m). <code>CartLoader</code> accepts it via <code>--scale-json</code> and computes the scaling automatically, so you don\u2019t need to manually specify <code>--units-per-um</code>.</p> <p>Alternatively, provide the scale directly with <code>--units-per-um</code>.</p>"},{"location":"vignettes/pipelines/visiumhd/#run-pipelines","title":"Run Pipelines","text":"<p>The example below runs all modules together. Customize actions with flags.</p> <pre><code>cartloader run_visiumhd \\\n  --load-space-ranger \\\n  --sge-convert \\\n  --run-ficture2 \\\n  --import-cells \\\n  --import-images \\\n  --run-cartload2 \\\n  --upload-aws \\\n  --space-ranger-dir /path/to/space/ranger/output \\\n  --out-dir /path/to/out/dir \\\n  --s3-dir ${S3_DIR} \\\n  --width ${train_width} \\\n  --n-factor ${n_factor} \\\n  --id ${DATA_ID} \\\n  --spatula ${spatula} \\\n  --ficture2 ${punkst} \\\n  --pmtiles ${pmtiles} \\\n  --tippecanoe ${tippecanoe} \\\n  --aws ${aws} \\\n  --n-jobs ${n_jobs} \\\n  --threads ${n_jobs}\n</code></pre> <p>Action Flags to Enable Modules</p> <p>Actions</p> <p><code>run_visiumhd</code> runs multiple <code>CartLoader</code> modules together; enable and combine actions with flags.</p> <code>CartLoader</code> Modules Flags in <code>run_visiumhd</code> Actions Prerequisites <code>load_space_ranger</code> <code>--load-space-ranger</code> Summarize Space Ranger outputs into JSON Space Ranger Output files <code>sge_convert</code> <code>--sge-convert</code> Convert SGE to <code>CartLoader</code> format; optional density filter and visuals Space Ranger assets JSON (from <code>load_space_ranger</code>) or transcript CSV/Parquet <code>run_ficture2</code> <code>--run-ficture2</code> FICTURE analysis SGE (from <code>sge_convert</code>); FICTURE parameters (<code>--width</code>, <code>--n-factor</code>) <code>import_space_cell</code> <code>--import-cells</code> Import cell points, boundaries, cluster, de; Space Ranger assets JSON or manual CSVs; also <code>--cell-id</code> <code>import_image</code> <code>--import-images</code> Import background images (BTF-TIFF) \u2192 PNG/PMTiles; Space Ranger assets JSON or <code>--tifs</code>; also <code>--image-ids</code>/<code>--all-images</code> <code>run_cartload2</code> <code>--run-cartload2</code> Package SGE, optional FICTURE/cells/images into PMTiles; write <code>catalog.yaml</code> SGE, optional FICTURE assets or any imported cell/image assets; <code>--id</code> <code>upload_aws</code> <code>--upload-aws</code> Upload catalog and PMTiles to S3 <code>catalog.yaml</code> (from <code>run_cartload2</code>); <code>--s3-bucket</code>, <code>--id</code> <code>upload_zenodo</code> <code>--upload-zenodo</code> Upload catalog and PMTiles to Zenodo <code>catalog.yaml</code> (from <code>run_cartload2</code>); <code>--zenodo-token</code> <p>Parameter Requirements by Action Flag</p> <p>Below are explanations of the parameters used in the example. For the full list, see the <code>run_visiumhd</code> reference page.</p> Parameter Required when flags Description <code>--space-ranger-dir</code> <code>--load-space-ranger</code> Space Ranger output directory to scan. <code>--space-ranger-assets</code> optional <code>--load-space-ranger</code> Output JSON manifest path (defaults under <code>--out-dir</code>). <code>--width</code> <code>--run-ficture2</code> Hexagon width(s) in \u00b5m for training/projection. <code>--n-factor</code> <code>--run-ficture2</code> Factor count(s) for FICTURE training. <code>--cell-id</code> <code>--import-cells</code> Asset ID/prefix for cell outputs. <code>--image-ids</code> or <code>--all-images</code> <code>--import-images</code> Choose specific image IDs or import all detected. <code>--id</code> <code>--run-cartload2</code> Catalog ID (used in catalog.yaml and outputs). <code>--s3-dir</code> <code>--upload-aws</code> Destination S3 path (e.g., <code>s3://bucket/prefix</code>). <code>--out-dir</code> any action Output root directory for generated artifacts. <code>--dry-run</code>, <code>--restart</code> optional (any) Control execution (preview or rerun ignoring existing outputs). <code>--n-jobs</code>, <code>--threads</code> optional (any) Parallelism for Make/GDAL/tippecanoe steps."},{"location":"vignettes/pipelines/visiumhd/#outputs","title":"Outputs","text":"<p>See more details of output at the Reference pages for run_ficture2 and run_cartload2.</p>"},{"location":"vignettes/pipelines/visiumhd/#viewexplore","title":"View/Explore","text":"<p>The output are available in both CartoScope. </p> <p>Explore in CartoScope</p>"},{"location":"vignettes/pipelines/xenium/","title":"Xenium End-to-End Pipeline","text":""},{"location":"vignettes/pipelines/xenium/#overview","title":"Overview","text":"<p>This tutorial walks through end\u2011to\u2011end processing of 10x Xenium data with <code>CartLoader</code>: converting inputs, running FICTURE, importing cell results and histology, packaging assets, and uploading to AWS for sharing.</p>"},{"location":"vignettes/pipelines/xenium/#input-data","title":"Input Data","text":"<p>Data Structure and Format</p> <p>See details of the Xenium Ranger output at Xenium Ranger Official Documents</p> RAW Data StructureSGE FormatCell Analysis Result FormatMorphology images <pre><code>.\n\u251c\u2500\u2500 analysis\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 clustering\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 gene_expression_graphclust\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 clusters.csv\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 ...\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 diffexp\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 gene_expression_graphclust\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 differential_expression.csv\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 ...\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 pca\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 gene_expression_10_components\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 projection.csv\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 variance.csv\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 ...\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 umap\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 gene_expression_2_components\n\u2502\u00a0\u00a0         \u2514\u2500\u2500 projection.csv\n\u251c\u2500\u2500 cell_boundaries.csv.gz\n\u251c\u2500\u2500 cell_feature_matrix\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 barcodes.tsv.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 features.tsv.gz\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 matrix.mtx.gz\n\u251c\u2500\u2500 cells.csv.gz\n\u251c\u2500\u2500 morphology_focus\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 morphology_focus_0000.ome.tif\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 morphology_focus_0001.ome.tif\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 morphology_focus_0002.ome.tif\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 morphology_focus_0003.ome.tif\n\u251c\u2500\u2500 morphology.ome.tif\n\u251c\u2500\u2500 nucleus_boundaries.csv.gz\n\u251c\u2500\u2500 transcripts.parquet\n\u2514\u2500\u2500 ...\n</code></pre> <p>Naming Convention: <code>transcripts.csv.gz</code> or <code>transcripts.parquet</code></p> <pre><code>\"transcript_id\",\"cell_id\",\"overlaps_nucleus\",\"feature_name\",\"x_location\",\"y_location\",\"z_location\",\"qv\"\n281827164036151,133793,1,\"Sox10\",2350.0232,4153.6846,16.592316,40.0\n281827164036152,133793,1,\"Sox10\",2350.2585,4154.5225,17.237207,10.514394\n281827164036164,151216,0,\"Sox10\",2350.5874,4277.699,14.285685,40.0\n</code></pre> <ul> <li>\"<code>transcript_id</code>\": Unique identifier for each detected transcript molecule.  </li> <li>\"<code>cell_id</code>\": ID of the segmented cell associated with the transcript.</li> <li>\"<code>overlaps_nucleus</code>\": 1 if the transcript overlaps the nucleus mask, 0 otherwise.  </li> <li>\"<code>feature_name</code>\": Feature name corresponding to the transcript (typically a gene).</li> <li>\"<code>x_location</code>\": X coordinate of the transcript.  </li> <li>\"<code>y_location</code>\": Y coordinate of the transcript.  </li> <li>\"<code>z_location</code>\": Z coordinate (depth) of the transcript.  </li> <li>\"<code>qv</code>\": Quality value indicating confidence in transcript detection.</li> </ul> <p>Cells</p> <p>Naming Convention: <code>cells.csv.gz</code> <pre><code>\"cell_id\",\"x_centroid\",\"y_centroid\",\"transcript_counts\",\"control_probe_counts\",\"genomic_control_counts\",\"control_codeword_counts\",\"unassigned_codeword_counts\",\"deprecated_codeword_counts\",\"total_counts\",\"cell_area\",\"nucleus_area\",\"nucleus_count\",\"segmentation_method\"\n\"aaaagkdm-1\",170.85508728027344,2017.2412109375,1,0,0,0,0,0,1,46.285157930105925,NaN,0,\"Segmented by boundary stain (ATP1A1+CD45+E-Cadherin)\"\n\"aaaamcnn-1\",141.60569763183594,2481.442138671875,341,0,0,0,0,1,342,111.5359415486455,50.484689332544804,1,\"Segmented by boundary stain (ATP1A1+CD45+E-Cadherin)\"\n</code></pre></p> <p>Cell Boundaries</p> <p>Naming Convention: <code>cell_boundaries.csv.gz</code> <pre><code>\"cell_id\",\"vertex_x\",\"vertex_y\",\"label_id\"\n\"aaaagkdm-1\",169.3625,2013.0126,1\n\"aaaagkdm-1\",168.08751,2013.65,1\n</code></pre></p> <p>Clusters</p> <p>Naming Convention: <code>clusters.csv</code> <pre><code>Barcode,Cluster\naaaagkdm-1,1\naaaamcnn-1,10\n</code></pre></p> <p>Differentially Expressed Genes</p> <p>Naming Convention: <code>differential_expression.csv</code> <pre><code>Feature ID,Feature Name,Cluster 1 Mean Counts,Cluster 1 Log2 fold change,Cluster 1 Adjusted p value,Cluster 2 Mean Counts,Cluster 2 Log2 fold change,Cluster 2 Adjusted p value,Cluster 3 Mean Counts,Cluster 3 Log2 fold change,Cluster 3 Adjusted p value,Cluster 4 Mean Counts,Cluster 4 Log2 fold change,Cluster 4 Adjusted p value,Cluster 5 Mean Counts,Cluster 5 Log2 fold change,Cluster 5 Adjusted p value,Cluster 6 Mean Counts,Cluster 6 Log2 fold change,Cluster 6 Adjusted p value,Cluster 7 Mean Counts,Cluster 7 Log2 fold change,Cluster 7 Adjusted p value,Cluster 8 Mean Counts,Cluster 8 Log2 fold change,Cluster 8 Adjusted p value,Cluster 9 Mean Counts,Cluster 9 Log2 fold change,Cluster 9 Adjusted p value,Cluster 10 Mean Counts,Cluster 10 Log2 fold change,Cluster 10 Adjusted p value,Cluster 11 Mean Counts,Cluster 11 Log2 fold change,Cluster 11 Adjusted p value,Cluster 12 Mean Counts,Cluster 12 Log2 fold change,Cluster 12 Adjusted p value,Cluster 13 Mean Counts,Cluster 13 Log2 fold change,Cluster 13 Adjusted p value,Cluster 14 Mean Counts,Cluster 14 Log2 fold change,Cluster 14 Adjusted p value,Cluster 15 Mean Counts,Cluster 15 Log2 fold change,Cluster 15 Adjusted p value,Cluster 16 Mean Counts,Cluster 16 Log2 fold change,Cluster 16 Adjusted p value,Cluster 17 Mean Counts,Cluster 17 Log2 fold change,Cluster 17 Adjusted p value,Cluster 18 Mean Counts,Cluster 18 Log2 fold change,Cluster 18 Adjusted p value,Cluster 19 Mean Counts,Cluster 19 Log2 fold change,Cluster 19 Adjusted p value,Cluster 20 Mean Counts,Cluster 20 Log2 fold change,Cluster 20 Adjusted p value,Cluster 21 Mean Counts,Cluster 21 Log2 fold change,Cluster 21 Adjusted p value\nENSG00000166535,A2ML1,0.008082077992052654,2.292429464470433,0.000013831178435443352,0.0015317620832224837,-0.2717658073791789,0.16427980780868393,0.001226843332106492,-0.42095084864144816,0.46975425102829566,0.0037832334823669654,1.1762824711906763,0.00626099448573822,0.0009370316994608665,-0.9931426193918895,0.00012420457106652693,0.00035171591775058056,-1.9689174885349274,0.002636099946030819,0.0018219664759913663,0.0766263739653219,0.8995675333094153,0.0009475336160580633,-0.8343888826514707,0.06727367639920934,0.004361559793501598,1.5130532082572863,0.0000000000007537933872968394,0.000846294895303063,-0.992227102994244,0.028453359285143767,0.0018146574418219585,0.051194655215844875,0.9304123002179088,0.00045951336258476185,-1.7421234527453535,0.0013628094548944181,0.0023563153416359694,0.4774816523131893,0.2965413340700354,0.0021212060341883753,0.30481838952695206,0.4926601159653632,0.0014237107155417482,-0.14271909128282623,0.8500806231615298,0.0012562334587749313,-0.3507612852540696,0.6384951496662045,0.002355140186915884,0.5936824059089432,0.6436592400308225,0,-1.0564604491458525,0.697077988750366,0.0037541549892459126,1.6545227197901715,0.5114958184195594,0.0016831868337385438,0.9092558204592383,0.9557130750504969,0.004746991923520686,1.8259931272624748,0.4816191969175982\nENSG00000127837,AAMP,0.02869137687178692,-0.8208377939888187,0.06947481704069494,0.05848830321855647,0.25792687547836657,0.000740291628904809,0.046865415286467996,-0.1268733751597546,0.6859200637377005,0.046074379195969115,-0.1512653200377807,0.6321779498139667,0.06118265802362128,0.30246337282765,0.0011664010874126614,0.04560583066832528,-0.16756035764778598,0.5238325039655534,0.04598894691123035,-0.1611154993878925,0.345954046837975,0.05053512618976337,-0.016703446006141043,0.9871126969288548,0.059006871437084114,0.22791702658442592,0.05960885422623999,0.039698924179670955,-0.37956919506107756,0.02819556072921432,0.04670928255249721,-0.14454178156232,0.25704529967821615,0.04383757479058628,-0.2287656138945824,0.27728049168587215,0.0438060443058687,-0.22809983947157075,0.3116469017790129,0.04846634393266772,-0.08105776515758922,0.7319004973492986,0.029694537781299317,-0.7865793618218326,0.010641440414438465,0.03062069055763895,-0.7473835397757735,0.004183261794659202,0.04811214953271021,-0.08023857624188224,0.9971333031823112,0.036316690185246366,-0.46370796224802824,0.8420547873597443,0.018770774946229564,-1.3137594249747053,0.5160056939276148,0.038713297175986504,-0.34422202322342965,1,0.045887588594033295,-0.11087224163191323,1\n</code></pre></p> <p>Xenium output comes with tissue morphology images in OME\u2011TIFF, either nuclei\u2011only (DAPI) or multimodal (DAPI with cell boundary and interior stains). Each file uses a tiled, pyramidal layout (JPEG\u20112000, 16\u2011bit grayscale) with levels from full resolution down to 256\u00d7256 for efficient interactive viewing.</p> <ul> <li><code>morphology.ome.tif</code>: A 3D Z-stack of the DAPI image.</li> <li><code>morphology_focus_0000.ome.tif</code>: DAPI image</li> <li><code>morphology_focus_0001.ome.tif</code>: Boundary (ATP1A1/E\u2011Cadherin/CD45)</li> <li><code>morphology_focus_0002.ome.tif</code>: Interior \u2014 RNA (18S)</li> <li><code>morphology_focus_0003.ome.tif</code>: Interior \u2014 protein (alphaSMA/Vimentin)</li> <li><code>morphology_mip.ome.tif</code>: DAPI maximum intensity projection (MIP) of the Z\u2011stack.</li> </ul> <p>Data Access</p> <p>Downloaded the ST data from 10x Genomics Dataset portal.</p>"},{"location":"vignettes/pipelines/xenium/#set-up-the-environment","title":"Set Up the Environment","text":"<p>Pre-installed tools</p> <p>Please ensure you have installed all required tools (See Installation).</p> <p>Define paths to all required binaries and resources. Optionally, specify a fixed color map for consistent rendering.</p> <pre><code># ====\n# Replace each placeholder with the actual path on your system.  \n# ====\n\nwork_dir=/path/to/work/directory        # path to work directory that contains the downloaded input data\ncd $work_dir\n\n# Define paths to required binaries and resources\nspatula=/path/to/spatula/binary         # path to spatula executable\npunkst=/path/to/punkst/binary           # path to FICTURE2 (punkst) executable\ntippecanoe=/path/to/tippecanoe/binary   # path to tippecanoe executable\npmtiles=/path/to/pmtiles/binary         # path to pmtiles executable\naws=/path/to/aws/cli/binary             # path to AWS CLI binary\n\n# (Optional) Define path to color map. \ncmap=/path/to/color/map                 # Path to fixed color map. `CartLoader` includes one at cartloader/assets/fixed_color_map_256.tsv.\n\n# Number of jobs\nn_jobs=10                               # If not specified, the number of jobs defaults to 1.\n\n# Activate the bioconda environment\nconda activate ENV_NAME                 # replace ENV_NAME with your conda environment name\n</code></pre> <p>Define data ID and analysis parameters:</p> <pre><code># Unique identifier for your dataset\nDATA_ID=\"xenium-v1-humanlung-cancer-ffpe\"   # change this to reflect your dataset name\nSCALE=1                                     # coordinate to micrometer scaling factor\n\n# LDA parameters\ntrain_width=18                            # define LDA training hexagon width (comma-separated if multiple widths are applied)\nn_factor=24                               # define number of factors in LDA training (comma-separated if multiple n-factor are applied)\n\n# Path to AWS S3 directory\nS3_DIR=/s3/path/to/s3/dir                 # Recommend to use DATA_ID as directory name, such as s3://bucket-name/xenium-v1-humanlung-cancer-ffpe\n</code></pre> <p>How to Define Scaling Factors for Xenium?</p> <p>The Xenium example data currently used here provides SGE in \u00b5m. Define scaling factor from coordinate to micrometer as 1.</p>"},{"location":"vignettes/pipelines/xenium/#run-pipelines","title":"Run Pipelines","text":"<p>Below is an example of showing running all modules together. You can customize the actions by flags.</p> <p>In the following example, we only deployed OME_DAPI image. Alternatively, <code>CartLoader</code> supports a <code>--all-images</code> to deploy all detected image.</p> <pre><code>cartloader run_xenium \\\n  --load-xenium-ranger \\\n  --sge-convert \\\n  --run-ficture2 \\\n  --import-cells \\\n  --import-images \\\n  --run-cartload2 \\\n  --upload-aws \\\n  --xenium-ranger-dir /path/to/xenium/ranger/output \\\n  --out-dir /path/to/out/dir \\\n  --s3-dir ${S3_DIR} \\\n  --width ${train_width} \\\n  --n-factor ${n_factor} \\\n  --id ${DATA_ID} \\\n  --image-ids OME_DAPI \\\n  --spatula ${spatula} \\\n  --ficture2 ${punkst} \\\n  --pmtiles ${pmtiles} \\\n  --tippecanoe ${tippecanoe} \\\n  --aws ${aws} \\\n  --n-jobs ${n_jobs} \\\n  --threads ${n_jobs}\n</code></pre> <p>Action Flags to Enable Modules</p> <p>Actions</p> <p><code>run_xenium</code> runs multiple <code>CartLoader</code> modules together; enable and combine actions with flags.</p> <code>CartLoader</code> Modules Flags in <code>run_xenium</code> Actions Prerequisites <code>load_xenium_ranger</code> <code>--load-xenium-ranger</code> Summarize Xenium Ranger outputs into JSON Xenium Output files <code>sge_convert</code> <code>--sge-convert</code> Convert SGE to <code>CartLoader</code> format; optional density filter and visuals Xenium assets JSON (from <code>load_xenium_ranger</code>) or transcript CSV/Parquet <code>run_ficture2</code> <code>--run-ficture2</code> FICTURE analysis SGE (from <code>sge_convert</code>); FICTURE parameters (<code>--width</code>, <code>--n-factor</code>) <code>import_xenium_cell</code> <code>--import-cells</code> Import cell points, boundaries, cluster, de; Xenium assets JSON or manual CSVs; also <code>--cell-id</code> <code>import_image</code> <code>--import-images</code> Import background images (OME\u2011TIFF) \u2192 PNG/PMTiles; Xenium assets JSON or <code>--ome-tifs</code>; also <code>--image-ids</code>  or <code>--all-images</code> <code>run_cartload2</code> <code>--run-cartload2</code> Package SGE, optional FICTURE/cells/images into PMTiles; write <code>catalog.yaml</code> SGE, optional FICTURE assets or any imported cell/image assets; <code>--id</code> <code>upload_aws</code> <code>--upload-aws</code> Upload catalog and PMTiles to S3 <code>catalog.yaml</code> (from <code>run_cartload2</code>); <code>--s3-bucket</code>, <code>--id</code> <code>upload_zenodo</code> <code>--upload-zenodo</code> Upload catalog and PMTiles to Zenodo <code>catalog.yaml</code> (from <code>run_cartload2</code>); <code>--zenodo-token</code> <p>Parameter Requirements by Action Flag</p> <p>Below are explanations of the parameters used in the example. For the full list, see the <code>run_xenium</code> reference page.</p> Parameter Required when flags Description <code>--xenium-ranger-dir</code> <code>--load-xenium-ranger</code> Xenium Ranger output directory to scan. <code>--xenium-ranger-assets</code> optional <code>--load-xenium-ranger</code> Output JSON manifest path (defaults under <code>--out-dir</code>). <code>--width</code> <code>--run-ficture2</code> Hexagon width(s) in \u00b5m for training/projection. <code>--n-factor</code> <code>--run-ficture2</code> Factor count(s) for FICTURE training. <code>--cell-id</code> <code>--import-cells</code> Asset ID/prefix for cell outputs. <code>--image-ids</code> or <code>--all-images</code> <code>--import-images</code> Choose specific image IDs or import all detected. <code>--id</code> <code>--run-cartload2</code> Catalog ID (used in catalog.yaml and outputs). <code>--s3-dir</code> <code>--upload-aws</code> Destination S3 path (e.g., <code>s3://bucket/prefix</code>). <code>--out-dir</code> any action Output root directory for generated artifacts. <code>--dry-run</code>, <code>--restart</code> optional (any) Control execution (preview or rerun ignoring existing outputs). <code>--n-jobs</code>, <code>--threads</code> optional (any) Parallelism for Make/GDAL/tippecanoe steps."},{"location":"vignettes/pipelines/xenium/#outputs","title":"Outputs","text":"<p>See more details of output at the Reference pages for run_ficture2 and run_cartload2.</p>"},{"location":"vignettes/pipelines/xenium/#viewexplore","title":"View/Explore","text":"<p>The output are available in both CartoScope.</p> <p>Explore in CartoScope</p>"},{"location":"vignettes/quickstart/intro/","title":"Quick Start","text":"<p>Get started with <code>CartLoader</code> using a small mouse hippocampus dataset. Choose one of the options below.</p>"},{"location":"vignettes/quickstart/intro/#options","title":"Options","text":"<ul> <li> <p><ul> <li>  \ud83d\ude80 Run with Docker <p>Run <code>cartloader</code> inside a prebuilt Docker image.</p> <ul> <li>\u2705 No installation required</li> <li>\ud83d\udce6 Includes all dependencies</li> <li>\ud83e\uddea Preloaded input data</li> </ul> <p> Read</p> </li> <li> <p><ul> <li>  \ud83d\udd27 Run Locally <p>Install <code>cartloader</code> and dependencies on your system.</p> <ul> <li>\ud83d\udcbb Use latest <code>cartloader</code></li> <li>\u2699\ufe0f Full flexibility</li> <li>\ud83d\udcc2 Customize workflow</li> </ul> <p> Read</p> </li> </ul>"},{"location":"vignettes/quickstart/run_in_docker/","title":"\ud83d\ude80 Quick Start: Run with Docker","text":"<p>This tutorial walks through the <code>CartLoader</code> workflow \u2014 all packaged inside a prebuilt Docker image with dependencies and input data included.</p> <p>Use Cases</p> <p>This is the fastest and simplest way to try <code>CartLoader</code> \u2014 no setup, installation, or data download required.</p> <p>Requirements</p> <p>Users will need to:</p> <ul> <li>Set up <code>Docker</code> on their system (see Set Up Docker guide).</li> </ul>"},{"location":"vignettes/quickstart/run_in_docker/#set-up-docker","title":"Set Up Docker","text":"<p>If you are new to Docker, please refer to the Docker documentation for installation and basic usage.</p> <p>Verify whether Docker is properly set up on your system: <pre><code># Check if Docker is installed and show its version\ndocker --version\n\n# Test if Docker can successfully run a container\ndocker run hello-world\n</code></pre></p> <p>If these commands fail, install Docker in your system.</p>"},{"location":"vignettes/quickstart/run_in_docker/#input-data","title":"Input Data","text":"<p>The input is an mouse hippocampus SGE in a <code>FICTURE</code>-compatible format compatible, prepared by <code>sge_convert</code> in <code>CartLoader</code> .</p> <p>File Format</p> <code>transcripts.unsorted.tsv.gz</code>: transcript-indexed SGE in TSV <pre><code>X        Y        gene     count\n295.29   1422.35  Myo3a    0\n1745.54  1110.72  Med14    1\n1745.54  1110.72  Ntpcr    1\n</code></pre> <ul> <li><code>X</code>: X coordinates in um</li> <li><code>Y</code>: Y coordinates in um</li> <li><code>gene</code>: gene symbols</li> <li><code>count</code>: expression count per pixel per gene</li> </ul> <code>feature.clean.tsv.gz</code>: UMI counts on a per-gene basis in TSV <p><pre><code>gene           gene_id             count\nGm29155        ENSMUSG00000100764  1\nPcmtd1         ENSMUSG00000051285  431\nGm26901        ENSMUSG00000097797  1\n</code></pre> * <code>gene</code>: gene symbols * <code>gene_id</code>: gene IDs * <code>count</code>: expression count per gene</p> <code>coordinate_minmax.tsv</code>: X Y min/max coordinates <pre><code>xmin    0.14\nxmax    2359.90\nymin    0.23\nymax    1439.95\n</code></pre> <ul> <li><code>xmin</code> <code>xmax</code>: min and max X coordinates in um</li> <li><code>ymin</code> <code>ymax</code>: min and max Y coordinates in um</li> </ul> <p>Data Access</p> <p>Input data already included</p> <p>The example dataset is preloaded in the Docker image \u2014 no need to download separately.</p> <p>If needs, it is also available on Zenodo: DOI: 10.5281/zenodo.15701393</p>"},{"location":"vignettes/quickstart/run_in_docker/#set-up-the-environment","title":"Set Up the Environment","text":"<p>Fixed paths in the Docker Image</p> <p>Tools and dependencies have fixed paths in the Docker image (e.g., <code>/usr/local/bin/pmtiles</code>), which are used directly in the commands below. Skip specifying them manually.</p> <pre><code># ====\n# Replace each placeholder with the actual path on your system.  \n# ====\n\nwork_dir=/path/to/work/directory        # path to work directory that contains the downloaded input data\ncd $work_dir\n\n# Number of jobs\nn_jobs=10                               # If not specify, the number of jobs defaults to 1.\n\n# Unique identifier for your dataset\nDATA_ID=\"seqscope_hippo\"                # change this to reflect your dataset name\nPLATFORM=\"seqscope\"                     # platform information\n\n# LDA parameters\ntrain_width=18                           # define LDA training hexagon width (comma-separated if multiple widths are applied)\nn_factor=6,12                            # define number of factors in LDA training (comma-separated if multiple n-factor are applied)\n</code></pre>"},{"location":"vignettes/quickstart/run_in_docker/#ficture-analysis","title":"<code>FICTURE</code> Analysis","text":"<p>Compute spatial factors using <code>punkst</code> (FICTURE2 mode). See more details in Reference page.</p> <pre><code>docker run -it --rm \\\n  -v $(pwd):/data \\\n  weiqiuc/cartloader:20250708b \\\n  run_ficture2 \\\n    --makefn run_ficture2.mk \\\n    --main \\\n    --in-transcript /app/data/sge/transcripts.unsorted.tsv.gz \\\n    --in-feature /app/data/sge/feature.clean.tsv.gz \\\n    --in-minmax /app/data/sge/coordinate_minmax.tsv \\\n    --cmap-file /app/cartloader/assets/fixed_color_map_256.tsv \\\n    --exclude-feature-regex '^(mt-.*$|Gm\\d+$)' \\\n    --out-dir /data/ficture2 \\\n    --width ${train_width} \\\n    --n-factor ${n_factor} \\\n    --ficture2 /app/cartloader/submodules/punkst \\\n    --spatula /app/cartloader/submodules/spatula/bin/spatula \\\n    --n-jobs ${n_jobs} \\\n    --threads ${n_jobs}\n</code></pre> Parameter Required Type Description <code>--main</code> required <sup>1</sup> flag Enable <code>CartLoader</code> to run all five steps <code>--in-transcript</code> required string Path to input transcript-level SGE file <code>--out-dir</code> required string Path to output directory <code>--width</code> required int or comma-separated list LDA training hexagon width(s) <code>--n-factor</code> required int or comma-separated list Number of LDA factors <code>--makefn</code> string File name for the generated Makefile (default: <code>run_ficture2.mk</code> ) <code>--in-feature</code> string Path to input feature file <code>--in-minmax</code> string Path to input coordinate min/max file <code>--cmap-file</code> string Path to color map file <code>--exclude-feature-regex</code> regex Pattern to exclude features <code>--spatula</code> string Path to the <code>spatula</code> binary (default: <code>spatula</code>) <code>--ficture2</code> string Path to the <code>punkst</code> directory (defaults to <code>punkst</code> repository within <code>submodules</code> directory of  <code>CartLoader</code>) <code>--n-jobs</code> int Number of parallel jobs (default: <code>1</code>) <code>--threads</code> int Number of threads per job (default: <code>1</code>) <p><sub><sup>1</sup>: <code>CartLoader</code> requires the user to specify at least one action. Available actions includes: <code>--tile</code> to run tiling step; <code>--segment</code> to run segmentation step; <code>--init-lda</code> to run LDA training step; <code>--decode</code> to run decoding step; <code>--summary</code> to run summarization step; <code>--main</code> to run all above five actions.</sub></p>"},{"location":"vignettes/quickstart/run_in_docker/#cartloader-asset-packaging","title":"<code>CartLoader</code> Asset Packaging","text":"<p>Generate pmtiles and web-compatible tile directories. See more details in Reference page.</p> <pre><code># Example: with FICTURE outputs\ndocker run -it --rm \\\n  -v $(pwd):/data \\\n  weiqiuc/cartloader:20250708b \\\n  run_cartload2 \\\n    --makefn run_cartload2.mk \\\n    --fic-dir /data/ficture2 \\\n    --out-dir /data/cartload2 \\\n    --id ${DATA_ID} \\\n    --spatula /app/cartloader/submodules/spatula/bin/spatula \\\n    --pmtiles /usr/local/bin/pmtiles \\\n    --tippecanoe /usr/local/bin/tippecanoe \\\n    --n-jobs ${n_jobs} \\\n    --threads ${n_jobs}\n\n# Example: SGE-only packaging\ndocker run -it --rm \\\n  -v $(pwd):/data \\\n  weiqiuc/cartloader:20250708b \\\n  run_cartload2 \\\n    --makefn run_cartload2.mk \\\n    --sge-dir /data/sge_convert \\\n    --out-dir /data/cartload2 \\\n    --id ${DATA_ID} \\\n    --spatula /app/cartloader/submodules/spatula/bin/spatula \\\n    --pmtiles /usr/local/bin/pmtiles \\\n    --tippecanoe /usr/local/bin/tippecanoe \\\n    --n-jobs ${n_jobs} \\\n    --threads ${n_jobs}\n</code></pre> Parameter Required Type Description <code>--out-dir</code> required string Path to the output directory for PMTiles and web tiles <code>--id</code> required string Dataset ID used for naming outputs and metadata <code>--fic-dir</code> string Path to FICTURE outputs (enables factor layers + molecule\u2013factor joins) <code>--sge-dir</code> string Path to SGE outputs from <code>sge_convert</code> (enables SGE-only packaging) <code>--in-sge-assets</code> string File name of SGE assets JSON/YAML in <code>--sge-dir</code> (default: <code>sge_assets.json</code>) <code>--in-fic-params</code> string File name of FICTURE params JSON/YAML in <code>--fic-dir</code> (default: <code>ficture.params.json</code>) <code>--makefn</code> string File name for the generated Makefile (default: <code>run_cartload2.mk</code>) <code>--spatula</code> string Path to the <code>spatula</code> binary (default: <code>spatula</code>) <code>--pmtiles</code> string Path to the <code>pmtiles</code> binary (default: <code>pmtiles</code>) <code>--tippecanoe</code> string Path to the <code>tippecanoe</code> binary (default: <code>tippecanoe</code>) <code>--n-jobs</code> int Number of parallel jobs (default: <code>1</code>) <code>--threads</code> int Number of threads per job (default: <code>4</code>)"},{"location":"vignettes/quickstart/run_in_docker/#upload-to-data-repository","title":"Upload to Data Repository","text":"<p>Choose a data repository to host/share your output</p> <p><code>CartLoader</code> supports two upload options (<code>AWS</code> and <code>Zenodo</code>) for storing PMTiles of SGE and spatial factors in a data repository.</p> <p>Choose the one that best suits your needs.</p>"},{"location":"vignettes/quickstart/run_in_docker/#aws-uploads","title":"AWS Uploads","text":"<p>Upload the generated <code>CartLoader</code> outputs to your designated AWS S3 directory:</p> <pre><code># AWS S3 target location for cartostore\nAWS_BUCKET=\"EXAMPLE_AWS_BUCKET\"         # replace EXAMPLE_AWS_BUCKET with your actual S3 bucket name\n\ndocker run -it --rm \\\n  -v $(pwd):/data \\\n  weiqiuc/cartloader:20250708b \\\n  upload_aws \\\n    --in-dir /data/cartload2 \\\n    --s3-dir \"s3://${AWS_BUCKET}/${DATA_ID}\" \\\n    --aws /usr/local/bin/aws \\\n    --n-jobs ${n_jobs}\n</code></pre>"},{"location":"vignettes/quickstart/run_in_docker/#zenodo-uploads","title":"Zenodo Uploads","text":"<p>Upload the generated <code>CartLoader</code> outputs to your designated Zenodo deposition or a new deposition.</p> <pre><code>zenodo_token=/path/to/zenodo/token/file    # replace /path/to/zenodo/token/file by path to your zenodo token file\n\ndocker run -it --rm \\\n  -v $(pwd):/data \\\n  weiqiuc/cartloader:20250708b \\\n  upload_zenodo \\\n    --in-dir /data/cartload2 \\\n    --upload-method catalog \\\n    --zenodo-token ${zenodo_token} \\\n    --title  \"Your Title\" \\\n    --creators \"Your Name\" \\\n    --description \"This is an example description\"\n</code></pre> Parameter Required Type Description <code>--in-dir</code> required string Path to the input directory containing the <code>CartLoader</code> asset packaging output <code>--upload-method</code> required string Method to determine which files to upload. Options: <code>all</code> to upload all files in <code>--in-dir</code>; <code>catalog</code> to upload files listed in a catalog YAML file; <code>user_list</code> to upload files explicitly listed via <code>--in-list</code> <code>--catalog-yaml</code> string Required if <code>--upload-method catalog</code>. Path to <code>catalog.yaml</code> generated in <code>run_cartload2</code>. If absent, uses the catalog in the input directory specified by <code>--in-dir</code>. <code>--zenodo-token</code> required string Path to your Zenodo access token file <code>--title</code> required string Required when creating a new deposition (i.e., if <code>--zenodo-deposition-id</code> is omitted). Title for the new Zenodo deposition. <code>--creators</code> required list of str List of creators in \"Lastname, Firstname\" format."},{"location":"vignettes/quickstart/run_in_docker/#output-data","title":"Output Data","text":"<p>See more details of output at the Reference pages for run_ficture2 and run_cartload2.</p>"},{"location":"vignettes/quickstart/run_in_docker/#viewexplore","title":"View/Explore","text":"<p>The output are available in both CartoScope and Zenodo. </p> <p>Explore in CartoScope</p> <p>Download from Zenodo</p>"},{"location":"vignettes/quickstart/run_locally/","title":"\ud83d\udd27 Quick Start: Run Locally","text":"<p>This tutorial walks you through running the <code>CartLoader</code> workflow using a minimal example dataset from the mouse hippocampus.</p> <p>Use Cases</p> <p>This tutorial is ideal for users who want to:</p> <ul> <li>Take full control over the environment</li> <li>Customize workflow</li> <li>Stay up-to-date with the latest development versions </li> </ul> <p>Requirements</p> <p>Users will need to:</p> <ul> <li>Set up <code>CartLoader</code> and its dependencies locally (see Installation guide).</li> <li>Download the example input data (see Input Data)</li> </ul>"},{"location":"vignettes/quickstart/run_locally/#input-data","title":"Input Data","text":"<p>The input is a mouse hippocampus SGE, already converted to a format compatible with <code>FICTURE</code> using <code>sge_convert</code> in <code>CartLoader</code>.</p> <p>File Format</p> <p>SGE in FICTURE-compatible format includes:</p> <code>transcripts.unsorted.tsv.gz</code>: transcript-indexed SGE in TSV <pre><code>X        Y        gene     count\n295.29   1422.35  Myo3a    0\n1745.54  1110.72  Med14    1\n1745.54  1110.72  Ntpcr    1\n</code></pre> <ul> <li><code>X</code>: X coordinates in um</li> <li><code>Y</code>: Y coordinates in um</li> <li><code>gene</code>: gene symbols</li> <li><code>count</code>: expression count per pixel per gene</li> </ul> <code>feature.clean.tsv.gz</code>: UMI counts on a per-gene basis in TSV <p><pre><code>gene           gene_id             count\nGm29155        ENSMUSG00000100764  1\nPcmtd1         ENSMUSG00000051285  431\nGm26901        ENSMUSG00000097797  1\n</code></pre> * <code>gene</code>: gene symbols * <code>gene_id</code>: gene IDs * <code>count</code>: expression count per gene</p> <code>coordinate_minmax.tsv</code>: X Y min/max coordinates <pre><code>xmin    0.14\nxmax    2359.90\nymin    0.23\nymax    1439.95\n</code></pre> <ul> <li><code>xmin</code> <code>xmax</code>: min and max X coordinates in um</li> <li><code>ymin</code> <code>ymax</code>: min and max Y coordinates in um</li> </ul> <p>Data Access</p> <p>The input example data is hosted on Zenodo DOI: 10.5281/zenodo.15701393.</p> <p>Download the example data:</p> <pre><code>work_dir=/path/to/work/directory        # path to work directory that contains the downloaded input data\ncd $work_dir\n\nwget https://zenodo.org/records/17953582/files/seqscope_starter.std.tar.gz\ntar -zxvf seqscope_starter.std.tar.gz\n</code></pre>"},{"location":"vignettes/quickstart/run_locally/#set-up-the-environment","title":"Set Up the Environment","text":"<p>Pre-installed tools</p> <p>Please ensure you have installed all required tools (See Installation).</p> <p>Define paths to all required binaries and resources. Optionally, specify a fixed color map for consistent rendering.</p> <pre><code># ====\n# Replace each placeholder with the actual path on your system.  \n# ====\n\nwork_dir=/path/to/work/directory        # path to work directory that contains the downloaded input data\ncd $work_dir\n\n# Define paths to required binaries and resources\nspatula=/path/to/spatula/binary         # path to spatula executable\npunkst=/path/to/punkst/binary           # path to FICTURE2 (punkst) executable\ntippecanoe=/path/to/tippecanoe/binary   # path to tippecanoe executable\npmtiles=/path/to/pmtiles/binary         # path to pmtiles executable\naws=/path/to/aws/cli/binary             # path to AWS CLI binary\n\n# (Optional) Define path to color map. \ncmap=/path/to/color/map                 # Path to fixed color map. `CartLoader` includes one at cartloader/assets/fixed_color_map_256.tsv.\n\n# Number of jobs\nn_jobs=10                               # If not specified, the number of jobs defaults to 1.\n\n# Activate the bioconda environment\nconda activate ENV_NAME                 # replace ENV_NAME with your conda environment name\n</code></pre> <p>Define data ID and analysis parameters:</p> <pre><code># Unique identifier for your dataset\nDATA_ID=\"seqscope_hippo\"                # change this to reflect your dataset name\nPLATFORM=\"seqscope\"                     # platform information\n\n# LDA parameters\ntrain_width=18                           # define LDA training hexagon width (comma-separated if multiple widths are applied)\nn_factor=6,12                            # define number of factors in LDA training (comma-separated if multiple n-factor are applied)\n</code></pre>"},{"location":"vignettes/quickstart/run_locally/#ficture-analysis","title":"<code>FICTURE</code> Analysis","text":"<p>Compute spatial factors using <code>punkst</code> (FICTURE2 mode). See more details on the Reference page.</p> <pre><code>cartloader run_ficture2 \\\n  --makefn run_ficture2.mk \\\n  --main \\\n  --in-transcript ./sge/transcripts.unsorted.tsv.gz \\\n  --in-feature ./sge/feature.clean.tsv.gz \\\n  --in-minmax ./sge/coordinate_minmax.tsv \\\n  --cmap-file ${cmap} \\\n  --exclude-feature-regex '^(mt-.*$|Gm\\d+$)' \\\n  --out-dir ./ficture2 \\\n  --width ${train_width} \\\n  --n-factor ${n_factor} \\\n  --spatula ${spatula} \\\n  --ficture2 ${punkst} \\\n  --n-jobs ${n_jobs} \\\n  --threads ${n_jobs}\n</code></pre> Parameter Required Type Description <code>--main</code> required <sup>1</sup> flag Enable <code>CartLoader</code> to run all five steps <code>--in-transcript</code> required string Path to input transcript-level SGE file <code>--out-dir</code> required string Path to output directory <code>--width</code> required int or comma-separated list LDA training hexagon width(s) <code>--n-factor</code> required int or comma-separated list Number of LDA factors <code>--makefn</code> string File name for the generated Makefile (default: <code>run_ficture2.mk</code> ) <code>--in-feature</code> string Path to input feature file <code>--in-minmax</code> string Path to input coordinate min/max file <code>--cmap-file</code> string Path to color map file <code>--exclude-feature-regex</code> regex Pattern to exclude features <code>--spatula</code> string Path to the <code>spatula</code> binary (default: <code>spatula</code>) <code>--ficture2</code> string Path to the <code>punkst</code> directory (defaults to <code>punkst</code> repository within <code>submodules</code> directory of  <code>CartLoader</code>) <code>--n-jobs</code> int Number of parallel jobs (default: <code>1</code>) <code>--threads</code> int Number of threads per job (default: <code>1</code>) <p><sub><sup>1</sup>: <code>CartLoader</code> requires the user to specify at least one action. Available actions includes: <code>--tile</code> to run tiling step; <code>--segment</code> to run segmentation step; <code>--init-lda</code> to run LDA training step; <code>--decode</code> to run decoding step; <code>--summary</code> to run summarization step; <code>--main</code> to run all above five actions.</sub></p>"},{"location":"vignettes/quickstart/run_locally/#cartloader-asset-packaging","title":"<code>CartLoader</code> Asset Packaging","text":"<p>Generate pmtiles and web-compatible tile directories. See more details in Reference page.</p> <pre><code># Example A: With FICTURE outputs (integrates factors + joins)\ncartloader run_cartload2 \\\n  --makefn run_cartload2.mk \\\n  --fic-dir ./ficture2 \\\n  --out-dir ./cartload2 \\\n  --id ${DATA_ID} \\\n  --spatula ${spatula} \\\n  --pmtiles ${pmtiles} \\\n  --tippecanoe ${tippecanoe} \\\n  --n-jobs ${n_jobs} \\\n  --threads ${n_jobs}\n\n# Example B: SGE-only (package molecules without FICTURE)\ncartloader run_cartload2 \\\n  --makefn run_cartload2.mk \\\n  --sge-dir ./sge_convert \\\n  --out-dir ./cartload2 \\\n  --id ${DATA_ID} \\\n  --spatula ${spatula} \\\n  --pmtiles ${pmtiles} \\\n  --tippecanoe ${tippecanoe} \\\n  --n-jobs ${n_jobs} \\\n  --threads ${n_jobs}\n</code></pre> Parameter Required Type Description <code>--out-dir</code> required string Path to the output directory for PMTiles and web tiles <code>--id</code> required string Dataset ID used for naming outputs and metadata <code>--fic-dir</code> string Path to FICTURE outputs (enables factor layers + molecule\u2013factor joins) <code>--sge-dir</code> string Path to SGE outputs from <code>sge_convert</code> (enables SGE-only packaging) <code>--in-sge-assets</code> string File name of SGE assets JSON/YAML in <code>--sge-dir</code> (default: <code>sge_assets.json</code>) <code>--in-fic-params</code> string File name of FICTURE params JSON/YAML in <code>--fic-dir</code> (default: <code>ficture.params.json</code>) <code>--makefn</code> string File name for the generated Makefile (default: <code>run_cartload2.mk</code>) <code>--spatula</code> string Path to the <code>spatula</code> binary (default: <code>spatula</code>) <code>--pmtiles</code> string Path to the <code>pmtiles</code> binary (default: <code>pmtiles</code>) <code>--tippecanoe</code> string Path to the <code>tippecanoe</code> binary (default: <code>tippecanoe</code>) <code>--n-jobs</code> int Number of parallel jobs (default: <code>1</code>) <code>--threads</code> int Number of threads per job (default: <code>4</code>)"},{"location":"vignettes/quickstart/run_locally/#upload-to-data-repository","title":"Upload to Data Repository","text":"<p>Choose a data repository to host/share your output</p> <p><code>CartLoader</code> supports two upload options (<code>AWS</code> and <code>Zenodo</code>) for storing PMTiles of SGE and spatial factors in a data repository.</p> <p>Choose the one that best suits your needs.</p>"},{"location":"vignettes/quickstart/run_locally/#aws-uploads","title":"AWS Uploads","text":"<p>Upload the generated <code>CartLoader</code> outputs to your designated AWS S3 directory:</p> <pre><code># AWS S3 target location for cartostore\nS3_DIR=/s3/path/to/s3/dir              # Recommend to use DATA_ID as directory name, such as s3://bucket_name/xenium-v1-humanlung-cancer-ffpe\n\ncartloader upload_aws \\\n  --in-dir ./cartload2 \\\n  --s3-dir \"${S3_DIR}\" \\\n  --aws ${aws} \\\n  --n-jobs ${n_jobs}\n</code></pre> Parameter Required Type Description <code>--in-dir</code> required string Path to the input directory containing the <code>CartLoader</code> asset packaging output <code>--s3-dir</code> required string Path to the target S3 directory for uploading <code>--aws</code> string Path to the AWS CLI binary <code>--n-jobs</code> int Number of parallel jobs"},{"location":"vignettes/quickstart/run_locally/#zenodo-uploads","title":"Zenodo Uploads","text":"<p>Upload the generated <code>CartLoader</code> outputs to your designated Zenodo deposition or a new deposition.</p> <pre><code>zenodo_token=/path/to/zenodo/token/file    # replace /path/to/zenodo/token/file by path to your zenodo token file\n\ncartloader upload_zenodo \\\n  --in-dir ./cartload2 \\\n  --upload-method catalog \\\n  --zenodo-token $zenodo_token \\\n  --title  \"Your Title\" \\\n  --creators \"Your Name\" \\\n  --description \"This is an example description\"\n</code></pre> Parameter Required Type Description <code>--in-dir</code> required string Path to the input directory containing the <code>CartLoader</code> asset packaging output <code>--upload-method</code> required string Method to determine which files to upload. Options: <code>all</code> to upload all files in <code>--in-dir</code>; <code>catalog</code> to upload files listed in a catalog YAML file; <code>user_list</code> to upload files explicitly listed via <code>--in-list</code> <code>--catalog-yaml</code> string Required if <code>--upload-method catalog</code>. Path to <code>catalog.yaml</code> generated in <code>run_cartload2</code>. If absent, uses the catalog in the input directory specified by <code>--in-dir</code>. <code>--zenodo-token</code> required string Path to your Zenodo access token file <code>--title</code> required string Required when creating a new deposition (i.e., if <code>--zenodo-deposition-id</code> is omitted). Title for the new Zenodo deposition. <code>--creators</code> required list of str List of creators in \"Lastname, Firstname\" format."},{"location":"vignettes/quickstart/run_locally/#output-data","title":"Output Data","text":"<p>See more details of output at the Reference pages for run_ficture2 and run_cartload2.</p>"},{"location":"vignettes/quickstart/run_locally/#viewexplore","title":"View/Explore","text":"<p>The output are available in both CartoScope and Zenodo. </p> <p>Explore in CartoScope</p> <p>Download from Zenodo</p>"},{"location":"vignettes/subregion_tutorials/cosmxsmi/","title":"CosMX SMI Starter Tutorial","text":""},{"location":"vignettes/subregion_tutorials/cosmxsmi/#input-data","title":"Input Data","text":"<p>The input data is from an adult mouse hippocampus, extracted by masking a coronal brain section. The original full-section </p> <p>File Format</p> <p>NanoString CosMx SMI produces single\u2011molecule spatial transcriptomics data as a comma\u2011separated values (CSV) table.</p> <p>CSV File Format</p> <pre><code>\"fov\",\"cell_ID\",\"x_global_px\",\"y_global_px\",\"x_local_px\",\"y_local_px\",\"z\",\"target\",\"CellComp\"\n64,0,-473043,7954.533,4015.3,4246.2,1,\"Gfap\",\"None\"\n64,0,-473022.9,7902.723,4035.48,4194.39,1,\"Fth1\",\"None\"\n64,0,-473132,7836.476,3926.34,4128.143,1,\"Ptn\",\"None\"\n</code></pre> <ul> <li><code>fov</code>: The field of view (FOV) number.</li> <li><code>cell_ID</code>: Unique identifier for a single cell within a given FOV; 0 if background or unassigned molecules.</li> <li><code>x_global_px</code>, <code>y_global_px</code>: Global pixel coordinates relative to the tissue.</li> <li><code>x_local_px</code>, <code>y_local_px</code>: The x or y position (in pixels) relative to the given FOV.</li> <li><code>z</code>: Z-plane index representing the depth (optical section) where the transcript was detected.</li> <li><code>target</code>: Target name.</li> <li><code>CellComp</code>: Subcellular location of the target.</li> </ul> <p>Data Access</p> <p>The example data is hosted on Zenodo.</p> <p>Follow the commands below to download the example data.</p> <pre><code>work_dir=/path/to/work/directory\ncd $work_dir\nwget  https://zenodo.org/records/17953582/files/cosmxsmi_starter.raw.tar.gz\ntar --strip-components=1 -zxvf cosmxsmi_starter.raw.tar.gz\n</code></pre>"},{"location":"vignettes/subregion_tutorials/cosmxsmi/#set-up-the-environment","title":"Set Up the Environment","text":"<p>Pre-installed tools</p> <p>Please ensure you have installed all required tools (See Installation).</p> <p>Define paths to all required binaries and resources. Optionally, specify a fixed color map for consistent rendering.</p> <pre><code># ====\n# Replace each placeholder with the actual path on your system.  \n# ====\n\nwork_dir=/path/to/work/directory        # path to work directory that contains the downloaded input data\ncd $work_dir\n\n# Define paths to required binaries and resources\nspatula=/path/to/spatula/binary         # path to spatula executable\npunkst=/path/to/punkst/binary           # path to FICTURE2 (punkst) executable\ntippecanoe=/path/to/tippecanoe/binary   # path to tippecanoe executable\npmtiles=/path/to/pmtiles/binary         # path to pmtiles executable\naws=/path/to/aws/cli/binary             # path to AWS CLI binary\n\n# (Optional) Define path to color map. \ncmap=/path/to/color/map                 # Path to fixed color map. `CartLoader` includes one at cartloader/assets/fixed_color_map_256.tsv.\n\n# Number of jobs\nn_jobs=10                               # If not specified, the number of jobs defaults to 1.\n\n# Activate the bioconda environment\nconda activate ENV_NAME                 # replace ENV_NAME with your conda environment name\n</code></pre> <p>Define data ID and analysis parameters:</p> <pre><code># Unique identifier for your dataset\nDATA_ID=\"cosmxsmi_hippo\"                # change this to reflect your dataset name\nPLATFORM=\"cosmx_smi\"                    # platform information\nSCALE=$(echo 1000/120|bc -l)              # scale from coordinate to micrometer\n\n# LDA parameters\ntrain_width=12                           # define LDA training hexagon width (comma-separated if multiple widths are applied)\nn_factor=6,12                            # define number of factors in LDA training (comma-separated if multiple n-factor are applied)\n</code></pre> <p>How to Define Scaling Factors for CosMX SMI?</p> <p>According to the README.html provided with the Pixel-seq dataset, each pixel has an edge length of 120\u202fnm. To calculate the number of pixels per micrometer, use the formula: scale = 1000 / 120.</p>"},{"location":"vignettes/subregion_tutorials/cosmxsmi/#sge-format-conversion","title":"SGE Format Conversion","text":"<p>Convert the raw input to the unified SGE format. See more details in its Reference page.</p> <pre><code>cartloader sge_convert \\\n  --makefn sge_convert.mk \\\n  --platform ${PLATFORM} \\\n  --in-csv ./input.tsv.gz \\\n  --units-per-um ${SCALE} \\\n  --out-dir ./sge \\\n  --exclude-feature-regex '^(BLANK|Neg|Intergenic|Deprecated|Unassigned)' \\\n  --sge-visual \\\n  --spatula ${spatula} \\\n  --n-jobs ${n_jobs}\n</code></pre> Parameter Required Type Description <code>--platform</code> required string Platform (options: \"<code>10x_visium_hd</code>\", \"<code>seqscope</code>\", \"<code>10x_xenium</code>\", \"<code>bgi_stereoseq</code>\", \"<code>cosmx_smi</code>\", \"<code>vizgen_merscope</code>\", \"<code>pixel_seq</code>\", \"<code>generic</code>\") <code>--in-csv</code> required string Path to the input TSV/CSV file <code>--units-per-um</code> required float Scale to convert coordinates to microns (default: <code>1.0</code>) <code>--out-dir</code> required string Output directory for the converted SGE files <code>--makefn</code> string File name for the generated Makefile (default: <code>sge_convert.mk</code>) <code>--exclude-feature-regex</code> regex Pattern to exclude control features <code>--sge-visual</code> flag Enable SGE visualization step (generates diagnostic image) (default: <code>FALSE</code>) <code>--spatula</code> string Path to the spatula binary (default: <code>spatula</code>) <code>--n-jobs</code> int Number of parallel jobs for processing (default: <code>1</code>)"},{"location":"vignettes/subregion_tutorials/cosmxsmi/#ficture-analysis","title":"<code>FICTURE</code> Analysis","text":"<p>Compute spatial factors using <code>punkst</code> (FICTURE2 mode). See more details on the Reference page.</p> <pre><code>cartloader run_ficture2 \\\n  --makefn run_ficture2.mk \\\n  --main \\\n  --in-transcript ./sge/transcripts.unsorted.tsv.gz \\\n  --in-feature ./sge/feature.clean.tsv.gz \\\n  --in-minmax ./sge/coordinate_minmax.tsv \\\n  --cmap-file ${cmap} \\\n  --exclude-feature-regex '^(mt-.*$|Gm\\d+$)' \\\n  --out-dir ./ficture2 \\\n  --width ${train_width} \\\n  --n-factor ${n_factor} \\\n  --spatula ${spatula} \\\n  --ficture2 ${punkst} \\\n  --n-jobs ${n_jobs} \\\n  --threads ${n_jobs}\n</code></pre> Parameter Required Type Description <code>--main</code> required <sup>1</sup> flag Enable <code>CartLoader</code> to run all five steps <code>--in-transcript</code> required string Path to input transcript-level SGE file <code>--out-dir</code> required string Path to output directory <code>--width</code> required int or comma-separated list LDA training hexagon width(s) <code>--n-factor</code> required int or comma-separated list Number of LDA factors <code>--makefn</code> string File name for the generated Makefile (default: <code>run_ficture2.mk</code> ) <code>--in-feature</code> string Path to input feature file <code>--in-minmax</code> string Path to input coordinate min/max file <code>--cmap-file</code> string Path to color map file <code>--exclude-feature-regex</code> regex Pattern to exclude features <code>--spatula</code> string Path to the <code>spatula</code> binary (default: <code>spatula</code>) <code>--ficture2</code> string Path to the <code>punkst</code> directory (defaults to <code>punkst</code> repository within <code>submodules</code> directory of  <code>CartLoader</code>) <code>--n-jobs</code> int Number of parallel jobs (default: <code>1</code>) <code>--threads</code> int Number of threads per job (default: <code>1</code>) <p><sub><sup>1</sup>: <code>CartLoader</code> requires the user to specify at least one action. Available actions includes: <code>--tile</code> to run tiling step; <code>--segment</code> to run segmentation step; <code>--init-lda</code> to run LDA training step; <code>--decode</code> to run decoding step; <code>--summary</code> to run summarization step; <code>--main</code> to run all above five actions.</sub></p>"},{"location":"vignettes/subregion_tutorials/cosmxsmi/#cartloader-asset-packaging","title":"<code>CartLoader</code> Asset Packaging","text":"<p>Generate pmtiles and web-compatible tile directories. See more details in Reference page.</p> <pre><code># Example A: With FICTURE outputs (integrates factors + joins)\ncartloader run_cartload2 \\\n  --makefn run_cartload2.mk \\\n  --fic-dir ./ficture2 \\\n  --out-dir ./cartload2 \\\n  --id ${DATA_ID} \\\n  --spatula ${spatula} \\\n  --pmtiles ${pmtiles} \\\n  --tippecanoe ${tippecanoe} \\\n  --n-jobs ${n_jobs} \\\n  --threads ${n_jobs}\n\n# Example B: SGE-only (package molecules without FICTURE)\ncartloader run_cartload2 \\\n  --makefn run_cartload2.mk \\\n  --sge-dir ./sge_convert \\\n  --out-dir ./cartload2 \\\n  --id ${DATA_ID} \\\n  --spatula ${spatula} \\\n  --pmtiles ${pmtiles} \\\n  --tippecanoe ${tippecanoe} \\\n  --n-jobs ${n_jobs} \\\n  --threads ${n_jobs}\n</code></pre> Parameter Required Type Description <code>--out-dir</code> required string Path to the output directory for PMTiles and web tiles <code>--id</code> required string Dataset ID used for naming outputs and metadata <code>--fic-dir</code> string Path to FICTURE outputs (enables factor layers + molecule\u2013factor joins) <code>--sge-dir</code> string Path to SGE outputs from <code>sge_convert</code> (enables SGE-only packaging) <code>--in-sge-assets</code> string File name of SGE assets JSON/YAML in <code>--sge-dir</code> (default: <code>sge_assets.json</code>) <code>--in-fic-params</code> string File name of FICTURE params JSON/YAML in <code>--fic-dir</code> (default: <code>ficture.params.json</code>) <code>--makefn</code> string File name for the generated Makefile (default: <code>run_cartload2.mk</code>) <code>--spatula</code> string Path to the <code>spatula</code> binary (default: <code>spatula</code>) <code>--pmtiles</code> string Path to the <code>pmtiles</code> binary (default: <code>pmtiles</code>) <code>--tippecanoe</code> string Path to the <code>tippecanoe</code> binary (default: <code>tippecanoe</code>) <code>--n-jobs</code> int Number of parallel jobs (default: <code>1</code>) <code>--threads</code> int Number of threads per job (default: <code>4</code>)"},{"location":"vignettes/subregion_tutorials/cosmxsmi/#upload-to-data-repository","title":"Upload to Data Repository","text":"<p>Choose a data repository to host/share your output</p> <p><code>CartLoader</code> supports two upload options (<code>AWS</code> and <code>Zenodo</code>) for storing PMTiles of SGE and spatial factors in a data repository.</p> <p>Choose the one that best suits your needs.</p>"},{"location":"vignettes/subregion_tutorials/cosmxsmi/#aws-uploads","title":"AWS Uploads","text":"<p>Upload the generated <code>CartLoader</code> outputs to your designated AWS S3 directory:</p> <pre><code># AWS S3 target location for cartostore\nS3_DIR=/s3/path/to/s3/dir              # Recommend to use DATA_ID as directory name, such as s3://bucket_name/xenium-v1-humanlung-cancer-ffpe\n\ncartloader upload_aws \\\n  --in-dir ./cartload2 \\\n  --s3-dir \"${S3_DIR}\" \\\n  --aws ${aws} \\\n  --n-jobs ${n_jobs}\n</code></pre> Parameter Required Type Description <code>--in-dir</code> required string Path to the input directory containing the <code>CartLoader</code> asset packaging output <code>--s3-dir</code> required string Path to the target S3 directory for uploading <code>--aws</code> string Path to the AWS CLI binary <code>--n-jobs</code> int Number of parallel jobs"},{"location":"vignettes/subregion_tutorials/cosmxsmi/#zenodo-uploads","title":"Zenodo Uploads","text":"<p>Upload the generated <code>CartLoader</code> outputs to your designated Zenodo deposition or a new deposition.</p> <pre><code>zenodo_token=/path/to/zenodo/token/file    # replace /path/to/zenodo/token/file by path to your zenodo token file\n\ncartloader upload_zenodo \\\n  --in-dir ./cartload2 \\\n  --upload-method catalog \\\n  --zenodo-token $zenodo_token \\\n  --title  \"Your Title\" \\\n  --creators \"Your Name\" \\\n  --description \"This is an example description\"\n</code></pre> Parameter Required Type Description <code>--in-dir</code> required string Path to the input directory containing the <code>CartLoader</code> asset packaging output <code>--upload-method</code> required string Method to determine which files to upload. Options: <code>all</code> to upload all files in <code>--in-dir</code>; <code>catalog</code> to upload files listed in a catalog YAML file; <code>user_list</code> to upload files explicitly listed via <code>--in-list</code> <code>--catalog-yaml</code> string Required if <code>--upload-method catalog</code>. Path to <code>catalog.yaml</code> generated in <code>run_cartload2</code>. If absent, uses the catalog in the input directory specified by <code>--in-dir</code>. <code>--zenodo-token</code> required string Path to your Zenodo access token file <code>--title</code> required string Required when creating a new deposition (i.e., if <code>--zenodo-deposition-id</code> is omitted). Title for the new Zenodo deposition. <code>--creators</code> required list of str List of creators in \"Lastname, Firstname\" format."},{"location":"vignettes/subregion_tutorials/cosmxsmi/#output-data","title":"Output Data","text":"<p>See more details of output at the Reference pages for run_ficture2 and run_cartload2.</p>"},{"location":"vignettes/subregion_tutorials/cosmxsmi/#viewexplore","title":"View/Explore","text":"<p>The output are available in both CartoScope and Zenodo. </p> <p>Explore in CartoScope</p> <p>Download from Zenodo</p>"},{"location":"vignettes/subregion_tutorials/merscope/","title":"Vizgen MERSCOPE Starter Tutorial","text":""},{"location":"vignettes/subregion_tutorials/merscope/#input-data","title":"Input Data","text":"<p>The input is a SGE dataset from the adult mouse hippocampus, extracted by masking a coronal brain section (Slice Number: 2\uff1bReplicate Number: 1; file: <code>detected_transcripts.csv</code>) from Vizgen MERSCOPE Neuroscience Showcase.</p> <p>File Format</p> <p>The MERSCOPE input SGE includes one comma\u2011delimited text file in the following format:</p> <p>CSV File Format</p> <pre><code>,barcode_id,global_x,global_y,global_z,x,y,fov,gene\n0,22,56.930107,3851.851,5.0,147.80061,1711.9067,0,Adgre1\n1,22,183.60107,3874.0085,5.0,1320.6799,1917.0692,0,Adgre1\n2,22,59.750736,3666.5576,5.0,132.66754,1844.2372,1,Adgre1\n</code></pre> <ul> <li>Column 1: Unique numeric index for each transcript within a field of view (non-consecutive, ascending).  </li> <li><code>barcode_id</code>: Zero-based index of the transcript barcode in the codebook; forms a composite key with <code>fov</code>.</li> <li><code>global_x</code>: Transcript x coordinates (\u00b5m) in the experimental region; may be negative due to alignment.  </li> <li><code>global_y</code>: Transcript y coordinates (\u00b5m) in the experimental region; may be negative due to alignment.  </li> <li><code>global_z</code>: Zero\u2011based z\u2011position index.</li> <li><code>x</code>: The x-coordinate of the transcript (\u00b5m), within the coordinate space of the field of view.</li> <li><code>y</code>: The y-coordinate of the transcript (\u00b5m), within the coordinate space of the field of view.</li> <li><code>fov</code>: Zero-based field of view index; forms a composite key with <code>barcode_id</code>.  </li> <li><code>gene</code>: Gene name associated with the transcript.</li> </ul> <p>Data Access</p> <p>The example data is hosted on Zenodo.</p> <p>Follow the commands below to download the example data.</p> <pre><code>work_dir=/path/to/work/directory\ncd $work_dir\nwget  https://zenodo.org/records/17953582/files/merscope_starter.raw.tar.gz\ntar --strip-components=1 -zxvf merscope_starter.raw.tar.gz\n</code></pre>"},{"location":"vignettes/subregion_tutorials/merscope/#set-up-the-environment","title":"Set Up the Environment","text":"<p>Pre-installed tools</p> <p>Please ensure you have installed all required tools (See Installation).</p> <p>Define paths to all required binaries and resources. Optionally, specify a fixed color map for consistent rendering.</p> <pre><code># ====\n# Replace each placeholder with the actual path on your system.  \n# ====\n\nwork_dir=/path/to/work/directory        # path to work directory that contains the downloaded input data\ncd $work_dir\n\n# Define paths to required binaries and resources\nspatula=/path/to/spatula/binary         # path to spatula executable\npunkst=/path/to/punkst/binary           # path to FICTURE2 (punkst) executable\ntippecanoe=/path/to/tippecanoe/binary   # path to tippecanoe executable\npmtiles=/path/to/pmtiles/binary         # path to pmtiles executable\naws=/path/to/aws/cli/binary             # path to AWS CLI binary\n\n# (Optional) Define path to color map. \ncmap=/path/to/color/map                 # Path to fixed color map. `CartLoader` includes one at cartloader/assets/fixed_color_map_256.tsv.\n\n# Number of jobs\nn_jobs=10                               # If not specified, the number of jobs defaults to 1.\n\n# Activate the bioconda environment\nconda activate ENV_NAME                 # replace ENV_NAME with your conda environment name\n</code></pre> <p>Define data ID and analysis parameters:</p> <pre><code># Unique identifier for your dataset\nDATA_ID=\"merscope_hippo\"                # change this to reflect your dataset name\nPLATFORM=\"vizgen_merscope\"              # platform information\nSCALE=1                                 # scale from coordinate to micrometer\n\n# LDA parameters\ntrain_width=12                           # define LDA training hexagon width (comma-separated if multiple widths are applied)\nn_factor=6,12                            # define number of factors in LDA training (comma-separated if multiple n-factor are applied)\n</code></pre> <p>How to Define Scaling Factors for MERSCOPE?</p> <p>The MERSCOPE example data currently used here provides SGE in \u00b5m. Define scaling factor from coordinate to micrometer as 1.</p>"},{"location":"vignettes/subregion_tutorials/merscope/#sge-format-conversion","title":"SGE Format Conversion","text":"<p>Convert the raw input to the unified SGE format. See more details in its Reference page.</p> <pre><code>cartloader sge_convert \\\n  --makefn sge_convert.mk \\\n  --platform ${PLATFORM} \\\n  --in-csv ./input.tsv.gz \\\n  --units-per-um ${SCALE} \\\n  --out-dir ./sge \\\n  --exclude-feature-regex '^(BLANK|Neg|Intergenic|Deprecated|Unassigned)' \\\n  --sge-visual \\\n  --spatula ${spatula} \\\n  --n-jobs ${n_jobs}\n</code></pre> Parameter Required Type Description <code>--platform</code> required string Platform (options: \"<code>10x_visium_hd</code>\", \"<code>seqscope</code>\", \"<code>10x_xenium</code>\", \"<code>bgi_stereoseq</code>\", \"<code>cosmx_smi</code>\", \"<code>vizgen_merscope</code>\", \"<code>pixel_seq</code>\", \"<code>generic</code>\") <code>--in-csv</code> required string Path to the input TSV/CSV file <code>--units-per-um</code> required float Scale to convert coordinates to microns (default: <code>1.0</code>) <code>--out-dir</code> required string Output directory for the converted SGE files <code>--makefn</code> string File name for the generated Makefile (default: <code>sge_convert.mk</code>) <code>--exclude-feature-regex</code> regex Pattern to exclude control features <code>--sge-visual</code> flag Enable SGE visualization step (generates diagnostic image) (default: <code>FALSE</code>) <code>--spatula</code> string Path to the spatula binary (default: <code>spatula</code>) <code>--n-jobs</code> int Number of parallel jobs for processing (default: <code>1</code>)"},{"location":"vignettes/subregion_tutorials/merscope/#ficture-analysis","title":"<code>FICTURE</code> Analysis","text":"<p>Compute spatial factors using <code>punkst</code> (FICTURE2 mode). See more details on the Reference page.</p> <pre><code>cartloader run_ficture2 \\\n  --makefn run_ficture2.mk \\\n  --main \\\n  --in-transcript ./sge/transcripts.unsorted.tsv.gz \\\n  --in-feature ./sge/feature.clean.tsv.gz \\\n  --in-minmax ./sge/coordinate_minmax.tsv \\\n  --cmap-file ${cmap} \\\n  --exclude-feature-regex '^(mt-.*$|Gm\\d+$)' \\\n  --out-dir ./ficture2 \\\n  --width ${train_width} \\\n  --n-factor ${n_factor} \\\n  --spatula ${spatula} \\\n  --ficture2 ${punkst} \\\n  --n-jobs ${n_jobs} \\\n  --threads ${n_jobs}\n</code></pre> Parameter Required Type Description <code>--main</code> required <sup>1</sup> flag Enable <code>CartLoader</code> to run all five steps <code>--in-transcript</code> required string Path to input transcript-level SGE file <code>--out-dir</code> required string Path to output directory <code>--width</code> required int or comma-separated list LDA training hexagon width(s) <code>--n-factor</code> required int or comma-separated list Number of LDA factors <code>--makefn</code> string File name for the generated Makefile (default: <code>run_ficture2.mk</code> ) <code>--in-feature</code> string Path to input feature file <code>--in-minmax</code> string Path to input coordinate min/max file <code>--cmap-file</code> string Path to color map file <code>--exclude-feature-regex</code> regex Pattern to exclude features <code>--spatula</code> string Path to the <code>spatula</code> binary (default: <code>spatula</code>) <code>--ficture2</code> string Path to the <code>punkst</code> directory (defaults to <code>punkst</code> repository within <code>submodules</code> directory of  <code>CartLoader</code>) <code>--n-jobs</code> int Number of parallel jobs (default: <code>1</code>) <code>--threads</code> int Number of threads per job (default: <code>1</code>) <p><sub><sup>1</sup>: <code>CartLoader</code> requires the user to specify at least one action. Available actions includes: <code>--tile</code> to run tiling step; <code>--segment</code> to run segmentation step; <code>--init-lda</code> to run LDA training step; <code>--decode</code> to run decoding step; <code>--summary</code> to run summarization step; <code>--main</code> to run all above five actions.</sub></p>"},{"location":"vignettes/subregion_tutorials/merscope/#cartloader-asset-packaging","title":"<code>CartLoader</code> Asset Packaging","text":"<p>Generate pmtiles and web-compatible tile directories. See more details in Reference page.</p> <pre><code># Example A: With FICTURE outputs (integrates factors + joins)\ncartloader run_cartload2 \\\n  --makefn run_cartload2.mk \\\n  --fic-dir ./ficture2 \\\n  --out-dir ./cartload2 \\\n  --id ${DATA_ID} \\\n  --spatula ${spatula} \\\n  --pmtiles ${pmtiles} \\\n  --tippecanoe ${tippecanoe} \\\n  --n-jobs ${n_jobs} \\\n  --threads ${n_jobs}\n\n# Example B: SGE-only (package molecules without FICTURE)\ncartloader run_cartload2 \\\n  --makefn run_cartload2.mk \\\n  --sge-dir ./sge_convert \\\n  --out-dir ./cartload2 \\\n  --id ${DATA_ID} \\\n  --spatula ${spatula} \\\n  --pmtiles ${pmtiles} \\\n  --tippecanoe ${tippecanoe} \\\n  --n-jobs ${n_jobs} \\\n  --threads ${n_jobs}\n</code></pre> Parameter Required Type Description <code>--out-dir</code> required string Path to the output directory for PMTiles and web tiles <code>--id</code> required string Dataset ID used for naming outputs and metadata <code>--fic-dir</code> string Path to FICTURE outputs (enables factor layers + molecule\u2013factor joins) <code>--sge-dir</code> string Path to SGE outputs from <code>sge_convert</code> (enables SGE-only packaging) <code>--in-sge-assets</code> string File name of SGE assets JSON/YAML in <code>--sge-dir</code> (default: <code>sge_assets.json</code>) <code>--in-fic-params</code> string File name of FICTURE params JSON/YAML in <code>--fic-dir</code> (default: <code>ficture.params.json</code>) <code>--makefn</code> string File name for the generated Makefile (default: <code>run_cartload2.mk</code>) <code>--spatula</code> string Path to the <code>spatula</code> binary (default: <code>spatula</code>) <code>--pmtiles</code> string Path to the <code>pmtiles</code> binary (default: <code>pmtiles</code>) <code>--tippecanoe</code> string Path to the <code>tippecanoe</code> binary (default: <code>tippecanoe</code>) <code>--n-jobs</code> int Number of parallel jobs (default: <code>1</code>) <code>--threads</code> int Number of threads per job (default: <code>4</code>)"},{"location":"vignettes/subregion_tutorials/merscope/#upload-to-data-repository","title":"Upload to Data Repository","text":"<p>Choose a data repository to host/share your output</p> <p><code>CartLoader</code> supports two upload options (<code>AWS</code> and <code>Zenodo</code>) for storing PMTiles of SGE and spatial factors in a data repository.</p> <p>Choose the one that best suits your needs.</p>"},{"location":"vignettes/subregion_tutorials/merscope/#aws-uploads","title":"AWS Uploads","text":"<p>Upload the generated <code>CartLoader</code> outputs to your designated AWS S3 directory:</p> <pre><code># AWS S3 target location for cartostore\nS3_DIR=/s3/path/to/s3/dir              # Recommend to use DATA_ID as directory name, such as s3://bucket_name/xenium-v1-humanlung-cancer-ffpe\n\ncartloader upload_aws \\\n  --in-dir ./cartload2 \\\n  --s3-dir \"${S3_DIR}\" \\\n  --aws ${aws} \\\n  --n-jobs ${n_jobs}\n</code></pre> Parameter Required Type Description <code>--in-dir</code> required string Path to the input directory containing the <code>CartLoader</code> asset packaging output <code>--s3-dir</code> required string Path to the target S3 directory for uploading <code>--aws</code> string Path to the AWS CLI binary <code>--n-jobs</code> int Number of parallel jobs"},{"location":"vignettes/subregion_tutorials/merscope/#zenodo-uploads","title":"Zenodo Uploads","text":"<p>Upload the generated <code>CartLoader</code> outputs to your designated Zenodo deposition or a new deposition.</p> <pre><code>zenodo_token=/path/to/zenodo/token/file    # replace /path/to/zenodo/token/file by path to your zenodo token file\n\ncartloader upload_zenodo \\\n  --in-dir ./cartload2 \\\n  --upload-method catalog \\\n  --zenodo-token $zenodo_token \\\n  --title  \"Your Title\" \\\n  --creators \"Your Name\" \\\n  --description \"This is an example description\"\n</code></pre> Parameter Required Type Description <code>--in-dir</code> required string Path to the input directory containing the <code>CartLoader</code> asset packaging output <code>--upload-method</code> required string Method to determine which files to upload. Options: <code>all</code> to upload all files in <code>--in-dir</code>; <code>catalog</code> to upload files listed in a catalog YAML file; <code>user_list</code> to upload files explicitly listed via <code>--in-list</code> <code>--catalog-yaml</code> string Required if <code>--upload-method catalog</code>. Path to <code>catalog.yaml</code> generated in <code>run_cartload2</code>. If absent, uses the catalog in the input directory specified by <code>--in-dir</code>. <code>--zenodo-token</code> required string Path to your Zenodo access token file <code>--title</code> required string Required when creating a new deposition (i.e., if <code>--zenodo-deposition-id</code> is omitted). Title for the new Zenodo deposition. <code>--creators</code> required list of str List of creators in \"Lastname, Firstname\" format."},{"location":"vignettes/subregion_tutorials/merscope/#output-data","title":"Output Data","text":"<p>See more details of output at the Reference pages for run_ficture2 and run_cartload2.</p>"},{"location":"vignettes/subregion_tutorials/merscope/#viewexplore","title":"View/Explore","text":"<p>The output are available in both CartoScope and Zenodo. </p> <p>Explore in CartoScope</p> <p>Download from Zenodo</p>"},{"location":"vignettes/subregion_tutorials/pixelseq/","title":"Pixel-Seq Starter Tutorial","text":""},{"location":"vignettes/subregion_tutorials/pixelseq/#input-data","title":"Input Data","text":"<p>Since the Pixel-Seq publication provides SGE data only from the mouse olfactory bulb and parabrachial nucleus \u2014 neither of which includes the hippocampus \u2014 we extract a subregion from the olfactory bulb as the input for this tutorial.</p> <p>File Format</p> <p>The Pixel-Seq SGE includes one tab-delimited text file, where each row represents a unique RNA molecule detected within a defined field of view (FOV), with associated genomic and spatial metadata.</p> <p>TSV file format</p> <pre><code>FOVx  FOVy  xcoord     ycoord     UMIs     SpatialBarcode            MapStrand  Chrom  Start      STARmapping        Counts  geneID              geneName  bioType                 intronRatio\n017   005   26691.5    5786.5     TAACGAA  AAGGTTCATACCTACGACTGTTAA  16         1      24613729   150M               1       ENSMUSG00000101111  Gm28437   unprocessed_pseudogene  0.00\n016   007   27590.25   4639.0815  TAATATA  AATGGCGCATTTTGCTGTTTAGGC  16         2      39001628   138M2341N12M       1       ENSMUSG00000062997  Rpl35     protein_coding          0.00\n018   006   25099.945  5621.8335  AGTTGTA  CTGCATATGTGTCACCTAGGTAGC  16         1      24615767   150M               1       ENSMUSG00000101249  Gm29216   unprocessed_pseudogene  0.00\n</code></pre> <ul> <li><code>FOVx</code>, <code>FOVy</code>: Field-of-view indices indicating the imaging tile coordinates in the x and y directions.</li> <li><code>xcoord</code>, <code>ycoord</code>: Spatial coordinates (in microns or pixels).</li> <li><code>UMIs</code>: Unique molecular identifier (UMI) sequence.</li> <li><code>SpatialBarcode</code>: Spatial barcode capturing the location and identity.</li> <li><code>MapStrand</code>: Indicates the strand orientation of the mapped read.</li> <li><code>Chrom</code>, <code>Start</code>: Chromosome number and start position of the mapped read on the genome.</li> <li><code>STARmapping</code>: Alignment pattern (CIGAR string) from the STAR aligner indicating how the transcript maps to the genome.</li> <li><code>Counts</code>: Number of times the UMI/gene combination was observed.</li> <li><code>geneID</code>, <code>geneName</code>: Ensembl gene ID and gene symbol.</li> <li><code>bioType</code>: Gene biotype.</li> <li><code>intronRatio</code>: Fraction of UMI counts assigned to intronic regions.</li> </ul> <p>Data Access</p> <p>The example data is hosted on Zenodo.</p> <p>Follow the commands below to download the example data.</p> <pre><code>work_dir=/path/to/work/directory\ncd $work_dir\nwget  https://zenodo.org/records/17953582/files/pixelseq_starter.raw.tar.gz \ntar --strip-components=1 -zxvf pixelseq_starter.raw.tar.gz \n</code></pre>"},{"location":"vignettes/subregion_tutorials/pixelseq/#set-up-the-environment","title":"Set Up the Environment","text":"<p>Pre-installed tools</p> <p>Please ensure you have installed all required tools (See Installation).</p> <p>Define paths to all required binaries and resources. Optionally, specify a fixed color map for consistent rendering.</p> <pre><code># ====\n# Replace each placeholder with the actual path on your system.  \n# ====\n\nwork_dir=/path/to/work/directory        # path to work directory that contains the downloaded input data\ncd $work_dir\n\n# Define paths to required binaries and resources\nspatula=/path/to/spatula/binary         # path to spatula executable\npunkst=/path/to/punkst/binary           # path to FICTURE2 (punkst) executable\ntippecanoe=/path/to/tippecanoe/binary   # path to tippecanoe executable\npmtiles=/path/to/pmtiles/binary         # path to pmtiles executable\naws=/path/to/aws/cli/binary             # path to AWS CLI binary\n\n# (Optional) Define path to color map. \ncmap=/path/to/color/map                 # Path to fixed color map. `CartLoader` includes one at cartloader/assets/fixed_color_map_256.tsv.\n\n# Number of jobs\nn_jobs=10                               # If not specified, the number of jobs defaults to 1.\n\n# Activate the bioconda environment\nconda activate ENV_NAME                 # replace ENV_NAME with your conda environment name\n</code></pre> <p>Define data ID and analysis parameters:</p> <pre><code># Unique identifier for your dataset\nDATA_ID=\"pixelseq_hippo\"                # change this to reflect your dataset name\nPLATFORM=\"pixel_seq\"                    # platform information\nSCALE=3.076923                        # scale from coordinate to micrometer\n\n# LDA parameters\ntrain_width=18                           # define LDA training hexagon width (comma-separated if multiple widths are applied)\nn_factor=6,12                            # define number of factors in LDA training (comma-separated if multiple n-factor are applied)\n</code></pre> <p>How to Define Scaling Factors for Pixel-Seq?</p> <p>In Pixel-Seq publication:</p> <p>\"Because polonies have varied sizes and shapes, to maximize the feature resolution we developed a base-calling pipeline to determine the major barcode species in each pixel (0.325 * 0.325 mm2) of gel images to construct a spatial barcode map\".</p> <p>Accordingly, we defined scale as 1/0.325 = 3.076923</p>"},{"location":"vignettes/subregion_tutorials/pixelseq/#sge-format-conversion","title":"SGE Format Conversion","text":"<p>Convert the raw input to the unified SGE format. See more details in its Reference page.</p> <pre><code>cartloader sge_convert \\\n  --makefn sge_convert.mk \\\n  --platform ${PLATFORM} \\\n  --in-csv ./input.tsv.gz \\\n  --units-per-um ${SCALE} \\\n  --out-dir ./sge \\\n  --exclude-feature-regex '^(BLANK|Neg|Intergenic|Deprecated|Unassigned)' \\\n  --sge-visual \\\n  --spatula ${spatula} \\\n  --n-jobs ${n_jobs}\n</code></pre> Parameter Required Type Description <code>--platform</code> required string Platform (options: \"<code>10x_visium_hd</code>\", \"<code>seqscope</code>\", \"<code>10x_xenium</code>\", \"<code>bgi_stereoseq</code>\", \"<code>cosmx_smi</code>\", \"<code>vizgen_merscope</code>\", \"<code>pixel_seq</code>\", \"<code>generic</code>\") <code>--in-csv</code> required string Path to the input TSV/CSV file <code>--units-per-um</code> required float Scale to convert coordinates to microns (default: <code>1.0</code>) <code>--out-dir</code> required string Output directory for the converted SGE files <code>--makefn</code> string File name for the generated Makefile (default: <code>sge_convert.mk</code>) <code>--exclude-feature-regex</code> regex Pattern to exclude control features <code>--sge-visual</code> flag Enable SGE visualization step (generates diagnostic image) (default: <code>FALSE</code>) <code>--spatula</code> string Path to the spatula binary (default: <code>spatula</code>) <code>--n-jobs</code> int Number of parallel jobs for processing (default: <code>1</code>)"},{"location":"vignettes/subregion_tutorials/pixelseq/#ficture-analysis","title":"<code>FICTURE</code> Analysis","text":"<p>Compute spatial factors using <code>punkst</code> (FICTURE2 mode). See more details on the Reference page.</p> <pre><code>cartloader run_ficture2 \\\n  --makefn run_ficture2.mk \\\n  --main \\\n  --in-transcript ./sge/transcripts.unsorted.tsv.gz \\\n  --in-feature ./sge/feature.clean.tsv.gz \\\n  --in-minmax ./sge/coordinate_minmax.tsv \\\n  --cmap-file ${cmap} \\\n  --exclude-feature-regex '^(mt-.*$|Gm\\d+$)' \\\n  --out-dir ./ficture2 \\\n  --width ${train_width} \\\n  --n-factor ${n_factor} \\\n  --spatula ${spatula} \\\n  --ficture2 ${punkst} \\\n  --n-jobs ${n_jobs} \\\n  --threads ${n_jobs}\n</code></pre> Parameter Required Type Description <code>--main</code> required <sup>1</sup> flag Enable <code>CartLoader</code> to run all five steps <code>--in-transcript</code> required string Path to input transcript-level SGE file <code>--out-dir</code> required string Path to output directory <code>--width</code> required int or comma-separated list LDA training hexagon width(s) <code>--n-factor</code> required int or comma-separated list Number of LDA factors <code>--makefn</code> string File name for the generated Makefile (default: <code>run_ficture2.mk</code> ) <code>--in-feature</code> string Path to input feature file <code>--in-minmax</code> string Path to input coordinate min/max file <code>--cmap-file</code> string Path to color map file <code>--exclude-feature-regex</code> regex Pattern to exclude features <code>--spatula</code> string Path to the <code>spatula</code> binary (default: <code>spatula</code>) <code>--ficture2</code> string Path to the <code>punkst</code> directory (defaults to <code>punkst</code> repository within <code>submodules</code> directory of  <code>CartLoader</code>) <code>--n-jobs</code> int Number of parallel jobs (default: <code>1</code>) <code>--threads</code> int Number of threads per job (default: <code>1</code>) <p><sub><sup>1</sup>: <code>CartLoader</code> requires the user to specify at least one action. Available actions includes: <code>--tile</code> to run tiling step; <code>--segment</code> to run segmentation step; <code>--init-lda</code> to run LDA training step; <code>--decode</code> to run decoding step; <code>--summary</code> to run summarization step; <code>--main</code> to run all above five actions.</sub></p>"},{"location":"vignettes/subregion_tutorials/pixelseq/#cartloader-asset-packaging","title":"<code>CartLoader</code> Asset Packaging","text":"<p>Generate pmtiles and web-compatible tile directories. See more details in Reference page.</p> <pre><code># Example A: With FICTURE outputs (integrates factors + joins)\ncartloader run_cartload2 \\\n  --makefn run_cartload2.mk \\\n  --fic-dir ./ficture2 \\\n  --out-dir ./cartload2 \\\n  --id ${DATA_ID} \\\n  --spatula ${spatula} \\\n  --pmtiles ${pmtiles} \\\n  --tippecanoe ${tippecanoe} \\\n  --n-jobs ${n_jobs} \\\n  --threads ${n_jobs}\n\n# Example B: SGE-only (package molecules without FICTURE)\ncartloader run_cartload2 \\\n  --makefn run_cartload2.mk \\\n  --sge-dir ./sge_convert \\\n  --out-dir ./cartload2 \\\n  --id ${DATA_ID} \\\n  --spatula ${spatula} \\\n  --pmtiles ${pmtiles} \\\n  --tippecanoe ${tippecanoe} \\\n  --n-jobs ${n_jobs} \\\n  --threads ${n_jobs}\n</code></pre> Parameter Required Type Description <code>--out-dir</code> required string Path to the output directory for PMTiles and web tiles <code>--id</code> required string Dataset ID used for naming outputs and metadata <code>--fic-dir</code> string Path to FICTURE outputs (enables factor layers + molecule\u2013factor joins) <code>--sge-dir</code> string Path to SGE outputs from <code>sge_convert</code> (enables SGE-only packaging) <code>--in-sge-assets</code> string File name of SGE assets JSON/YAML in <code>--sge-dir</code> (default: <code>sge_assets.json</code>) <code>--in-fic-params</code> string File name of FICTURE params JSON/YAML in <code>--fic-dir</code> (default: <code>ficture.params.json</code>) <code>--makefn</code> string File name for the generated Makefile (default: <code>run_cartload2.mk</code>) <code>--spatula</code> string Path to the <code>spatula</code> binary (default: <code>spatula</code>) <code>--pmtiles</code> string Path to the <code>pmtiles</code> binary (default: <code>pmtiles</code>) <code>--tippecanoe</code> string Path to the <code>tippecanoe</code> binary (default: <code>tippecanoe</code>) <code>--n-jobs</code> int Number of parallel jobs (default: <code>1</code>) <code>--threads</code> int Number of threads per job (default: <code>4</code>)"},{"location":"vignettes/subregion_tutorials/pixelseq/#upload-to-data-repository","title":"Upload to Data Repository","text":"<p>Choose a data repository to host/share your output</p> <p><code>CartLoader</code> supports two upload options (<code>AWS</code> and <code>Zenodo</code>) for storing PMTiles of SGE and spatial factors in a data repository.</p> <p>Choose the one that best suits your needs.</p>"},{"location":"vignettes/subregion_tutorials/pixelseq/#aws-uploads","title":"AWS Uploads","text":"<p>Upload the generated <code>CartLoader</code> outputs to your designated AWS S3 directory:</p> <pre><code># AWS S3 target location for cartostore\nS3_DIR=/s3/path/to/s3/dir              # Recommend to use DATA_ID as directory name, such as s3://bucket_name/xenium-v1-humanlung-cancer-ffpe\n\ncartloader upload_aws \\\n  --in-dir ./cartload2 \\\n  --s3-dir \"${S3_DIR}\" \\\n  --aws ${aws} \\\n  --n-jobs ${n_jobs}\n</code></pre> Parameter Required Type Description <code>--in-dir</code> required string Path to the input directory containing the <code>CartLoader</code> asset packaging output <code>--s3-dir</code> required string Path to the target S3 directory for uploading <code>--aws</code> string Path to the AWS CLI binary <code>--n-jobs</code> int Number of parallel jobs"},{"location":"vignettes/subregion_tutorials/pixelseq/#zenodo-uploads","title":"Zenodo Uploads","text":"<p>Upload the generated <code>CartLoader</code> outputs to your designated Zenodo deposition or a new deposition.</p> <pre><code>zenodo_token=/path/to/zenodo/token/file    # replace /path/to/zenodo/token/file by path to your zenodo token file\n\ncartloader upload_zenodo \\\n  --in-dir ./cartload2 \\\n  --upload-method catalog \\\n  --zenodo-token $zenodo_token \\\n  --title  \"Your Title\" \\\n  --creators \"Your Name\" \\\n  --description \"This is an example description\"\n</code></pre> Parameter Required Type Description <code>--in-dir</code> required string Path to the input directory containing the <code>CartLoader</code> asset packaging output <code>--upload-method</code> required string Method to determine which files to upload. Options: <code>all</code> to upload all files in <code>--in-dir</code>; <code>catalog</code> to upload files listed in a catalog YAML file; <code>user_list</code> to upload files explicitly listed via <code>--in-list</code> <code>--catalog-yaml</code> string Required if <code>--upload-method catalog</code>. Path to <code>catalog.yaml</code> generated in <code>run_cartload2</code>. If absent, uses the catalog in the input directory specified by <code>--in-dir</code>. <code>--zenodo-token</code> required string Path to your Zenodo access token file <code>--title</code> required string Required when creating a new deposition (i.e., if <code>--zenodo-deposition-id</code> is omitted). Title for the new Zenodo deposition. <code>--creators</code> required list of str List of creators in \"Lastname, Firstname\" format."},{"location":"vignettes/subregion_tutorials/pixelseq/#output-data","title":"Output Data","text":"<p>See more details of output at the Reference pages for run_ficture2 and run_cartload2.</p>"},{"location":"vignettes/subregion_tutorials/pixelseq/#viewexplore","title":"View/Explore","text":"<p>The output are available in both CartoScope and Zenodo. </p> <p>Explore in CartoScope</p> <p>Download from Zenodo</p>"},{"location":"vignettes/subregion_tutorials/seqscope/","title":"Seq-Scope Starter Tutorial","text":""},{"location":"vignettes/subregion_tutorials/seqscope/#input-data","title":"Input Data","text":"<p>This tutorial uses an example SGE from mouse hippocampus, extracted via spatial masking from a Seq-Scope coronal brain slice.</p> <p>File Format</p> <p>Actual input formats are platform-dependent. Please refer to the Vignettes for detailed input specifications by each platform.</p> <p>SeqScope provides SGE with three files:</p> <code>barcodes.tsv.gz</code> \u2013 spatial barcode metadata <pre><code>AAAACAAAAACCTTCTTCGGACACTGGTCT  1   20  1   1   295288  1422349 0,1,0,0,0\nAAAACAAAAATCCTGTTATACATGCCATGG  2   45  1   1   1745544 1110720 2,2,1,0,1\nAAAACAAAACACGGGAAAAAACTATAGGTG  3   58  1   1   887244  250820  7,7,5,0,1\n</code></pre> <ul> <li>Column 1: Sorted spatial barcodes</li> <li>Column 2: 1-based integer index of spatial barcodes, used in <code>matrix.mtx.gz</code></li> <li>Column 3: 1-based integer index from the full barcode that is in the STARsolo output</li> <li>Column 4: Lane ID (fixed as <code>1</code>)  </li> <li>Column 5: Tile ID (fixed as <code>1</code>)  </li> <li>Column 6: X-coordinates</li> <li>Column 7: Y-coordinates</li> <li>Column 8: Five comma-separated numbers denote the count per spatial barcode for \"Gene\", \"GeneFull\", \"Spliced\", \"Unspliced\", and \"Ambiguous\".</li> </ul> <code>features.tsv.gz</code> \u2013 feature metadata  <pre><code>ENSMUSG00000100764  Gm29155 1   1,1,1,0,0\nENSMUSG00000100635  Gm29157 2   0,0,0,0,0\nENSMUSG00000100480  Gm29156 3   0,0,0,0,0\n</code></pre> <ul> <li>Column 1: Feature ID</li> <li>Column 2: Feature symbol</li> <li>Column 3: 1-based integer index of genes, used in <code>matrix.mtx.gz</code></li> <li>Column 4: Five comma-separated numbers denote the count per gene \"Gene\", \"GeneFull\", \"Spliced\", \"Unspliced\", and \"Ambiguous\".</li> </ul> <code>matrix.mtx.gz</code> \u2013 expression count matrix  <pre><code>%%MatrixMarket matrix coordinate integer general\n%\n33989 2928173 5404336\n2487 1 0 1 0 0 0\n5104 2 1 1 0 0 1\n</code></pre> <ul> <li><code>Header</code>: Initial lines form the header, declaring the matrix's adherence to the Market Matrix (MTX) format, outlining its traits. This may include comments (lines beginning with <code>%</code>) for extra metadata, all marked by a \u201c%\u201d.</li> <li><code>Dimensions</code>: Following the header, the first line details the matrix dimensions: the count of rows (features), columns (barcodes), and non-zero entries.</li> <li><code>Data Entries</code>: After the dimensions, subsequent lines enumerate non\u2011zero entries in seven columns: row index (feature index), column index (barcode index), and five values (expression levels) corresponding to \"Gene\", \"GeneFull\", \"Spliced\", \"Unspliced\", and \"Ambiguous\".<ul> <li>\"Gene\": represents unique, confidently mapped transcript count (\"gene name\"-based);</li> <li>\"GeneFull\": denotes total transcript count assigned to gene (includes ambiguities).</li> </ul> </li> </ul> <p>Data Access</p> <p>The example data is hosted on Zenodo (10.5281/zenodo.17953582).</p> <p>Follow the commands below to download the example data.</p> <pre><code>work_dir=/path/to/work/directory\ncd $work_dir\nwget  https://zenodo.org/records/17953582/files/seqscope_starter.raw.tar.gz \ntar -zxvf seqscope_starter.raw.tar.gz \n</code></pre>"},{"location":"vignettes/subregion_tutorials/seqscope/#set-up-the-environment","title":"Set Up the Environment","text":"<p>Pre-installed tools</p> <p>Please ensure you have installed all required tools (See Installation).</p> <p>Define paths to all required binaries and resources. Optionally, specify a fixed color map for consistent rendering.</p> <pre><code># ====\n# Replace each placeholder with the actual path on your system.  \n# ====\n\nwork_dir=/path/to/work/directory        # path to work directory that contains the downloaded input data\ncd $work_dir\n\n# Define paths to required binaries and resources\nspatula=/path/to/spatula/binary         # path to spatula executable\npunkst=/path/to/punkst/binary           # path to FICTURE2 (punkst) executable\ntippecanoe=/path/to/tippecanoe/binary   # path to tippecanoe executable\npmtiles=/path/to/pmtiles/binary         # path to pmtiles executable\naws=/path/to/aws/cli/binary             # path to AWS CLI binary\n\n# (Optional) Define path to color map. \ncmap=/path/to/color/map                 # Path to fixed color map. `CartLoader` includes one at cartloader/assets/fixed_color_map_256.tsv.\n\n# Number of jobs\nn_jobs=10                               # If not specified, the number of jobs defaults to 1.\n\n# Activate the bioconda environment\nconda activate ENV_NAME                 # replace ENV_NAME with your conda environment name\n</code></pre> <p>Define data ID and analysis parameters:</p> <pre><code># Unique identifier for your dataset\nDATA_ID=\"seqscope_hippo\"                # change this to reflect your dataset name\nPLATFORM=\"seqscope\"                     # platform information\nSCALE=1000                              # scale from coordinate to micrometer\n\n# LDA parameters\ntrain_width=18                           # define LDA training hexagon width (comma-separated if multiple widths are applied)\nn_factor=6,12                            # define number of factors in LDA training (comma-separated if multiple n-factor are applied)\n</code></pre> <p>How to Define Scaling Factors for Seq-Scope?</p> <p>The latest SeqScope with an Illumina NovaSeq 6000 uses <code>NovaScope</code> pipeline to process sequencing data. <code>NovaScope</code> defaults to generate SGE at nanometer (nm) resolution, meaning each pixel corresponds to 1\u202fnm.</p> <p>Thus, use 1000 as scaling factor from coordinate to micrometer since 1000 nm = 1 \u00b5m.</p>"},{"location":"vignettes/subregion_tutorials/seqscope/#sge-format-conversion","title":"SGE Format Conversion","text":"<p>Convert the raw input to the unified SGE format. See more details in SGE Format Conversion.</p> <pre><code>cartloader sge_convert \\\n  --makefn sge_convert.mk \\\n  --platform ${PLATFORM} \\\n  --in-mex ./raw \\\n  --units-per-um ${SCALE} \\\n  --out-dir ./sge \\\n  --exclude-feature-regex '^(BLANK|NegCon|NegPrb)' \\\n  --sge-visual \\\n  --spatula ${spatula} \\\n  --n-jobs ${n_jobs}\n</code></pre> Parameter Required Type Description <code>--platform</code> required string Platform (options: <code>10x_visium_hd</code>, <code>seqscope</code>, <code>10x_xenium</code>, <code>bgi_stereoseq</code>, <code>cosmx_smi</code>, <code>vizgen_merscope</code>, <code>pixel_seq</code>, <code>generic</code>) <code>--in-mex</code> required string Path to the input MEX directory containing gene \u00d7 barcode matrix <code>--units-per-um</code> required float Scale to convert coordinates to microns (default: <code>1.0</code>) <code>--out-dir</code> required string Output directory for the converted SGE files <code>--makefn</code> string File name for the generated Makefile (default: <code>sge_convert.mk</code>) <code>--exclude-feature-regex</code> regex Pattern to exclude control features <code>--sge-visual</code> flag Enable SGE visualization step (generates a diagnostic image) (default: false) <code>--spatula</code> string Path to the spatula binary (default: <code>spatula</code>) <code>--n-jobs</code> int Number of parallel jobs for processing (default: <code>1</code>)"},{"location":"vignettes/subregion_tutorials/seqscope/#ficture-analysis","title":"<code>FICTURE</code> Analysis","text":"<p>Compute spatial factors using <code>punkst</code> (FICTURE2 mode). See more details on the Reference page.</p> <pre><code>cartloader run_ficture2 \\\n  --makefn run_ficture2.mk \\\n  --main \\\n  --in-transcript ./sge/transcripts.unsorted.tsv.gz \\\n  --in-feature ./sge/feature.clean.tsv.gz \\\n  --in-minmax ./sge/coordinate_minmax.tsv \\\n  --cmap-file ${cmap} \\\n  --exclude-feature-regex '^(mt-.*$|Gm\\d+$)' \\\n  --out-dir ./ficture2 \\\n  --width ${train_width} \\\n  --n-factor ${n_factor} \\\n  --spatula ${spatula} \\\n  --ficture2 ${punkst} \\\n  --n-jobs ${n_jobs} \\\n  --threads ${n_jobs}\n</code></pre> Parameter Required Type Description <code>--main</code> required <sup>1</sup> flag Enable <code>CartLoader</code> to run all five steps <code>--in-transcript</code> required string Path to input transcript-level SGE file <code>--out-dir</code> required string Path to output directory <code>--width</code> required int or comma-separated list LDA training hexagon width(s) <code>--n-factor</code> required int or comma-separated list Number of LDA factors <code>--makefn</code> string File name for the generated Makefile (default: <code>run_ficture2.mk</code> ) <code>--in-feature</code> string Path to input feature file <code>--in-minmax</code> string Path to input coordinate min/max file <code>--cmap-file</code> string Path to color map file <code>--exclude-feature-regex</code> regex Pattern to exclude features <code>--spatula</code> string Path to the <code>spatula</code> binary (default: <code>spatula</code>) <code>--ficture2</code> string Path to the <code>punkst</code> directory (defaults to <code>punkst</code> repository within <code>submodules</code> directory of  <code>CartLoader</code>) <code>--n-jobs</code> int Number of parallel jobs (default: <code>1</code>) <code>--threads</code> int Number of threads per job (default: <code>1</code>) <p><sub><sup>1</sup>: <code>CartLoader</code> requires the user to specify at least one action. Available actions includes: <code>--tile</code> to run tiling step; <code>--segment</code> to run segmentation step; <code>--init-lda</code> to run LDA training step; <code>--decode</code> to run decoding step; <code>--summary</code> to run summarization step; <code>--main</code> to run all above five actions.</sub></p>"},{"location":"vignettes/subregion_tutorials/seqscope/#cartloader-asset-packaging","title":"<code>CartLoader</code> Asset Packaging","text":"<p>Generate pmtiles and web-compatible tile directories. See more details in Reference page.</p> <pre><code># Example A: With FICTURE outputs (integrates factors + joins)\ncartloader run_cartload2 \\\n  --makefn run_cartload2.mk \\\n  --fic-dir ./ficture2 \\\n  --out-dir ./cartload2 \\\n  --id ${DATA_ID} \\\n  --spatula ${spatula} \\\n  --pmtiles ${pmtiles} \\\n  --tippecanoe ${tippecanoe} \\\n  --n-jobs ${n_jobs} \\\n  --threads ${n_jobs}\n\n# Example B: SGE-only (package molecules without FICTURE)\ncartloader run_cartload2 \\\n  --makefn run_cartload2.mk \\\n  --sge-dir ./sge_convert \\\n  --out-dir ./cartload2 \\\n  --id ${DATA_ID} \\\n  --spatula ${spatula} \\\n  --pmtiles ${pmtiles} \\\n  --tippecanoe ${tippecanoe} \\\n  --n-jobs ${n_jobs} \\\n  --threads ${n_jobs}\n</code></pre> Parameter Required Type Description <code>--out-dir</code> required string Path to the output directory for PMTiles and web tiles <code>--id</code> required string Dataset ID used for naming outputs and metadata <code>--fic-dir</code> string Path to FICTURE outputs (enables factor layers + molecule\u2013factor joins) <code>--sge-dir</code> string Path to SGE outputs from <code>sge_convert</code> (enables SGE-only packaging) <code>--in-sge-assets</code> string File name of SGE assets JSON/YAML in <code>--sge-dir</code> (default: <code>sge_assets.json</code>) <code>--in-fic-params</code> string File name of FICTURE params JSON/YAML in <code>--fic-dir</code> (default: <code>ficture.params.json</code>) <code>--makefn</code> string File name for the generated Makefile (default: <code>run_cartload2.mk</code>) <code>--spatula</code> string Path to the <code>spatula</code> binary (default: <code>spatula</code>) <code>--pmtiles</code> string Path to the <code>pmtiles</code> binary (default: <code>pmtiles</code>) <code>--tippecanoe</code> string Path to the <code>tippecanoe</code> binary (default: <code>tippecanoe</code>) <code>--n-jobs</code> int Number of parallel jobs (default: <code>1</code>) <code>--threads</code> int Number of threads per job (default: <code>4</code>)"},{"location":"vignettes/subregion_tutorials/seqscope/#upload-to-data-repository","title":"Upload to Data Repository","text":"<p>Choose a data repository to host/share your output</p> <p><code>CartLoader</code> supports two upload options (<code>AWS</code> and <code>Zenodo</code>) for storing PMTiles of SGE and spatial factors in a data repository.</p> <p>Choose the one that best suits your needs.</p>"},{"location":"vignettes/subregion_tutorials/seqscope/#aws-uploads","title":"AWS Uploads","text":"<p>Upload the generated <code>CartLoader</code> outputs to your designated AWS S3 directory:</p> <pre><code># AWS S3 target location for cartostore\nS3_DIR=/s3/path/to/s3/dir              # Recommend to use DATA_ID as directory name, such as s3://bucket_name/xenium-v1-humanlung-cancer-ffpe\n\ncartloader upload_aws \\\n  --in-dir ./cartload2 \\\n  --s3-dir \"${S3_DIR}\" \\\n  --aws ${aws} \\\n  --n-jobs ${n_jobs}\n</code></pre> Parameter Required Type Description <code>--in-dir</code> required string Path to the input directory containing the <code>CartLoader</code> asset packaging output <code>--s3-dir</code> required string Path to the target S3 directory for uploading <code>--aws</code> string Path to the AWS CLI binary <code>--n-jobs</code> int Number of parallel jobs"},{"location":"vignettes/subregion_tutorials/seqscope/#zenodo-uploads","title":"Zenodo Uploads","text":"<p>Upload the generated <code>CartLoader</code> outputs to your designated Zenodo deposition or a new deposition.</p> <pre><code>zenodo_token=/path/to/zenodo/token/file    # replace /path/to/zenodo/token/file by path to your zenodo token file\n\ncartloader upload_zenodo \\\n  --in-dir ./cartload2 \\\n  --upload-method catalog \\\n  --zenodo-token $zenodo_token \\\n  --title  \"Your Title\" \\\n  --creators \"Your Name\" \\\n  --description \"This is an example description\"\n</code></pre> Parameter Required Type Description <code>--in-dir</code> required string Path to the input directory containing the <code>CartLoader</code> asset packaging output <code>--upload-method</code> required string Method to determine which files to upload. Options: <code>all</code> to upload all files in <code>--in-dir</code>; <code>catalog</code> to upload files listed in a catalog YAML file; <code>user_list</code> to upload files explicitly listed via <code>--in-list</code> <code>--catalog-yaml</code> string Required if <code>--upload-method catalog</code>. Path to <code>catalog.yaml</code> generated in <code>run_cartload2</code>. If absent, uses the catalog in the input directory specified by <code>--in-dir</code>. <code>--zenodo-token</code> required string Path to your Zenodo access token file <code>--title</code> required string Required when creating a new deposition (i.e., if <code>--zenodo-deposition-id</code> is omitted). Title for the new Zenodo deposition. <code>--creators</code> required list of str List of creators in \"Lastname, Firstname\" format."},{"location":"vignettes/subregion_tutorials/seqscope/#output-data","title":"Output Data","text":"<p>See more details of output at the Reference pages for run_ficture2 and run_cartload2.</p>"},{"location":"vignettes/subregion_tutorials/seqscope/#viewexplore","title":"View/Explore","text":"<p>The output are available in both CartoScope and Zenodo. </p> <p>Explore in CartoScope</p> <p>Download from Zenodo</p>"},{"location":"vignettes/subregion_tutorials/stereoseq/","title":"StereoSeq Starter Tutorial","text":""},{"location":"vignettes/subregion_tutorials/stereoseq/#input-data","title":"Input Data","text":"<p>The input data represents mouse hippocampus. For demonstration purposes, we selected the adult mouse brain coronal section from the official release and extracted only the hippocampus region. The full-section data sourced from the Stereo-seq platform, as part of the MOSTA project.</p> <p>File Format</p> <p>Stereo\u2011seq SGE includes one tab\u2011delimited \u201cBin1\u201d gene expression matrix file:</p> <p>TSV File Format</p> <pre><code>geneID          x       y       MIDCounts\n0610005C13Rik   6632    9074    1\n0610005C13Rik   8651    8935    1\n0610005C13Rik   7228    12814   2\n</code></pre> <ul> <li><code>geneID</code>: Gene symbol.</li> <li><code>x</code>: X coordinate of each DNB on the capture chip.</li> <li><code>y</code>: Y coordinate of each DNB on the capture chip.</li> <li><code>MIDCounts</code>: UMI count for each gene at each DNB.</li> </ul> <p>Data Access</p> <p>The example data is hosted on Zenodo.</p> <p>Follow the commands below to download the example data.</p> <pre><code>work_dir=/path/to/work/directory\ncd $work_dir\nwget  https://zenodo.org/records/17953582/files/stereoseq_starter.raw.tar.gz \ntar --strip-components=1 -zxvf stereoseq_starter.raw.tar.gz  \n</code></pre>"},{"location":"vignettes/subregion_tutorials/stereoseq/#set-up-the-environment","title":"Set Up the Environment","text":"<p>Pre-installed tools</p> <p>Please ensure you have installed all required tools (See Installation).</p> <p>Define paths to all required binaries and resources. Optionally, specify a fixed color map for consistent rendering.</p> <pre><code># ====\n# Replace each placeholder with the actual path on your system.  \n# ====\n\nwork_dir=/path/to/work/directory        # path to work directory that contains the downloaded input data\ncd $work_dir\n\n# Define paths to required binaries and resources\nspatula=/path/to/spatula/binary         # path to spatula executable\npunkst=/path/to/punkst/binary           # path to FICTURE2 (punkst) executable\ntippecanoe=/path/to/tippecanoe/binary   # path to tippecanoe executable\npmtiles=/path/to/pmtiles/binary         # path to pmtiles executable\naws=/path/to/aws/cli/binary             # path to AWS CLI binary\n\n# (Optional) Define path to color map. \ncmap=/path/to/color/map                 # Path to fixed color map. `CartLoader` includes one at cartloader/assets/fixed_color_map_256.tsv.\n\n# Number of jobs\nn_jobs=10                               # If not specified, the number of jobs defaults to 1.\n\n# Activate the bioconda environment\nconda activate ENV_NAME                 # replace ENV_NAME with your conda environment name\n</code></pre> <p>Define data ID and analysis parameters:</p> <pre><code># Unique identifier for your dataset\nDATA_ID=\"stereoseq_hippo\"                # change this to reflect your dataset name\nPLATFORM=\"bgi_stereoseq\"                 # platform information\nSCALE=2                                  # scale from coordinate to micrometer\n\n# LDA parameters\ntrain_width=18                           # define LDA training hexagon width (comma-separated if multiple widths are applied)\nn_factor=6,12                            # define number of factors in LDA training (comma-separated if multiple n-factor are applied)\n</code></pre> <p>How to Define Scaling Factors for StereoSeq?</p> <p>According to the StereoSeq paper, the technology features spot sizes of approximately 220 nanometers in diameter with center-to-center distances of about 500 nanometers. Thus, each pixel corresponds to approximately 0.5 micrometers. The scaling factor from coordinate to \u00b5m is defined as 2.</p>"},{"location":"vignettes/subregion_tutorials/stereoseq/#sge-format-conversion","title":"SGE Format Conversion","text":"<p>Convert the raw input to the unified SGE format. See more details in its Reference page.</p> <pre><code>cartloader sge_convert \\\n  --makefn sge_convert.mk \\\n  --platform ${PLATFORM} \\\n  --in-csv ./input.tsv.gz \\\n  --units-per-um ${SCALE} \\\n  --out-dir ./sge \\\n  --exclude-feature-regex '^(BLANK|Neg|Intergenic|Deprecated|Unassigned)' \\\n  --sge-visual \\\n  --spatula ${spatula} \\\n  --n-jobs ${n_jobs}\n</code></pre> Parameter Required Type Description <code>--platform</code> required string Platform (options: \"<code>10x_visium_hd</code>\", \"<code>seqscope</code>\", \"<code>10x_xenium</code>\", \"<code>bgi_stereoseq</code>\", \"<code>cosmx_smi</code>\", \"<code>vizgen_merscope</code>\", \"<code>pixel_seq</code>\", \"<code>generic</code>\") <code>--in-csv</code> required string Path to the input TSV/CSV file <code>--units-per-um</code> required float Scale to convert coordinates to microns (default: <code>1.0</code>) <code>--out-dir</code> required string Output directory for the converted SGE files <code>--makefn</code> string File name for the generated Makefile (default: <code>sge_convert.mk</code>) <code>--exclude-feature-regex</code> regex Pattern to exclude control features <code>--sge-visual</code> flag Enable SGE visualization step (generates diagnostic image) (default: <code>FALSE</code>) <code>--spatula</code> string Path to the spatula binary (default: <code>spatula</code>) <code>--n-jobs</code> int Number of parallel jobs for processing (default: <code>1</code>)"},{"location":"vignettes/subregion_tutorials/stereoseq/#ficture-analysis","title":"<code>FICTURE</code> Analysis","text":"<p>Compute spatial factors using <code>punkst</code> (FICTURE2 mode). See more details on the Reference page.</p> <pre><code>cartloader run_ficture2 \\\n  --makefn run_ficture2.mk \\\n  --main \\\n  --in-transcript ./sge/transcripts.unsorted.tsv.gz \\\n  --in-feature ./sge/feature.clean.tsv.gz \\\n  --in-minmax ./sge/coordinate_minmax.tsv \\\n  --cmap-file ${cmap} \\\n  --exclude-feature-regex '^(mt-.*$|Gm\\d+$)' \\\n  --out-dir ./ficture2 \\\n  --width ${train_width} \\\n  --n-factor ${n_factor} \\\n  --spatula ${spatula} \\\n  --ficture2 ${punkst} \\\n  --n-jobs ${n_jobs} \\\n  --threads ${n_jobs}\n</code></pre> Parameter Required Type Description <code>--main</code> required <sup>1</sup> flag Enable <code>CartLoader</code> to run all five steps <code>--in-transcript</code> required string Path to input transcript-level SGE file <code>--out-dir</code> required string Path to output directory <code>--width</code> required int or comma-separated list LDA training hexagon width(s) <code>--n-factor</code> required int or comma-separated list Number of LDA factors <code>--makefn</code> string File name for the generated Makefile (default: <code>run_ficture2.mk</code> ) <code>--in-feature</code> string Path to input feature file <code>--in-minmax</code> string Path to input coordinate min/max file <code>--cmap-file</code> string Path to color map file <code>--exclude-feature-regex</code> regex Pattern to exclude features <code>--spatula</code> string Path to the <code>spatula</code> binary (default: <code>spatula</code>) <code>--ficture2</code> string Path to the <code>punkst</code> directory (defaults to <code>punkst</code> repository within <code>submodules</code> directory of  <code>CartLoader</code>) <code>--n-jobs</code> int Number of parallel jobs (default: <code>1</code>) <code>--threads</code> int Number of threads per job (default: <code>1</code>) <p><sub><sup>1</sup>: <code>CartLoader</code> requires the user to specify at least one action. Available actions includes: <code>--tile</code> to run tiling step; <code>--segment</code> to run segmentation step; <code>--init-lda</code> to run LDA training step; <code>--decode</code> to run decoding step; <code>--summary</code> to run summarization step; <code>--main</code> to run all above five actions.</sub></p>"},{"location":"vignettes/subregion_tutorials/stereoseq/#cartloader-asset-packaging","title":"<code>CartLoader</code> Asset Packaging","text":"<p>Generate pmtiles and web-compatible tile directories. See more details in Reference page.</p> <pre><code># Example A: With FICTURE outputs (integrates factors + joins)\ncartloader run_cartload2 \\\n  --makefn run_cartload2.mk \\\n  --fic-dir ./ficture2 \\\n  --out-dir ./cartload2 \\\n  --id ${DATA_ID} \\\n  --spatula ${spatula} \\\n  --pmtiles ${pmtiles} \\\n  --tippecanoe ${tippecanoe} \\\n  --n-jobs ${n_jobs} \\\n  --threads ${n_jobs}\n\n# Example B: SGE-only (package molecules without FICTURE)\ncartloader run_cartload2 \\\n  --makefn run_cartload2.mk \\\n  --sge-dir ./sge_convert \\\n  --out-dir ./cartload2 \\\n  --id ${DATA_ID} \\\n  --spatula ${spatula} \\\n  --pmtiles ${pmtiles} \\\n  --tippecanoe ${tippecanoe} \\\n  --n-jobs ${n_jobs} \\\n  --threads ${n_jobs}\n</code></pre> Parameter Required Type Description <code>--out-dir</code> required string Path to the output directory for PMTiles and web tiles <code>--id</code> required string Dataset ID used for naming outputs and metadata <code>--fic-dir</code> string Path to FICTURE outputs (enables factor layers + molecule\u2013factor joins) <code>--sge-dir</code> string Path to SGE outputs from <code>sge_convert</code> (enables SGE-only packaging) <code>--in-sge-assets</code> string File name of SGE assets JSON/YAML in <code>--sge-dir</code> (default: <code>sge_assets.json</code>) <code>--in-fic-params</code> string File name of FICTURE params JSON/YAML in <code>--fic-dir</code> (default: <code>ficture.params.json</code>) <code>--makefn</code> string File name for the generated Makefile (default: <code>run_cartload2.mk</code>) <code>--spatula</code> string Path to the <code>spatula</code> binary (default: <code>spatula</code>) <code>--pmtiles</code> string Path to the <code>pmtiles</code> binary (default: <code>pmtiles</code>) <code>--tippecanoe</code> string Path to the <code>tippecanoe</code> binary (default: <code>tippecanoe</code>) <code>--n-jobs</code> int Number of parallel jobs (default: <code>1</code>) <code>--threads</code> int Number of threads per job (default: <code>4</code>)"},{"location":"vignettes/subregion_tutorials/stereoseq/#upload-to-data-repository","title":"Upload to Data Repository","text":"<p>Choose a data repository to host/share your output</p> <p><code>CartLoader</code> supports two upload options (<code>AWS</code> and <code>Zenodo</code>) for storing PMTiles of SGE and spatial factors in a data repository.</p> <p>Choose the one that best suits your needs.</p>"},{"location":"vignettes/subregion_tutorials/stereoseq/#aws-uploads","title":"AWS Uploads","text":"<p>Upload the generated <code>CartLoader</code> outputs to your designated AWS S3 directory:</p> <pre><code># AWS S3 target location for cartostore\nS3_DIR=/s3/path/to/s3/dir              # Recommend to use DATA_ID as directory name, such as s3://bucket_name/xenium-v1-humanlung-cancer-ffpe\n\ncartloader upload_aws \\\n  --in-dir ./cartload2 \\\n  --s3-dir \"${S3_DIR}\" \\\n  --aws ${aws} \\\n  --n-jobs ${n_jobs}\n</code></pre> Parameter Required Type Description <code>--in-dir</code> required string Path to the input directory containing the <code>CartLoader</code> asset packaging output <code>--s3-dir</code> required string Path to the target S3 directory for uploading <code>--aws</code> string Path to the AWS CLI binary <code>--n-jobs</code> int Number of parallel jobs"},{"location":"vignettes/subregion_tutorials/stereoseq/#zenodo-uploads","title":"Zenodo Uploads","text":"<p>Upload the generated <code>CartLoader</code> outputs to your designated Zenodo deposition or a new deposition.</p> <pre><code>zenodo_token=/path/to/zenodo/token/file    # replace /path/to/zenodo/token/file by path to your zenodo token file\n\ncartloader upload_zenodo \\\n  --in-dir ./cartload2 \\\n  --upload-method catalog \\\n  --zenodo-token $zenodo_token \\\n  --title  \"Your Title\" \\\n  --creators \"Your Name\" \\\n  --description \"This is an example description\"\n</code></pre> Parameter Required Type Description <code>--in-dir</code> required string Path to the input directory containing the <code>CartLoader</code> asset packaging output <code>--upload-method</code> required string Method to determine which files to upload. Options: <code>all</code> to upload all files in <code>--in-dir</code>; <code>catalog</code> to upload files listed in a catalog YAML file; <code>user_list</code> to upload files explicitly listed via <code>--in-list</code> <code>--catalog-yaml</code> string Required if <code>--upload-method catalog</code>. Path to <code>catalog.yaml</code> generated in <code>run_cartload2</code>. If absent, uses the catalog in the input directory specified by <code>--in-dir</code>. <code>--zenodo-token</code> required string Path to your Zenodo access token file <code>--title</code> required string Required when creating a new deposition (i.e., if <code>--zenodo-deposition-id</code> is omitted). Title for the new Zenodo deposition. <code>--creators</code> required list of str List of creators in \"Lastname, Firstname\" format."},{"location":"vignettes/subregion_tutorials/stereoseq/#output-data","title":"Output Data","text":"<p>See more details of output at the Reference pages for run_ficture2 and run_cartload2.</p>"},{"location":"vignettes/subregion_tutorials/stereoseq/#viewexplore","title":"View/Explore","text":"<p>The output are available in both CartoScope and Zenodo. </p> <p>Explore in CartoScope</p> <p>Download from Zenodo</p>"},{"location":"vignettes/subregion_tutorials/visiumhd/","title":"10x VisiumHD Starter Tutorial","text":""},{"location":"vignettes/subregion_tutorials/visiumhd/#input-data","title":"Input Data","text":"<p>The input data originates from the mouse hippocampus and is extracted from an official release of mouse brain SGE data.</p> <p>File Format</p> <p>Visium HD slides use a 2\u00d72\u202f\u00b5m grid of barcoded squares (<code>square_002um</code>) for high-resolution spatial gene mapping. Use <code>filtered_feature_bc_matrix</code> to only process tissue-associated signals. </p> <p>ATTENTION</p> <p>The file\u2011format examples below use a sample Visium HD dataset. Paths, IDs, and values are illustrative and may not match the dataset used in this tutorial.</p> <p>SGE comprises several key files as below: </p> <code>filtered_feature_bc_matrix/barcodes.tsv.gz</code> \u2013 spatial barcode for tissue locations  <pre><code>s_002um_00639_00600-1\ns_002um_00923_01639-1\ns_002um_01050_01530-1\n</code></pre> <ul> <li>Column 1: Spatial barcodes corresponding to specific locations on the tissue section.</li> </ul> <code>filtered_feature_bc_matrix/features.tsv.gz</code> \u2013 feature metadata  <pre><code>ENSMUSG00000051951  Xkr4    Gene Expression\nENSMUSG00000025900  Rp1     Gene Expression\nENSMUSG00000025902  Sox17   Gene Expression\n</code></pre> <ul> <li>Column 1: Feature ID</li> <li>Column 2: Feature symbol</li> <li>Column 3: Feature type</li> </ul> <code>filtered_feature_bc_matrix/matrix.mtx.gz</code> \u2013 expression count matrix  <pre><code>%%MatrixMarket matrix coordinate integer general\n%\n19059 869411 11376563\n3606 1 1\n8957 1 1\n9733 1 1\n</code></pre> <ul> <li><code>Header</code>: Initial lines form the header, declaring the matrix's adherence to the Market Matrix (MTX) format, outlining its traits. This may include comments (lines beginning with <code>%</code>) for extra metadata, all marked by a \u201c%\u201d.</li> <li><code>Dimensions</code>: Following the header, the first line details the matrix dimensions: the count of rows (features), columns (barcodes), and non-zero entries.</li> <li><code>Data Entries</code>: Post-dimensions, subsequent lines enumerate non-zero entries in seven columns: row index (feature index), column index (barcode index), and one value presenting the expression count per barcode per feature.</li> </ul> <code>tissue_positions.parquet</code> \u2013 spatial barcode metadata  <pre><code>barcode                 in_tissue   array_row   array_col   pxl_row_in_fullres  pxl_col_in_fullres\ns_002um_00434_01637-1   1           434         1637        3396.371014         9125.919898\n</code></pre> <ul> <li><code>barcode</code>: Unique spatial barcode associated with each capture spot.</li> <li><code>in_tissue</code>: Binary flag (1 = in tissue, 0 = background) indicating whether the spot falls within the tissue boundary.</li> <li><code>array_row</code>, <code>array_col</code>: Integer indices representing the position of the spot on the capture array grid.</li> <li><code>pxl_row_in_fullres</code>, <code>pxl_col_in_fullres</code>: Floating point coordinates locating the spot in full-resolution tissue image pixels.</li> </ul> <code>scalefactors_json.json</code> \u2013 pixel-to-micrometer scaling factors  <pre><code>{\n    \"spot_diameter_fullres\": 7.303953797779634,\n    \"bin_size_um\": 2.0,\n    \"microns_per_pixel\": 0.2738242950835738,\n    \"regist_target_img_scalef\": 0.2505533,\n    \"tissue_lowres_scalef\": 0.02505533,\n    \"fiducial_diameter_fullres\": 1205.1523766336395,\n    \"tissue_hires_scalef\": 0.2505533\n}\n</code></pre> <ul> <li><code>spot_diameter_fullres</code>: Estimated diameter of a barcoded spot in full-resolution pixels.</li> <li><code>bin_size_um</code>: Physical size (in micrometers) of the smallest bin, typically 2.0\u202f\u00b5m for Visium HD.</li> <li><code>microns_per_pixel</code>: Resolution of the full-res image, used to convert pixel distances to micrometers.</li> <li><code>regist_target_img_scalef</code>: Scaling factor applied during image registration to the target image.</li> <li><code>tissue_lowres_scalef</code>: Downscaling factor from full-res to low-resolution tissue image.</li> <li><code>fiducial_diameter_fullres</code>: Diameter of fiducial markers in full-resolution pixels, useful for alignment.</li> <li><code>tissue_hires_scalef</code>: Downscaling factor from full-res to high-resolution tissue image.</li> </ul> <p>Data Access</p> <p>The example data is hosted on Zenodo.</p> <p>Follow the commands below to download the example data.</p> <pre><code>work_dir=/path/to/work/directory\ncd $work_dir\nwget  https://zenodo.org/records/17953582/files/visiumhd_starter.raw.tar.gz \ntar -zxvf visiumhd_starter.raw.tar.gz  \n</code></pre>"},{"location":"vignettes/subregion_tutorials/visiumhd/#set-up-the-environment","title":"Set Up the Environment","text":"<p>Pre-installed tools</p> <p>Please ensure you have installed all required tools (See Installation).</p> <p>Define paths to all required binaries and resources. Optionally, specify a fixed color map for consistent rendering.</p> <pre><code># ====\n# Replace each placeholder with the actual path on your system.  \n# ====\n\nwork_dir=/path/to/work/directory        # path to work directory that contains the downloaded input data\ncd $work_dir\n\n# Define paths to required binaries and resources\nspatula=/path/to/spatula/binary         # path to spatula executable\npunkst=/path/to/punkst/binary           # path to FICTURE2 (punkst) executable\ntippecanoe=/path/to/tippecanoe/binary   # path to tippecanoe executable\npmtiles=/path/to/pmtiles/binary         # path to pmtiles executable\naws=/path/to/aws/cli/binary             # path to AWS CLI binary\n\n# (Optional) Define path to color map. \ncmap=/path/to/color/map                 # Path to fixed color map. `CartLoader` includes one at cartloader/assets/fixed_color_map_256.tsv.\n\n# Number of jobs\nn_jobs=10                               # If not specified, the number of jobs defaults to 1.\n\n# Activate the bioconda environment\nconda activate ENV_NAME                 # replace ENV_NAME with your conda environment name\n</code></pre> <p>Define data ID and analysis parameters:</p> <pre><code># Unique identifier for your dataset\nDATA_ID=\"visiumhd_hippo\"                 # change this to reflect your dataset name\nPLATFORM=\"10x_visium_hd\"                 # platform information\n\n# LDA parameters\ntrain_width=18                           # define LDA training hexagon width (comma-separated if multiple widths are applied)\nn_factor=6,12                            # define number of factors in LDA training (comma-separated if multiple n-factor are applied)\n</code></pre> <p>How to Define Scaling Factors for Visium HD?</p> <p>10x Visium HD includes a <code>scalefactors_json.json</code> file that provides pixel-to-micrometer scaling information. <code>CartLoader</code> can directly accept this file via the <code>--scale-json</code> option and will automatically compute the appropriate scaling factor, omitting manually calculate and specify <code>--units-per-um</code>. </p> <p>Alternatively, users may bypass the JSON file by directly providing a value through the <code>--units-per-um</code> option.</p>"},{"location":"vignettes/subregion_tutorials/visiumhd/#sge-format-conversion","title":"SGE Format Conversion","text":"<p>Convert the raw input to the unified SGE format. See more details in its Reference page.</p> <pre><code>cartloader sge_convert \\\n  --makefn sge_convert.mk \\\n  --platform ${PLATFORM} \\\n  --in-mex ./raw \\\n  --in-parquet ./raw/tissue_positions.parquet \\\n  --scale-json ./raw/scalefactors_json.json \\\n  --out-dir ./sge \\\n  --exclude-feature-regex '^(BLANK|NegCon|NegPrb)' \\\n  --sge-visual \\\n  --spatula ${spatula} \\\n  --n-jobs ${n_jobs}\n</code></pre> Parameter Required Type Description <code>--platform</code> required string Platform (options: <code>10x_visium_hd</code>, <code>seqscope</code>, <code>10x_xenium</code>, <code>bgi_stereoseq</code>, <code>cosmx_smi</code>, <code>vizgen_merscope</code>, <code>pixel_seq</code>, <code>generic</code>) <code>--in-mex</code> required string Path to the input MEX directory containing gene \u00d7 barcode matrix <code>--in-parquet</code> required string Path to the <code>tissue_positions.parquet</code> file with spatial barcode metadata <code>--scale-json</code> required <sup>1</sup> string Path to the <code>scalefactors_json.json</code> file for coordinate scaling (or use <code>--units-per-um</code> to specify directly) <code>--out-dir</code> required string Output directory for the converted SGE files <code>--makefn</code> string File name for the generated Makefile (default: <code>sge_convert.mk</code>) <code>--exclude-feature-regex</code> regex Pattern to exclude control features <code>--sge-visual</code> flag Enable SGE visualization step (generates diagnostic image) (default: <code>FALSE</code>) <code>--spatula</code> string Path to the spatula binary (default: <code>spatula</code>) <code>--n-jobs</code> int Number of parallel jobs for processing (default: <code>1</code>) <p><sub><sup>1</sup>: To define the scaling factor, <code>CartLoader</code> requires either a JSON file (via <code>--scale-json</code>) or a direct scale value using <code>--units-per-um</code>. When using <code>--scale-json</code>, make sure the JSON file has <code>microns_per_pixel</code> information.</sub></p>"},{"location":"vignettes/subregion_tutorials/visiumhd/#ficture-analysis","title":"<code>FICTURE</code> Analysis","text":"Parameter Required Type Description <code>--main</code> required <sup>1</sup> flag Enable <code>CartLoader</code> to run all five steps <code>--in-transcript</code> required string Path to input transcript-level SGE file <code>--out-dir</code> required string Path to output directory <code>--width</code> required int or comma-separated list LDA training hexagon width(s) <code>--n-factor</code> required int or comma-separated list Number of LDA factors <code>--makefn</code> string File name for the generated Makefile (default: <code>run_ficture2.mk</code> ) <code>--in-feature</code> string Path to input feature file <code>--in-minmax</code> string Path to input coordinate min/max file <code>--cmap-file</code> string Path to color map file <code>--exclude-feature-regex</code> regex Pattern to exclude features <code>--spatula</code> string Path to the <code>spatula</code> binary (default: <code>spatula</code>) <code>--ficture2</code> string Path to the <code>punkst</code> directory (defaults to <code>punkst</code> repository within <code>submodules</code> directory of  <code>CartLoader</code>) <code>--n-jobs</code> int Number of parallel jobs (default: <code>1</code>) <code>--threads</code> int Number of threads per job (default: <code>1</code>) <p><sub><sup>1</sup>: <code>CartLoader</code> requires the user to specify at least one action. Available actions includes: <code>--tile</code> to run tiling step; <code>--segment</code> to run segmentation step; <code>--init-lda</code> to run LDA training step; <code>--decode</code> to run decoding step; <code>--summary</code> to run summarization step; <code>--main</code> to run all above five actions.</sub></p>"},{"location":"vignettes/subregion_tutorials/visiumhd/#cartloader-asset-packaging","title":"<code>CartLoader</code> Asset Packaging","text":"<p>Generate pmtiles and web-compatible tile directories. See more details in Reference page.</p> <pre><code># Example A: With FICTURE outputs (integrates factors + joins)\ncartloader run_cartload2 \\\n  --makefn run_cartload2.mk \\\n  --fic-dir ./ficture2 \\\n  --out-dir ./cartload2 \\\n  --id ${DATA_ID} \\\n  --spatula ${spatula} \\\n  --pmtiles ${pmtiles} \\\n  --tippecanoe ${tippecanoe} \\\n  --n-jobs ${n_jobs} \\\n  --threads ${n_jobs}\n\n# Example B: SGE-only (package molecules without FICTURE)\ncartloader run_cartload2 \\\n  --makefn run_cartload2.mk \\\n  --sge-dir ./sge_convert \\\n  --out-dir ./cartload2 \\\n  --id ${DATA_ID} \\\n  --spatula ${spatula} \\\n  --pmtiles ${pmtiles} \\\n  --tippecanoe ${tippecanoe} \\\n  --n-jobs ${n_jobs} \\\n  --threads ${n_jobs}\n</code></pre> Parameter Required Type Description <code>--out-dir</code> required string Path to the output directory for PMTiles and web tiles <code>--id</code> required string Dataset ID used for naming outputs and metadata <code>--fic-dir</code> string Path to FICTURE outputs (enables factor layers + molecule\u2013factor joins) <code>--sge-dir</code> string Path to SGE outputs from <code>sge_convert</code> (enables SGE-only packaging) <code>--in-sge-assets</code> string File name of SGE assets JSON/YAML in <code>--sge-dir</code> (default: <code>sge_assets.json</code>) <code>--in-fic-params</code> string File name of FICTURE params JSON/YAML in <code>--fic-dir</code> (default: <code>ficture.params.json</code>) <code>--makefn</code> string File name for the generated Makefile (default: <code>run_cartload2.mk</code>) <code>--spatula</code> string Path to the <code>spatula</code> binary (default: <code>spatula</code>) <code>--pmtiles</code> string Path to the <code>pmtiles</code> binary (default: <code>pmtiles</code>) <code>--tippecanoe</code> string Path to the <code>tippecanoe</code> binary (default: <code>tippecanoe</code>) <code>--n-jobs</code> int Number of parallel jobs (default: <code>1</code>) <code>--threads</code> int Number of threads per job (default: <code>4</code>)"},{"location":"vignettes/subregion_tutorials/visiumhd/#upload-to-data-repository","title":"Upload to Data Repository","text":"<p>Choose a data repository to host/share your output</p> <p><code>CartLoader</code> supports two upload options (<code>AWS</code> and <code>Zenodo</code>) for storing PMTiles of SGE and spatial factors in a data repository.</p> <p>Choose the one that best suits your needs.</p>"},{"location":"vignettes/subregion_tutorials/visiumhd/#aws-uploads","title":"AWS Uploads","text":"<p>Upload the generated <code>CartLoader</code> outputs to your designated AWS S3 directory:</p> <pre><code># AWS S3 target location for cartostore\nS3_DIR=/s3/path/to/s3/dir              # Recommend to use DATA_ID as directory name, such as s3://bucket_name/xenium-v1-humanlung-cancer-ffpe\n\ncartloader upload_aws \\\n  --in-dir ./cartload2 \\\n  --s3-dir \"${S3_DIR}\" \\\n  --aws ${aws} \\\n  --n-jobs ${n_jobs}\n</code></pre> Parameter Required Type Description <code>--in-dir</code> required string Path to the input directory containing the <code>CartLoader</code> asset packaging output <code>--s3-dir</code> required string Path to the target S3 directory for uploading <code>--aws</code> string Path to the AWS CLI binary <code>--n-jobs</code> int Number of parallel jobs"},{"location":"vignettes/subregion_tutorials/visiumhd/#zenodo-uploads","title":"Zenodo Uploads","text":"<p>Upload the generated <code>CartLoader</code> outputs to your designated Zenodo deposition or a new deposition.</p> <pre><code>zenodo_token=/path/to/zenodo/token/file    # replace /path/to/zenodo/token/file by path to your zenodo token file\n\ncartloader upload_zenodo \\\n  --in-dir ./cartload2 \\\n  --upload-method catalog \\\n  --zenodo-token $zenodo_token \\\n  --title  \"Your Title\" \\\n  --creators \"Your Name\" \\\n  --description \"This is an example description\"\n</code></pre> Parameter Required Type Description <code>--in-dir</code> required string Path to the input directory containing the <code>CartLoader</code> asset packaging output <code>--upload-method</code> required string Method to determine which files to upload. Options: <code>all</code> to upload all files in <code>--in-dir</code>; <code>catalog</code> to upload files listed in a catalog YAML file; <code>user_list</code> to upload files explicitly listed via <code>--in-list</code> <code>--catalog-yaml</code> string Required if <code>--upload-method catalog</code>. Path to <code>catalog.yaml</code> generated in <code>run_cartload2</code>. If absent, uses the catalog in the input directory specified by <code>--in-dir</code>. <code>--zenodo-token</code> required string Path to your Zenodo access token file <code>--title</code> required string Required when creating a new deposition (i.e., if <code>--zenodo-deposition-id</code> is omitted). Title for the new Zenodo deposition. <code>--creators</code> required list of str List of creators in \"Lastname, Firstname\" format."},{"location":"vignettes/subregion_tutorials/visiumhd/#output-data","title":"Output Data","text":"<ul> <li> <p>     ---</p> </li> </ul> <p>See more details of output at the Reference pages for run_ficture2 and run_cartload2.</p>"},{"location":"vignettes/subregion_tutorials/visiumhd/#viewexplore","title":"View/Explore","text":"<p>The output are available in both CartoScope and Zenodo. </p> <p>Explore in CartoScope</p> <p>Download from Zenodo</p>"},{"location":"vignettes/subregion_tutorials/xenium/","title":"10x Xenium Starter Tutorial","text":""},{"location":"vignettes/subregion_tutorials/xenium/#input-data","title":"Input Data","text":"<p>This tutorial uses SGE data generated with the 10x Genomics Xenium platform, and it has been cropped to a small region of the adult mouse brain for demonstration purposes.</p> <p>File Format</p> <p>The 10x Genomics Xenium platform outputs Spatial Gene Expression (SGE) data in a comma\u2011separated values (CSV) format.</p> <p>CSV File Format</p> <pre><code>\"transcript_id\",\"cell_id\",\"overlaps_nucleus\",\"feature_name\",\"x_location\",\"y_location\",\"z_location\",\"qv\"\n281827164036151,133793,1,\"Sox10\",2350.0232,4153.6846,16.592316,40.0\n281827164036152,133793,1,\"Sox10\",2350.2585,4154.5225,17.237207,10.514394\n281827164036164,151216,0,\"Sox10\",2350.5874,4277.699,14.285685,40.0\n</code></pre> <ul> <li>\"<code>transcript_id</code>\": Unique identifier for each detected transcript molecule.  </li> <li>\"<code>cell_id</code>\": ID of the segmented cell associated with the transcript.</li> <li>\"<code>overlaps_nucleus</code>\": 1 if the transcript overlaps the nucleus mask, 0 otherwise.  </li> <li>\"<code>feature_name</code>\": Feature name corresponding to the transcript (typically a gene).</li> <li>\"<code>x_location</code>\": X coordinate of the transcript.  </li> <li>\"<code>y_location</code>\": Y coordinate of the transcript.  </li> <li>\"<code>z_location</code>\": Z coordinate (depth) of the transcript.  </li> <li>\"<code>qv</code>\": Quality value indicating confidence in transcript detection. </li> </ul> <p>Data Access</p> <p>The example data is hosted on Zenodo.</p> <p>Follow the commands below to download the example data.</p> <pre><code>work_dir=/path/to/work/directory\ncd $work_dir\nwget  https://zenodo.org/records/17953582/files/xenium_starter.raw.tar.gz \ntar --strip-components=1 -zxvf xenium_starter.raw.tar.gz  \n</code></pre>"},{"location":"vignettes/subregion_tutorials/xenium/#set-up-the-environment","title":"Set Up the Environment","text":"<p>Pre-installed tools</p> <p>Please ensure you have installed all required tools (See Installation).</p> <p>Define paths to all required binaries and resources. Optionally, specify a fixed color map for consistent rendering.</p> <pre><code># ====\n# Replace each placeholder with the actual path on your system.  \n# ====\n\nwork_dir=/path/to/work/directory        # path to work directory that contains the downloaded input data\ncd $work_dir\n\n# Define paths to required binaries and resources\nspatula=/path/to/spatula/binary         # path to spatula executable\npunkst=/path/to/punkst/binary           # path to FICTURE2 (punkst) executable\ntippecanoe=/path/to/tippecanoe/binary   # path to tippecanoe executable\npmtiles=/path/to/pmtiles/binary         # path to pmtiles executable\naws=/path/to/aws/cli/binary             # path to AWS CLI binary\n\n# (Optional) Define path to color map. \ncmap=/path/to/color/map                 # Path to fixed color map. `CartLoader` includes one at cartloader/assets/fixed_color_map_256.tsv.\n\n# Number of jobs\nn_jobs=10                               # If not specified, the number of jobs defaults to 1.\n\n# Activate the bioconda environment\nconda activate ENV_NAME                 # replace ENV_NAME with your conda environment name\n</code></pre> <p>Define data ID and analysis parameters:</p> <pre><code># Unique identifier for your dataset\nDATA_ID=\"xenium_hippo\"                  # change this to reflect your dataset name\nPLATFORM=\"10x_xenium\"                   # platform information\nSCALE=1                                 # coordinate to micrometer scaling factor\n\n# LDA parameters\ntrain_width=12                           # define LDA training hexagon width (comma-separated if multiple widths are applied)\nn_factor=6,12                            # define number of factors in LDA training (comma-separated if multiple n-factor are applied)\n</code></pre> <p>How to Define Scaling Factors for Xenium?</p> <p>The Xenium example data currently used here provides SGE in micrometer units. Define scaling factor from coordinate to micrometer as 1.</p>"},{"location":"vignettes/subregion_tutorials/xenium/#sge-format-conversion","title":"SGE Format Conversion","text":"<p>Convert the raw input to the unified SGE format. See more details in its Reference page.</p> <pre><code>cartloader sge_convert \\\n  --makefn sge_convert.mk \\\n  --platform ${PLATFORM} \\\n  --in-csv ./input.tsv.gz \\\n  --units-per-um ${SCALE} \\\n  --out-dir ./sge \\\n  --exclude-feature-regex '^(BLANK|Neg|Intergenic|Deprecated|Unassigned)' \\\n  --sge-visual \\\n  --spatula ${spatula} \\\n  --n-jobs ${n_jobs}\n</code></pre> Parameter Required Type Description <code>--platform</code> required string Platform (options: \"<code>10x_visium_hd</code>\", \"<code>seqscope</code>\", \"<code>10x_xenium</code>\", \"<code>bgi_stereoseq</code>\", \"<code>cosmx_smi</code>\", \"<code>vizgen_merscope</code>\", \"<code>pixel_seq</code>\", \"<code>generic</code>\") <code>--in-csv</code> required string Path to the input TSV/CSV file <code>--units-per-um</code> required float Scale to convert coordinates to microns (default: <code>1.0</code>) <code>--out-dir</code> required string Output directory for the converted SGE files <code>--makefn</code> string File name for the generated Makefile (default: <code>sge_convert.mk</code>) <code>--exclude-feature-regex</code> regex Pattern to exclude control features <code>--sge-visual</code> flag Enable SGE visualization step (generates diagnostic image) (default: <code>FALSE</code>) <code>--spatula</code> string Path to the spatula binary (default: <code>spatula</code>) <code>--n-jobs</code> int Number of parallel jobs for processing (default: <code>1</code>)"},{"location":"vignettes/subregion_tutorials/xenium/#ficture-analysis","title":"<code>FICTURE</code> Analysis","text":"<p>Compute spatial factors using <code>punkst</code> (FICTURE2 mode). See more details on the Reference page.</p> <pre><code>cartloader run_ficture2 \\\n  --makefn run_ficture2.mk \\\n  --main \\\n  --in-transcript ./sge/transcripts.unsorted.tsv.gz \\\n  --in-feature ./sge/feature.clean.tsv.gz \\\n  --in-minmax ./sge/coordinate_minmax.tsv \\\n  --cmap-file ${cmap} \\\n  --exclude-feature-regex '^(mt-.*$|Gm\\d+$)' \\\n  --out-dir ./ficture2 \\\n  --width ${train_width} \\\n  --n-factor ${n_factor} \\\n  --spatula ${spatula} \\\n  --ficture2 ${punkst} \\\n  --n-jobs ${n_jobs} \\\n  --threads ${n_jobs}\n</code></pre> Parameter Required Type Description <code>--main</code> required <sup>1</sup> flag Enable <code>CartLoader</code> to run all five steps <code>--in-transcript</code> required string Path to input transcript-level SGE file <code>--out-dir</code> required string Path to output directory <code>--width</code> required int or comma-separated list LDA training hexagon width(s) <code>--n-factor</code> required int or comma-separated list Number of LDA factors <code>--makefn</code> string File name for the generated Makefile (default: <code>run_ficture2.mk</code> ) <code>--in-feature</code> string Path to input feature file <code>--in-minmax</code> string Path to input coordinate min/max file <code>--cmap-file</code> string Path to color map file <code>--exclude-feature-regex</code> regex Pattern to exclude features <code>--spatula</code> string Path to the <code>spatula</code> binary (default: <code>spatula</code>) <code>--ficture2</code> string Path to the <code>punkst</code> directory (defaults to <code>punkst</code> repository within <code>submodules</code> directory of  <code>CartLoader</code>) <code>--n-jobs</code> int Number of parallel jobs (default: <code>1</code>) <code>--threads</code> int Number of threads per job (default: <code>1</code>) <p><sub><sup>1</sup>: <code>CartLoader</code> requires the user to specify at least one action. Available actions includes: <code>--tile</code> to run tiling step; <code>--segment</code> to run segmentation step; <code>--init-lda</code> to run LDA training step; <code>--decode</code> to run decoding step; <code>--summary</code> to run summarization step; <code>--main</code> to run all above five actions.</sub></p>"},{"location":"vignettes/subregion_tutorials/xenium/#cartloader-asset-packaging","title":"<code>CartLoader</code> Asset Packaging","text":"<p>Generate pmtiles and web-compatible tile directories. See more details in Reference page.</p> <pre><code># Example A: With FICTURE outputs (integrates factors + joins)\ncartloader run_cartload2 \\\n  --makefn run_cartload2.mk \\\n  --fic-dir ./ficture2 \\\n  --out-dir ./cartload2 \\\n  --id ${DATA_ID} \\\n  --spatula ${spatula} \\\n  --pmtiles ${pmtiles} \\\n  --tippecanoe ${tippecanoe} \\\n  --n-jobs ${n_jobs} \\\n  --threads ${n_jobs}\n\n# Example B: SGE-only (package molecules without FICTURE)\ncartloader run_cartload2 \\\n  --makefn run_cartload2.mk \\\n  --sge-dir ./sge_convert \\\n  --out-dir ./cartload2 \\\n  --id ${DATA_ID} \\\n  --spatula ${spatula} \\\n  --pmtiles ${pmtiles} \\\n  --tippecanoe ${tippecanoe} \\\n  --n-jobs ${n_jobs} \\\n  --threads ${n_jobs}\n</code></pre> Parameter Required Type Description <code>--out-dir</code> required string Path to the output directory for PMTiles and web tiles <code>--id</code> required string Dataset ID used for naming outputs and metadata <code>--fic-dir</code> string Path to FICTURE outputs (enables factor layers + molecule\u2013factor joins) <code>--sge-dir</code> string Path to SGE outputs from <code>sge_convert</code> (enables SGE-only packaging) <code>--in-sge-assets</code> string File name of SGE assets JSON/YAML in <code>--sge-dir</code> (default: <code>sge_assets.json</code>) <code>--in-fic-params</code> string File name of FICTURE params JSON/YAML in <code>--fic-dir</code> (default: <code>ficture.params.json</code>) <code>--makefn</code> string File name for the generated Makefile (default: <code>run_cartload2.mk</code>) <code>--spatula</code> string Path to the <code>spatula</code> binary (default: <code>spatula</code>) <code>--pmtiles</code> string Path to the <code>pmtiles</code> binary (default: <code>pmtiles</code>) <code>--tippecanoe</code> string Path to the <code>tippecanoe</code> binary (default: <code>tippecanoe</code>) <code>--n-jobs</code> int Number of parallel jobs (default: <code>1</code>) <code>--threads</code> int Number of threads per job (default: <code>4</code>)"},{"location":"vignettes/subregion_tutorials/xenium/#upload-to-data-repository","title":"Upload to Data Repository","text":"<p>Choose a data repository to host/share your output</p> <p><code>CartLoader</code> supports two upload options (<code>AWS</code> and <code>Zenodo</code>) for storing PMTiles of SGE and spatial factors in a data repository.</p> <p>Choose the one that best suits your needs.</p>"},{"location":"vignettes/subregion_tutorials/xenium/#aws-uploads","title":"AWS Uploads","text":"<p>Upload the generated <code>CartLoader</code> outputs to your designated AWS S3 directory:</p> <pre><code># AWS S3 target location for cartostore\nS3_DIR=/s3/path/to/s3/dir              # Recommend to use DATA_ID as directory name, such as s3://bucket_name/xenium-v1-humanlung-cancer-ffpe\n\ncartloader upload_aws \\\n  --in-dir ./cartload2 \\\n  --s3-dir \"${S3_DIR}\" \\\n  --aws ${aws} \\\n  --n-jobs ${n_jobs}\n</code></pre> Parameter Required Type Description <code>--in-dir</code> required string Path to the input directory containing the <code>CartLoader</code> asset packaging output <code>--s3-dir</code> required string Path to the target S3 directory for uploading <code>--aws</code> string Path to the AWS CLI binary <code>--n-jobs</code> int Number of parallel jobs"},{"location":"vignettes/subregion_tutorials/xenium/#zenodo-uploads","title":"Zenodo Uploads","text":"<p>Upload the generated <code>CartLoader</code> outputs to your designated Zenodo deposition or a new deposition.</p> <pre><code>zenodo_token=/path/to/zenodo/token/file    # replace /path/to/zenodo/token/file by path to your zenodo token file\n\ncartloader upload_zenodo \\\n  --in-dir ./cartload2 \\\n  --upload-method catalog \\\n  --zenodo-token $zenodo_token \\\n  --title  \"Your Title\" \\\n  --creators \"Your Name\" \\\n  --description \"This is an example description\"\n</code></pre> Parameter Required Type Description <code>--in-dir</code> required string Path to the input directory containing the <code>CartLoader</code> asset packaging output <code>--upload-method</code> required string Method to determine which files to upload. Options: <code>all</code> to upload all files in <code>--in-dir</code>; <code>catalog</code> to upload files listed in a catalog YAML file; <code>user_list</code> to upload files explicitly listed via <code>--in-list</code> <code>--catalog-yaml</code> string Required if <code>--upload-method catalog</code>. Path to <code>catalog.yaml</code> generated in <code>run_cartload2</code>. If absent, uses the catalog in the input directory specified by <code>--in-dir</code>. <code>--zenodo-token</code> required string Path to your Zenodo access token file <code>--title</code> required string Required when creating a new deposition (i.e., if <code>--zenodo-deposition-id</code> is omitted). Title for the new Zenodo deposition. <code>--creators</code> required list of str List of creators in \"Lastname, Firstname\" format."},{"location":"vignettes/subregion_tutorials/xenium/#output-data","title":"Output Data","text":"<ul> <li> <p>     ---</p> </li> </ul> <p>See more details of output at the Reference pages for run_ficture2 and run_cartload2.</p>"},{"location":"vignettes/subregion_tutorials/xenium/#viewexplore","title":"View/Explore","text":"<p>The output are available in both CartoScope and Zenodo. </p> <p>Explore in CartoScope</p> <p>Download from Zenodo</p>"}]}