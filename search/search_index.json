{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"A scalable, harmonized, and cloud-friendly ecosystem for spatial transcriptomics data","text":""},{"location":"#overview","title":"Overview","text":"<p>Spatial transcriptomics (ST) technologies have revolutionized our ability to map molecular features with remarkable resolution\u2014down to cellular and subcellular levels.</p> <p>While the rapid development of sequencing-based platforms (e.g., Seq-Scope, Stereo-seq, Pixel-seq, 10x Visium HD) and imaging-based platforms (e.g., 10x Xenium, Vizgen MERSCOPE, CosMx SMI) has led to an explosion in the production of ST datasets across diverse tissues and species, this platform diversity has also introduced heterogeneous data formats and metadata schemas, which further obstruct efforts toward standardized data ingestion, cross-platform format conversion, and reproducible analytical workflows.</p> <p>To address this challenge, we introduce a scalable, harmonized, and cloud-friendly ecosystem for spatial transcriptomics data across platforms, composed of two components:</p> <ul> <li>cartloader \u2013 a harmonized, scalable pipeline for high-resolution spatial omics data processing and analysis with retaining the original resolution.</li> <li>cartostore \u2013 an open-access, cloud-hosted repository for dataset sharing and visualization.</li> </ul> <p>Together, this system should provide a unified solution for working with raw pixel-level spatial omics data\u2014without sacrificing resolution or reproducibility.</p>"},{"location":"#cartloader-a-scalable-spatial-transcriptomics-pipeline","title":"Cartloader: A Scalable Spatial Transcriptomics Pipeline","text":"<p>This document introduces <code>cartloader</code>, which is the core engine of our ecosystem. It provides a modular, reproducible tool to harmonize, integrate, analyze, and visualize raw high-resolution ST data across platforms. Usage examples are provided in the Get Started. Detailed descriptions of its workflow, inputs, outputs, and parameters are provided in the Reference Pages.</p> <p>Key Features</p> <ul> <li>Cross-Platform Format Conversion: Converts raw spatial gene expression (SGE) data from diverse ST platforms into a unified format, enabling consistent downstream processing.</li> <li>Spatial Factor Inference: Applies FICTURE to infer spatial factors directly from pixel-level data, capturing biological patterns without requiring cell segmentation.</li> <li>Multi-Modal Alignment: Aligns and overlays histology images to SGE data so all layers (histology, SGE, and histological images) share a common coordinate system for pixel-accurate comparisons.</li> <li>Cloud-Friendly Outputs: Produces compact, geospatially-indexed data formats suitable for web visualization and cloud storage.</li> <li>Batch Integration and Sample Stitching: Supports joint analysis and SGE stitching across samples or platforms to reveal shared or differential features across tissues.</li> <li>Modular and Reproducible Workflow: Orchestrates all steps through a Makefile-based system to ensure scalability, transparency, and reproducibility.</li> </ul>"},{"location":"#cartostore-cloud-access-and-visualization","title":"Cartostore: Cloud Access and Visualization","text":"<p>As a natural companion to <code>cartloader</code>, cartostore hosts the output of processed datasets for public access and exploration. Designed for scalability and interoperability, cartostore uses spatially indexed formats like PMTiles to support interactive visualization and seamless integration.</p> <p>Explore the Cartostore documentation to learn more about dataset access and how to contribute.</p>"},{"location":"#citations","title":"Citations:","text":"<ul> <li>FICTURE: doi.org/10.1038/s41592-024-02415-2</li> </ul>"},{"location":"installation/","title":"Installation Guide","text":"<p>This is an instruction to set up the required environment, install necessary dependencies, and install <code>cartloader</code>.</p>"},{"location":"installation/#1-dependencies","title":"1. Dependencies","text":"<p>To ensure full functionality of <code>cartloader</code>, the following dependencies must be installed:</p>"},{"location":"installation/#11-system-dependencies","title":"1.1 System Dependencies","text":"<p>Ensure the following command-line tools are available on your system:  </p> <ul> <li><code>gzip</code> </li> <li><code>sort</code> </li> <li><code>bgzip</code> </li> <li><code>tabix</code> </li> </ul>"},{"location":"installation/#12-external-tools-utilities","title":"1.2 External Tools &amp; Utilities","text":"<p>The following external tools and utilities are required for handling spatial data and file processing. Some of these are included as submodules within the repository.</p> <p>Python &amp; Related Packages:</p> <ul> <li><code>python</code> (<code>cartloader</code> has been tested with v3.10 and v3.13.1)</li> <li><code>parquet-tools</code></li> </ul> <p>External Tools (Included in submodules)</p> <ul> <li><code>punkst</code> (the latest and more efficient implementation of FICTURE)</li> <li><code>spatula</code></li> <li><code>tippecanoe</code></li> <li><code>magick</code></li> <li><code>go-pmtiles</code></li> </ul> <p>Geospatial Data Handling:</p> <ul> <li><code>gdal</code></li> </ul> <p>Cloud &amp; CLI Tools:</p> <ul> <li><code>aws-cli</code></li> </ul>"},{"location":"installation/#2-setting-up-the-environment-using-conda","title":"2. Setting Up the Environment using <code>conda</code>","text":"<p>We recommended to use <code>conda</code> to manage dependencies efficiently and avoid conflicts.</p>"},{"location":"installation/#21-installing-conda","title":"2.1 Installing <code>conda</code>","text":"<p>If <code>conda</code> is not installed, download and install Miniconda or Anaconda.</p> <p>Here is an example to install <code>Miniconda3</code> on Linux.</p> <pre><code>env_dir=/path/to/your/directory/hosting/tools/      ## replace `/path/to/your/directory/hosting/tools/` by the path to your tool directory\ncd $env_dir\n\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\nbash Miniconda3-latest-Linux-x86_64.sh\n</code></pre>"},{"location":"installation/#22-creating-an-environment","title":"2.2 Creating an Environment","text":"<p>Create a dedicated Conda environment for <code>cartloader</code>:</p> <pre><code>conda_env=cartenv               # replace cartenv with the name of your conda environment\npython_version=3.13.1           # replace 3.13.1 with the version you prefer\n\nconda create -n cartenv python=$python_version\nconda activate cartenv\n</code></pre>"},{"location":"installation/#23-installing-dependencies","title":"2.3 Installing Dependencies","text":"<p>Once inside the environment, install the required dependencies:</p> <pre><code>conda install -c conda-forge gdal aws-cli imagemagick parquet-tools\n</code></pre>"},{"location":"installation/#3-installing-cartloader","title":"3. Installing <code>cartloader</code>","text":"<p>Clone the repository and install it:</p> <pre><code>cd $env_dir\ngit clone git@github.com:seqscope/cartloader.git\ncd cartloader\n\npip install -e ./\n\n# Install its requirements:\npip install -r ./requirements.txt\n</code></pre>"},{"location":"installation/#4-installing-submodules","title":"4. Installing Submodules","text":"<pre><code>cd $env_dir/cartloader\ngit submodule update --init --recursive\n</code></pre>"},{"location":"installation/#41-installing-spatula","title":"4.1 Installing <code>spatula</code>","text":"<p>Install <code>spatula</code> with its dependencies from the submodules directory:</p> <pre><code>cd ${env_dir}/cartloader/submodules/spatula\n\ncd submodules\nbash -x build.sh\ncd ..\n\n## build spatula\nmkdir build\ncd build\ncmake ..\nmake\n</code></pre>"},{"location":"installation/#42-installing-punkst","title":"4.2 Installing <code>punkst</code>","text":"<p>Install <code>punkst</code> toolkit to use <code>FICTURE</code> (Si et al., Nature Methods 2024).</p> <p>Please following the <code>punkst</code> installation guide to install <code>punkst</code></p> What is <code>FICTURE</code> and <code>punkst</code> <p><code>FICTURE</code> is a segmentation-free method that infers latent spatial factors\u2014coherent spatial patterns of gene activity\u2014that correspond to underlying transcriptional programs or tissue structures. These factors can then be projected back to the pixel level. Although <code>FICTURE</code> is built on a Latent Dirichlet Allocation (LDA) framework by default, it is also compatible with clustering outputs from external tools like <code>Seurat</code> for pixel-level projection.</p> <p>The <code>punkst</code> toolkit is a streamlined implementation of the <code>FICTURE</code>, designed for improved computational efficiency and scalability while producing results equivalent to the original <code>FICTURE</code>.</p>"},{"location":"installation/#43-installing-tippecanoe","title":"4.3 Installing <code>tippecanoe</code>","text":"<pre><code>cd ${env_dir}/cartloader/submodules/tippecanoe\nmake -j\n\n## Choose one of the following methods to install tippecanoe:\n# (1) System-wide installation (requires root access):\nmake install\n\n# (2) Local installation (no root access): specify a custom PREFIX\nmake install PREFIX=${env_dir}/cartloader/submodules/tippecanoe/  # Replace with your desired installation path\n</code></pre>"},{"location":"installation/#44-installing-go-pmtiles","title":"4.4 Installing <code>go-pmtiles</code>","text":"<p>An easy way to install <code>go-pmtiles</code> is to download a release from the official website and decompress it. This will return a <code>pmtiles</code> bin file ready for use.</p> <p>Here is an example of its installation:</p> <pre><code>cd ${env_dir}\nwget https://github.com/protomaps/go-pmtiles/releases/download/v1.28.0/go-pmtiles_1.28.0_Linux_x86_64.tar.gz ./\ntar zxvf ./go-pmtiles_1.28.0_Linux_x86_64.tar.gz\n</code></pre>"},{"location":"installation/#45-installing-imagemagick","title":"4.5 Installing ImageMagick","text":"<p>If you have already installed ImageMagick when setting conda environment, skip this step.</p> <pre><code>cd ${env_dir}/cartloader/submodules/ImageMagick\n./configure     # Alternatively, run `./configure --prefix=${env_dir}/cartloader/submodules/ImageMagick`.\nmake \nmake install \n</code></pre>"},{"location":"installation/#5-verifying-the-installation","title":"5. Verifying the Installation","text":"<p>To confirm the package is installed correctly, run:</p> <pre><code>python -c \"import cartloader; print('cartloader installed successfully!')\"\n</code></pre>"},{"location":"reference/run_cartload2/","title":"Spatial Asset Packaging","text":""},{"location":"reference/run_cartload2/#overview","title":"Overview","text":"<p>Following spatial factor inference via FICTURE analysis, <code>cartloader</code> offers the <code>run_cartload2</code> module package SGE data and spatial factor output from FICTURE analysis into standardized, spatially indexed, and storage-efficient PMTiles, a web-native tiling format. These PMTiles outputs are optimized for downstream analysis, interactive web visualization (e.g., in CartoScope), and data sharing across platforms.</p>"},{"location":"reference/run_cartload2/#requirements","title":"Requirements","text":"<ul> <li>A completed FICTURE run (pixel-level decoding outputs) (from <code>run_ficture2</code>)</li> <li>A metadata file describing the input-output structure (<code>ficture.params.json</code>)</li> <li>Pre-installed CLI tools: <code>tippecanoe</code>, <code>gdal_translate</code>, <code>gdaladdo</code>, <code>pmtiles</code>, <code>spatula</code>, <code>gzip</code></li> </ul>"},{"location":"reference/run_cartload2/#example-usage","title":"Example Usage","text":"<pre><code>cartloader run_cartload2 \\\n    --makefn run_cartload2.mk \\\n    --fic-dir /path/to/run_ficture2/results \\\n    --out-dir /path/to/output/directory \\\n    --id dataset_id \\                            ## replace dataset_id with the id for this dataset\n    --colname-count count \\\n    --n-jobs 20  \\\n    --threads 20 \\\n    --spatula /path/to/spatula/binary \\\n    --pmtiles /path/to/pmtiles/binary \\\n    --tippecanoe /path/to/tippecanoe/binary\n</code></pre>"},{"location":"reference/run_cartload2/#actions","title":"Actions","text":"<p>Specifically, it will perform all the following steps:</p> <ul> <li>Converts transcript-level SGE to raster-format PMTiles.</li> <li>Converts topic proportions (.results.tsv.gz) into vector PMTiles for spatial factors.</li> <li>Processes each decoded pixel-level output to generate raster PMTiles for visual overlays.</li> <li>Create a joined molecule-feature matrix by joining decoded pixel-level spatial factors from FICTURE with transcript-level molecules from the original SGE based on spatial proximity.</li> <li>Converts the joined molecule-feature matrix into storage-efficient, multi-feature PMTiles.</li> <li>Generates a JSON file listing all FICTURE assets and a YAML catalog describing the final visualization layers.</li> </ul>"},{"location":"reference/run_cartload2/#parameters","title":"Parameters","text":"<p>The following outlines the minimum required parameters for running spatial asset packaging. </p> <p>For auxiliary parameters, we recommend using the default values unless you possess a thorough understanding of <code>run_cartload2</code>. For further details, refer to the collapsible sections below or run:</p> <pre><code>cartloader run_cartload2 --help\n</code></pre>"},{"location":"reference/run_cartload2/#inputoutput-parameters","title":"Input/Output Parameters","text":"<ul> <li><code>--fic-dir</code> (str): Path to the input directory containing FICTURE output.</li> <li><code>--out-dir</code> (str): Path to the output directory for storing generated assets.</li> </ul>"},{"location":"reference/run_cartload2/#dataset-id-and-descriptions","title":"Dataset ID and Descriptions","text":"<ul> <li><code>--id</code> (str): Unique identifier for the output asset set.</li> <li><code>--title</code> (str): Optional title for the output assets.</li> <li><code>--desc</code> (str): Optional description for the output assets.</li> </ul> Auxiliary <code>run_cartload2</code> Paramaters <p>Auxiliary Conversion Parameters:</p> <ul> <li><code>--in-fic-params</code> (str): Path to input JSON file with SGE files and FICTURE parameters (Default: <code>ficture.params.json</code>).</li> <li><code>--out-fic-assets</code> (str): Path to output JSON file to write FICTURE assets (Default: <code>ficture_assets.json</code>).</li> <li><code>--out-catalog</code> (str): Path to output YAML file for assets (Default: catalog.yaml).</li> <li><code>--background-assets</code> (str list): List of background asset descriptors in <code>[id:file]</code> or <code>[id1:id2:file]</code> format.</li> <li><code>--rename-x</code> (str): Column renaming rule for X axis in <code>tippecanoe</code> (Default: x:lon).</li> <li><code>--rename-y</code> (str): Column renaming rule for Y axis in <code>tippecanoe</code> (Default: y:lat).</li> <li><code>--colname-feature</code> (str): Column name for gene/feature name (Default: gene).</li> <li><code>--colname-count</code> (str): Column name for feature count (Default: count).</li> <li><code>--out-molecules-id</code> (str): Prefix for output molecule PMTiles files (Default: genes).</li> <li><code>--max-join-dist-um</code> (float): Maximum join distance (\u00b5m) between molecules and pixels (Default: 0.1).</li> <li><code>--join-tile-size</code> (float): Tile size (\u00b5m) for molecule\u2013pixel joining. (Default: 500).</li> <li><code>--max-tile-bytes</code> (int): Maximum allowed tile size in bytes for PMTiles (Default: 5e6).</li> <li><code>--max-feature-counts</code> (int): Maximum number of features per tile (Default: 5e5).</li> <li><code>--preserve-point-density-thres</code> (int): Threshold to preserve point density in PMTiles (Default: 1024).</li> <li><code>--keep-intermediate-files</code> (flag): If set, retain intermediate files generated.</li> <li><code>--skip-raster</code> (flag): If set, skip raster tile generation and related dependencies.</li> <li><code>--tmp-dir</code> (str): Path to a temporary directory (Default: <code>&lt;out-dir&gt;/tmp</code>).</li> </ul> <p>Auxiliary Environment Parameters:</p> <ul> <li><code>--gzip</code> (str): Path to the <code>gzip</code> binary. For faster compression, use <code>\"pigz -p4\"</code> (Default: gzip).</li> <li><code>--pmtiles</code> (str): Path to the <code>pmtiles</code> binary from go-pmtiles (Default: pmtiles).</li> <li><code>--gdal_translate</code> (str): Path to the <code>gdal_translate</code> binary (Default: gdal_translate).</li> <li><code>--gdaladdo</code> (str): Path to the <code>gdaladdo</code> binary (Default: gdaladdo).</li> <li><code>--tippecanoe</code> (str): Path to the <code>tippecanoe</code> binary (Default: tippecanoe).</li> <li><code>--spatula</code> (str): Path to the <code>spatula</code> binary (Default: spatula).</li> </ul>"},{"location":"reference/run_cartload2/#output","title":"Output","text":""},{"location":"reference/run_cartload2/#copied-ficture-output","title":"Copied FICTURE Output","text":"<p>Copied FICTURE output from <code>&lt;fic_dir&gt;</code>. See formats in FICTURE analysis.</p>"},{"location":"reference/run_cartload2/#rasterized-transcript-level-sge","title":"Rasterized transcript-level SGE","text":"<ul> <li>SGE mono PMTiles (<code>sge-mono-dark.pmtiles</code> and <code>sge-mono-light.pmtiles</code>): Rasterized gene expression tiles created from raw SGE for web visualization.</li> </ul>"},{"location":"reference/run_cartload2/#rasterized-spatial-factor-maps","title":"Rasterized Spatial Factor Maps","text":"<ul> <li>Factor probability PMTiles (<code>*-results.pmtiles</code>): Vector tiles encoding posterior topic probabilities per spatial location.</li> <li>Decoded factor PMTiles (<code>*-pixel-raster.pmtiles</code>): Rasterized spatial factor maps derived from pixel-level decoding results.</li> </ul>"},{"location":"reference/run_cartload2/#joined-molecule-factor-pmtiles","title":"Joined molecule-factor PMTiles","text":"<ul> <li>Joined molecule-factor TSV (<code>transcripts_pixel_joined.tsv.gz</code>): Merged file linking transcript-level SGE with decoded pixel factors.</li> <li>Final molecule PMTiles (*_pmtiles_index.tsv, <code>*_bin_counts.json</code>): Indexed, multi-feature PMTiles built from joined pixel-factor data for CartoScope.</li> </ul>"},{"location":"reference/run_cartload2/#summary-files","title":"Summary Files","text":"<ul> <li>FICTURE assets file (ficture_assets.json): JSON catalog listing all output files and their roles for each trained model.</li> <li>Catalog file (catalog.yaml): Final YAML file summarizing all visual assets and layers for further deployment and visualization.</li> </ul>"},{"location":"reference/run_ficture2/","title":"Spatial Factor Inference Analysis using FICTURE","text":""},{"location":"reference/run_ficture2/#overview","title":"Overview","text":"<p>Following format conversion, cartloader provides <code>run_ficture2</code> module to run spatial factor inference using <code>FICTURE</code> (Si et al., Nature Methods, 2024). This method infers spatial factors directly at the pixel level with submicron resolution, eliminating the need for segmentation.</p> <p>What is <code>FICTURE</code>?</p> <p><code>FICTURE</code> reconstructs the fine-scale tissue structure by first decomposing gene expression patterns across the tissue section into spatial factors and then assigns each pixel to these factors using local context. Biologically, these inferred factors may correspond to specific cell types, functional or physiological states, subcellular domains, or extracellular transcriptomic signatures.</p> <p>By default, <code>FICTURE</code> learns the spatial factors by implementing a standard latent Dirichlet allocation (LDA) model on a hexagonal grid overlay of the spatial coordinates. Optionally, spatial factors can also be derived from external sources, such as single-cell or single-nucleus RNA-seq reference datasets, or from spatially agnostic factor learning methods (e.g., Seurat, Scanpy).</p> <p>The <code>punkst</code> version of <code>FICTURE</code></p> <p>To efficiently run FICTURE-based inference, cartloader integrates <code>punkst</code>, an optimized implementation of FICTURE that maintains output equivalence while enhancing computational scalability and performance. </p> <p>Currently, <code>run_ficture2</code> is using <code>punkst</code> version of <code>FICTURE</code>.</p>"},{"location":"reference/run_ficture2/#requirements","title":"Requirements","text":"<ul> <li>An SGE in the unified format (from SGE format conversion) </li> <li>Pre-installed tools: <code>spatula</code>, <code>punkst</code>, <code>gzip</code>, <code>sort</code>, <code>python</code></li> </ul>"},{"location":"reference/run_ficture2/#example-usage","title":"Example Usage","text":"<pre><code>cartloader run_ficture2 \\\n    --main \\\n    --in-transcript /path/to/input/harmonized/transcripts/tsv/file \\\n    --in-feature /path/to/input/harmonized/feature/tsv/file \\               # optional\n    --in-minmax /path/to/input/harmonized/coordinates/minmax/tsv/file \\     # optional\n    --cmap-file /path/to/cartloader/assets/fixed_color_map_256.tsv \\        # optional\n    --colname-count count \\\n    --out-dir /path/to/output/directory \\\n    --width 18 \\\n    --n-factor 24 \\\n    --spatula /path/to/spatula/binary \\\n    --ficture2 /path/to/punkst/directory \\  \n    --exclude-feature-regex '^(mt-|Gm\\d+$)' \\                               # optional\n    --n-jobs 20  \\\n    --threads 20 \n</code></pre>"},{"location":"reference/run_ficture2/#actions","title":"Actions","text":""},{"location":"reference/run_ficture2/#tiling-step","title":"Tiling step","text":"<p>The tiling step takes the standarized SGE (from SGE format conversion step) as input. It aims to reorganizes input coordinate data into non-overlapping square tiles in a plain TSV format and generates an index file with tile offsets to enable efficient random access.</p>"},{"location":"reference/run_ficture2/#segmentation-step","title":"Segmentation Step","text":"<p>The segmentation step starts from the tiled SGE, using the plain TSV file from tiling step as input. It aggregates tiled pixel data into non-overlapping hexagons in a TSV file for spot-level analysis, outputting a tab-delimited file of hexagon records and associated metadata in JSON format.</p>"},{"location":"reference/run_ficture2/#lda-training-step","title":"LDA Training Step","text":"<p>The LDA training step uses the hexagon TSV and JSON file from segmentation step as input, trains a Latent Dirichlet Allocation (LDA) model on sparse gene count data from hexagon units, using metadata to interpret input structure and optionally filter or weight features, producing a factorized topic model in TSV.</p>"},{"location":"reference/run_ficture2/#decoding-step","title":"Decoding Step","text":"<p>The decoding step applies a trained LDA model from LDA training step to tiled pixel-level transcript data from tiling step to infer the top spatial factors and their posterior probabilities for each pixel, enabling fine-grained spatial mapping of gene expression. It outputs a pixel-level annotation file in TSV format with coordinates and factor assignments, along with a pseudobulk gene-by-factor matrix in TSV format.</p>"},{"location":"reference/run_ficture2/#summarization-step","title":"Summarization Step","text":"<p>The summarization step generate a JSON file to include all details of the FICTURE analysis, including the input files, output files, and parameters.</p>"},{"location":"reference/run_ficture2/#parameters","title":"Parameters","text":"<p>The following outlines the minimum required parameters for running FICTURE2. </p> <p>For auxiliary parameters, we recommend using the default values unless you possess a thorough understanding of FICTURE. For further details, refer to the collapsible sections below or run:</p> <pre><code>cartloader run_ficture2 --help\n</code></pre>"},{"location":"reference/run_ficture2/#action-parameters","title":"Action Parameters","text":"<p>Action Specifications</p> <p>At least one of the actions (<code>--main</code>, <code>--tile</code>, <code>--segment</code>, <code>--init-lda</code>, <code>--decode</code>, <code>--summary</code>) should be enabled.</p> <ul> <li><code>--main</code>: Run all of the following five actions.</li> <li><code>--tile</code>: Run tiling step.</li> <li><code>--segment</code>: Run segmentation step.</li> <li><code>--init-lda</code>: Run LDA training step.</li> <li><code>--decode</code>: Run decoding step.</li> <li><code>--summary</code>: Run summarization step.</li> </ul>"},{"location":"reference/run_ficture2/#inputoutput-parameters","title":"Input/Output Parameters","text":"<ul> <li><code>--out-dir</code> (str): Output directory to store all result files.</li> <li><code>--out-json</code> (str): Output JSON file summarizing FICTURE parameters (Default: <code>&lt;out-dir&gt;/ficture.params.json</code>).</li> <li><code>--in-transcript</code> (str): Input transcript-indexed SGE file in TSV format.</li> <li><code>--in-minmax</code> (str): Optional input coordinate min-max file.</li> <li><code>--in-feature</code> (str): Optional input UMI count per gene TSV file.</li> </ul>"},{"location":"reference/run_ficture2/#key-parameters","title":"Key Parameters","text":"<ul> <li><code>--width</code> (str): Comma-separated hexagon flat-to-flat widths (in \u00b5m) for LDA training.</li> <li><code>--n-factor</code> (str): Comma-separated list of factor counts for LDA training.</li> <li><code>--include-feature-regex</code> (str): Regex pattern for including features/genes.</li> <li><code>--exclude-feature-regex</code> (str): Regex pattern for excluding features/genes.</li> <li><code>--cmap-file</code> (str): Optional path to fixed color map TSV file. If not provided, FICTURE will generate a color map.</li> </ul> Auxiliary <code>run_ficture2</code> Paramaters <p>Auxiliary Input Parameters</p> <ul> <li><code>--in-feature-ficture</code> (str): (Optional) A separate feature file applied to FICTURE analysis. Alternative to customizing via auxiliary parameters.</li> <li><code>--colidx-x</code> (int): Column index of X in the transcript file (Default: 1).</li> <li><code>--colidx-y</code> (int): Column index of Y in the transcript file (Default: 2).</li> <li><code>--colname-count</code> (str): Column name to use as count value (Default: count).</li> <li><code>--colname-feature</code> (str): Column name for gene/feature name (Default: gene).</li> </ul> <p>Auxiliary FICTURE Parameters:</p> <ul> <li>Tiling-specific parameters:<ul> <li><code>--tile-size</code> (int): Size of tiles for processing (Default: 500).</li> <li><code>--tile-buffer</code> (int): Buffer zone around each tile (Default: 1000).</li> </ul> </li> <li>Segmentation-specific parameters:<ul> <li><code>--min-ct-per-unit-hexagon</code> (int): Minimum count per hexagon (Default: 50).</li> <li><code>--minibatch-size</code> (int): Minibatch size for preprocessing (Default: 500).</li> </ul> </li> <li>LDA training-specific parameters:<ul> <li><code>--min-ct-per-unit-train</code> (int): Minimum count for training (Default: 50).</li> <li><code>--train-epoch</code> (int): Number of epochs to train LDA model (Default: 2).</li> </ul> </li> <li>Decoding-specific paramaters:<ul> <li><code>--fit-width</code> (int): Hexagon width (in \u00b5m) for model fitting (Default: same as train width).</li> <li><code>--min-ct-per-unit-fit</code> (int): Minimum count per unit during model fitting (Default: 50).</li> <li><code>--anchor-res</code> (int): Anchor resolution used in decoding (Default: 6).</li> <li><code>--radius-buffer</code> (int): Buffer added to anchor resolution for decoding (Default: 1).</li> <li><code>--fit-plot-um-per-pixel</code> (int): Image resolution for fit coarse plots (Default: 1).</li> </ul> </li> <li>Shared paramaters across steps:<ul> <li><code>--seed</code> (int): Random seed for reproducibility (Default: 1).</li> <li><code>--min-ct-per-feature</code> (int): Minimum count per feature for LDA and decoding (Default: 20).</li> <li><code>--de-max-pval</code> (float): p-value cutoff for differential expression (Default: 1e-3).</li> <li><code>--de-min-fold</code> (float): Fold-change threshold for differential expression (Default: 1.5).</li> </ul> </li> </ul> <p>Auxiliary Environment Parameters: For tools that require specifying the path to their executable binaries, you may omit the path if the binary is already included in your system's <code>PATH</code>.</p> <ul> <li><code>--gzip</code> (str): Path to <code>gzip</code> binary; consider <code>pigz -p 4</code> for speed (Default: <code>gzip</code>).</li> <li><code>--sort</code> (str): Path to <code>sort</code> binary (Default: <code>sort</code>).</li> <li><code>--sort-mem</code> (str): Memory allocated per <code>sort</code> process (Default: 1G).</li> <li><code>--spatula</code> (str): Path to <code>spatula</code> binary (Default: <code>spatula</code>).</li> <li><code>--ficture2</code> (str): Path to the <code>punkst</code> repository (Default to <code>punkst</code> directory in <code>submodules</code>)</li> <li><code>--python</code> (str): Path to Python 3 binary (Default: <code>python3</code>).</li> </ul>"},{"location":"reference/run_ficture2/#output","title":"Output","text":""},{"location":"reference/run_ficture2/#tiling-output","title":"Tiling Output","text":"<ul> <li><code>transcripts.tiled.tsv</code>: A tab-delimited TSV file where each line records a tile with X and Y coordinates, a feature name (e.g., gene), and its associated count.     <pre><code>3815.69 491.9   Arfgef1 1\n</code></pre></li> <li><code>transcripts.tiled.index</code>: An index file that records the byte offsets of each tile in the tiled TSV file, enabling fast random access to tile-specific data. It includes comment lines with metadata (tile size, pixel count, min/max X and Y coordinates) and data lines listing the offset positions for each tile.     <pre><code># tilesize  500\n# npixels   333021294\n# xmin  0.28\n# xmax  19851.1\n# ymin  0.5\n# ymax  13476.4\n0   7   0           13103550    569474\n0   8   13103550    40259340    1180529\n</code></pre></li> <li><code>transcripts.tiled.coord_range.tsv</code>: A tab-delimited TSV file provides xmin, xmax, ymin, and ymax as key\u2013value pairs.     <pre><code>xmin    0.28\nxmax    19851.1\nymin    0.5\nymax    13476.4\n</code></pre></li> <li><code>transcripts.tiled.features.tsv</code>: A tab-delimited TSV file listing each feature name and its expression count per line.     <pre><code>1810009J06Rik   1\nGm48545         1\n</code></pre></li> </ul>"},{"location":"reference/run_ficture2/#segmentation-output","title":"Segmentation Output","text":"<ul> <li> <p><code>hexagon_d_{width}.randomized.tsv</code>: A plain-text TSV file that stores sparse feature representations for hexagon units, with each line corresponding to one hexagon.</p> <p>File Format</p> <p>This is not a regular table\u2014the number of columns varies across lines depending on the number of features present in each hexagon.</p> <pre><code>00001c64  18999.0000  9773.9627  227  244   2417 1  10469 2  2448 1  543 1   10935 1  6460 1  1797 1  6517 1  1094 1  9872 1  8587 1  7137 1  8786 1  10564 1  2127 1  439 1   1529 1  8432 1   1304 1  1739 1   3012 1  6434 1  5297 1  10017 1  2567 1  4771 1  5644 1  6415 1  5258 1   258 1   2314 1  6378 1  8843 1  7386 1  3322 1  2041 1  4735 1  9755 1  8614 1   4665 1  5693 1  2194 1  1680 1  10406 1  2696 1  7250 1  2367 1  7189 1  1616 1  10721 1  441 1   9981 1   8696 1  1012 1  8545 1  835 1   6550 1  4409 1  1860 1  575 1   139 1   5473 1  10172 1  7316 1  5260 1  180 1   2068 1  10806 1  8817 1  1621 1  4542 1  6193 1  440 1   6608 1  6989 1  4782 1  3258 1  5205 1  1093 1  9060 1  1921 1  6333 1   846 1   10575 1  2608 1  10186 1  932 1   2217 1  5392 1  2275 1  4845 1   8401 1  341 1   2810 1   754 1   4501 1  1160 1  5354 1  5097 1  3713 1  1619 1  9843 1  2749 1  1207 1  7384 1  2758 1  445 1   9040 1  45 1    2517 1   11255 1  8161 1  393 1   2963 1  3457 1  4481 1  10649 1  6954 2  2842 1  7982 1  2034 1  2849 2  5393 1  5257 1  773 1   1030 1  5455 1  2380 1  7079 1  1491 1  353 1    5343 1  1231 1  178 1   8659 1  10994 1  6168 1  267 1    6770 1   9083 1   2691 1  2423 2  3058 3  6921 1  1778 1  236 1   7175 1  7683 1   47 1    9094 2  1898 1  6524 1  5640 1  6668 1   6411 1  3536 1  10475 2  6538 1  1443 1  2728 1  7717 1  4633 1  6634 1   5349 1  11215 2  9159 1  2129 1  5984 1  8584 2  7042 1  3819 2  7931 1  2343 1  1182 2  2724 1  1871 1  716 1   1744 1  263 1   7459 1  6737 1  4654 1   9023 1  775 2    1546 1  1512 1  6395 1  5624 1  1560 2  8919 2  4689 1  2403 1  4163 1  5705 1  1260 1  8068 1  1900 1  1701 1  1187 1  8172 1  5955 1  494 1   428 1   6082 1  479 1   5362 1   11273 1  1764 1   9546 1  8261 1  11088 1  6262 1  2154 1  612 1   6777 2  866 1    10850 1  4168 1  9334 1  9077 2   3818 1  732 1   6386 1  989 1   1277 1  319 1   6230 1\n</code></pre> <ul> <li>1st column (str): Random identifier for the hexagon</li> <li>2nd and 3rd columns (float): Axial coordinates in the hexagonal coordinate system</li> <li>4th and 5th columns (int): Number of unique features and total counts, repeated per modality (for K modalities)</li> <li>6th column onward (integer integer): Index\u2013count pairs for non-zero features, using 0-based indices from --feature-dict or as provided in the input file</li> </ul> </li> <li> <p><code>hexagon_d_{width}.json</code>: The meta data for the hexagons. such as, , hexagon size, x and y column indices (), number of features, number of modalities, and number of hexagons (<code>n_units</code>),     <pre><code>{\n\"dictionary\": {\n    \"A2m\": 9636,\n    \"AA986860\": 6486,\n    ...\n    },\n    \"header_info\": [\n        \"random_key\",\n        \"x\",\n        \"y\"\n    ],\n    \"hex_size\": 10.392304845413264,\n    \"icol_x\": 1,\n    \"icol_y\": 2,\n    \"n_features\": 11319,\n    \"n_modalities\": 1,\n    \"n_units\": 498019,\n    \"offset_data\": 3,\n    \"random_key\": 0\n}\n</code></pre></p> <ul> <li><code>dictionary</code>: The feature name-idex pairs</li> <li><code>header_info</code>: Header information</li> <li><code>hex_size</code>: Size of hexagons</li> <li><code>icol_x</code> and <code>icol_y</code>: Indices of X and Y coordinates</li> <li><code>n_features</code>: Number of features</li> <li><code>n_modalities</code>: Number of modalities</li> <li><code>n_units</code>: Number of hexagons</li> <li><code>offset_data</code>: ?</li> <li><code>random_key</code>: the random seed for reproduction</li> </ul> </li> </ul>"},{"location":"reference/run_ficture2/#lda-training-output","title":"LDA Training Output","text":"<ul> <li><code>t{width}_f{n_factor}.model.tsv</code>: A matrix to store the learned topic-word distribution.     <pre><code>Feature  0        1      2      3      4      5      6         7      8      9      10        11       12     13     14        15     16     17     18      19     20      21     22     23\nNeu4     481.168  0.042  0.042  0.042  0.042  0.042  1828.293  0.042  0.042  0.042  2290.443  836.722  0.042  0.042  1704.589  0.042  0.042  0.042  29.738  0.042  24.854  0.042  0.042  0.042\n</code></pre><ul> <li>Rows (str): LDA topics or spatial factors</li> <li>Columns (int): Feature identifiers (e.g., gene names or indices)</li> <li>Values (float): Probability or weight of a feature under each topic <code>(P(feature | topic))</code></li> </ul> </li> <li><code>t{width}_f{n_factor}.results.tsv.gz</code>: A tab-delimited file containing the posterior topic distributions for each hexagon. <pre><code>x           y          0       1       2       3       4       5       6       7       8       9       10      11      12      13      14      15      16      17      18      19      20      21      22      23      topK  topP\n14202.0000  5393.6062  0.0000  0.5087  0.0860  0.0000  0.0269  0.0000  0.0136  0.0000  0.0000  0.0179  0.0153  0.0000  0.0490  0.0000  0.0982  0.0000  0.0911  0.0199  0.0143  0.0189  0.0373  0.0000  0.0030  0.0000  1     0.5087\n</code></pre><ul> <li><code>x</code> and <code>y</code> (float): X Y coordinates of the hexagon.</li> <li>Columns <code>0</code> to <code>{n_factor-1}</code> (float): Posterior probabilities for each latent factor <code>(P(topic | hexagon))</code></li> <li><code>topK</code> (int): Index of the most probable factor</li> <li><code>topP</code> (float): Posterior probability of the top factor</li> </ul> </li> <li> <p><code>t{width}_f{n_factor}.bulk_chisq.tsv</code> <pre><code>gene  factor  Chi2      pval      FoldChange  gene_total  log10pval\nApp   0       864182.5  0.00e+00  4.41        1422353     187657.91\n</code></pre></p> <ul> <li><code>gene</code> (str): Gene names.</li> <li><code>factor</code> (int): Factor IDs.</li> <li><code>Chi2</code> (float): Chi-squared test statistic comparing the expression in the target factor and the rest.</li> <li><code>pval</code> (float): P-value associated with the chi-squared test.</li> <li><code>FoldChange</code> (float): Ratio of gene expression inside versus outside the factor\u2019s high-loading region.</li> <li><code>gene_total</code> (int): Total count of the gene in the dataset.</li> <li><code>log10pval</code> (float): Base-10 logarithm of the inverse p-value (i.e., -log10(pval)), useful for ranking significant genes.</li> </ul> </li> <li> <p><code>t{width}_f{n_factor}.factor.info.tsv</code> and <code>t{width}_f{n_factor}.factor.info.html</code>: A TSV and HTML file providing the information for each factor per line.     <pre><code>Factor  RGB          Weight   PostUMI   TopGene_pval                                                                                                                                       TopGene_fc                                                                                                                                           TopGene_weight\n0       255,101,101  0.11279  82949360  App, Snrpn, Calm3, Eef1a2, Dctn1, Ptprn2, Akt3, Tmem181a, Sgtb, Ncdn, Selenow, Atp6v0a1, Cacng8, Atp2a2, Stub1, Akap5, Cmip, Cap1, Rundc3a, Ptprn  Sgtb, Map3k9, Cmip, Vps51, Ptprn2, Zscan2, Ppp2cb, Cacng8, Als2, Eif4e3, Ubxn2a, Gabrb2, Pms1, Rnpc3, Prepl, Zfp418, Tmem181a, Akap5, Dctn1, Atp2b3  App, Calm3, Selenow, Camk2n1, Snrpn, Ncdn, Atp2a2, Eef1a2, Uchl1, Ndfip1, Snap25, Stxbp1, Ywhag, Arf3, Serinc1, Atp6v1b2, Maged1, Atp6v0a1, Dnm1, Rab6b\n</code></pre></p> <ul> <li><code>Factor</code> (int): Factor IDs</li> <li><code>RGB</code> (str): Comma-separated RGB values</li> <li><code>Weight</code> (float): Proportion of the total factor signal explained by this factor</li> <li><code>PostUMI</code> (int): Sum of posterior UMI counts across all spatial locations for this factor</li> <li><code>TopGene_pval</code>, <code>TopGene_fc</code>, <code>TopGene_weight</code> (str): Top marker genes per factor ranked by significance (p-value), fold change, or weight</li> </ul> </li> <li><code>t{width}_f{n_factor}.cmap.tsv</code>: a color map.     <pre><code>R    G    B    Color_hex  Name\n255  101  101  #ff6565    0\n</code></pre><ul> <li><code>Name</code> (int): Factor IDs</li> <li><code>Color_hex</code> (str): Color HEX code</li> <li><code>R</code>, <code>G</code>, <code>B</code> (float): Red, Green, and Blue channel values (range: 0.0 to 1.0)</li> </ul> </li> </ul>"},{"location":"reference/run_ficture2/#decoding-output","title":"Decoding Output","text":"<ul> <li> <p><code>t{width}_f{n_factor}_p{width}_a{anchor_res}.tsv.gz</code>: A tab-delimited file where each line represents a pixel\u2013feature pair, recording the pixel\u2019s coordinates, the expressed feature and its count, along with the top three most probable latent factors (<code>K1</code>\u2013<code>K3</code>) and their corresponding probabilities (<code>P1</code>\u2013<code>P3</code>).     <pre><code>#x         y         feature  ct  K1  K2  K3  P1          P2          P3\n5159.4800  450.1500  Retreg2  1   0   19  9   9.5073e-01  4.8011e-02  5.0298e-04\n</code></pre></p> <ul> <li><code>x</code> and <code>y</code> (float): X Y coordinates</li> <li><code>feature</code> (str): feature names.</li> <li><code>ct</code> (int): count</li> <li><code>K1</code> (int) and <code>P1</code> (float): The most probable factor and its probability</li> <li><code>K2</code> (int) and <code>P2</code> (float): The 2nd most probable factor and its probability</li> <li><code>K3</code> (int) and <code>P3</code> (float): The 3rd most probable factor and its probability</li> </ul> </li> <li> <p><code>t{width}_f{n_factor}_p{width}_a{anchor_res}.index</code>: An index file for <code>t{width}_f{n_factor}_p{width}_a{anchor_res}.tsv.gz</code>.</p> </li> <li><code>t{width}_f{n_factor}_p{width}_a{anchor_res}.json</code>: A JSON file to provide header information for <code>t{width}_f{n_factor}_p{width}_a{anchor_res}.tsv.gz</code>.     <pre><code>{\n    \"K1\": 4,\n    \"K2\": 5,\n    \"K3\": 6,\n    \"P1\": 7,\n    \"P2\": 8,\n    \"P3\": 9,\n    \"ct\": 3,\n    \"feature\": 2,\n    \"x\": 0,\n    \"y\": 1\n}\n</code></pre></li> <li><code>t{width}_f{n_factor}_p{width}_a{anchor_res}.png</code>: A PNG file to visualize the spatial factors distribution at pixel level.</li> <li> <p><code>t{width}_f{n_factor}_p{width}_a{anchor_res}.pseudobulk.tsv</code>: A feature-by-factor matrix showing feature distribution across topics.     <pre><code>Feature  0         1       2       3       4       5       6          7       8       9       10         11        12      13      14        15      16      17      18       19      20       21      22      23\nNeu4     648.5156  0.0000  0.9999  0.0000  0.0000  2.1425  1316.2651  0.0000  0.0000  0.0000  1114.2935  527.5519  0.0000  0.0000  820.3735  0.0000  0.0000  3.3504  30.4680  0.0000  38.0400  0.0000  0.0000  0.0000\n</code></pre></p> <ul> <li>Rows (str): LDA topics or spatial factors</li> <li>Columns (int): Feature identifiers (e.g., gene names or indices)</li> <li>Values (float): Posterior probability of a feature in a factor.</li> </ul> </li> <li> <p><code>t{width}_f{n_factor}_p{width}_a{anchor_res}.bulk_chisq.tsv</code>: Same format as the <code>t{width}_f{n_factor}.bulk_chisq.tsv</code></p> </li> <li><code>t{width}_f{n_factor}_p{width}_a{anchor_res}.factor.info.tsv</code>:  Same format as the <code>t{width}_f{n_factor}.factor.info.tsv</code></li> <li><code>t{width}_f{n_factor}_p{width}_a{anchor_res}.factor.info.html</code>: Same format as the <code>t{width}_f{n_factor}.factor.info.html</code></li> </ul>"},{"location":"reference/run_ficture2/#summarization-output","title":"Summarization Output","text":"<ul> <li><code>ficture.params.json</code>: A JSON file to summarize the path to input, output, and paramaters.     <pre><code>{\n\"in_sge\": {\n    \"in_transcript\": \"/path/to/transcripts.unsorted.tsv.gz\",\n    \"in_feature\": \"/path/to/transcripts.tiled.features.hdr.tsv\",\n    \"in_minmax\": \"/path/to/coordinate_minmax.tsv\"\n},\n\"in_feature_ficture\": \"/path/to/transcripts.tiled.overlapping_features.min100.hdr.tsv\", # if available\n\"train_params\": [\n    {\n        \"model_type\": \"lda\",\n        \"model_id\": \"t{width}_f{n_factor}\",\n        \"model_path\": \"/path/to/t{width}_f{n_factor}.model.tsv\",\n        \"train_width\": width,\n        \"n_factor\": n_factor,\n        \"cmap\": \"/path/to/t{width}_f{n_factor}.cmap.tsv\",\n        \"decode_params\": [\n            {\n                \"decode_id\": \"t{width}_f{n_factor}_p{width}_a{anchor_res}\",\n                \"fit_width\": width,\n                \"anchor_res\": anchor_res\n            }\n        ]\n    }\n]\n}\n</code></pre></li> </ul>"},{"location":"reference/sge_convert/","title":"Spatial Gene Expression (SGE) Format Conversion","text":""},{"location":"reference/sge_convert/#overview","title":"Overview","text":"<p>Spatial Digital Gene Expression (SGE) datasets vary widely in format and resolution across platforms. To enable consistent downstream analysis, <code>cartloader</code> toolkit provides a <code>sge_convert</code> module to harmonize raw SGE data by converting it into standardized transcript-based SGE in a compressed TSV format, with spatial coordinates converted to a micrometer-based unit system without altering the original resolution.</p> <p>The current <code>sge_convert</code> supports standarizing SGE from sequencing-based platforms (e.g., Seq-Scope, Stereo-seq, Pixel-seq, 10x Visium HD) and imaging-based platforms (e.g., 10x Xenium, Vizgen MERSCOPE, CosMx SMI).</p>"},{"location":"reference/sge_convert/#example-usages","title":"Example Usages","text":""},{"location":"reference/sge_convert/#input-sge-in-mex-format","title":"Input SGE in MEX Format","text":""},{"location":"reference/sge_convert/#seq-scope","title":"<code>Seq-Scope</code>","text":"<pre><code>cartloader sge_convert \\\n    --platform seqscope \\\n    --in-mex /path/to/input/dir/of/mex \\   \n    --units-per-um 1000 \\\n    --icols-mtx 1 \\\n    --out-dir /path/to/output/dir \\\n    --colnames-count count \\\n    --filter-by-density \\\n    --out-filtered-prefix filtered \\\n    --genomic-feature count \\\n    --sge-visual \\\n    --north-up \\\n    --spatula /path/to/spatul/binary \n</code></pre>"},{"location":"reference/sge_convert/#10x-visium-hd","title":"<code>10X Visium HD</code>","text":"<pre><code>cartloader sge_convert \\\n    --platform 10x_visium_hd \\\n    --in-mex /path/to/input/dir/of/mex \\   \n    --icols-mtx 1 \\\n    --in-parquet /path/to/input/parquet/file \\\n    --scale-json /path/to/input/json/file \\\n    --exclude-feature-regex '^(BLANK.*$|NegCon.*$|NegPrb.*$|mt-.*$|Gm\\d+$)' \\\n    --out-dir /path/to/output/dir \\\n    --spatula /path/to/spatul/binary \\\n    --sge-visual \n</code></pre>"},{"location":"reference/sge_convert/#input-sge-in-tsvcsv-format","title":"Input SGE in TSV/CSV Format","text":"<p>This applied to input SGE in TSV/CSV format from platforms including 10X Xenium, StereoSeq, Cosmx SMI, MERSCOPE, Pixel-seq. Below is an example converting SGE from StereoSeq.</p> <pre><code>cartloader sge_convert \\\n    --platform bgi_stereoseq \\\n    --in-csv /path/to/input/csv/file \\\n    --units-per-um 28.75 \\\n    --out-dir /path/to/output/dir \\\n    --colnames-count count \\\n    --exclude-feature-regex '^(BLANK.*$|NegCon.*$|NegPrb.*$|mt-.*$|Gm\\d+$)' \\\n    --filter-by-density \\\n    --out-filtered-prefix filtered \\\n    --genomic-feature count \\\n    --sge-visual \\\n    --north-up \\\n    --spatula /path/to/spatul/binary \n</code></pre>"},{"location":"reference/sge_convert/#actions","title":"Actions","text":"<p>The following outlines the minimum required parameters for running SGE format conversion. </p> <p>For most auxiliary parameters, the default values are recommended and should only be modified when they do not suit your use case, e.g., the auxiliary input parameters. See more details in the collapsible sections below or by running: <pre><code>cartloader sge_convert --help\n</code></pre></p>"},{"location":"reference/sge_convert/#sge-conversion","title":"SGE Conversion","text":"<ul> <li> <p><code>--platform</code>: Source platform to infer the input file format and default setting. </p> <code>platform</code> options <ul> <li><code>10x_visium_hd</code>: 10X Visium HD. Provide raw SGE by <code>--in-mex</code>, <code>--in-parquet</code>, <code>--scale-json</code>.</li> <li><code>seqscope</code>: SeqScope. Provide raw SGE by <code>--in-mex</code>.</li> <li><code>10x_xenium</code>: 10X Xenium. Provide raw SGE by <code>--in-csv</code>.</li> <li><code>bgi_stereoseq</code>: StereoSeq. Provide raw SGE by <code>--in-csv</code>.</li> <li><code>cosmx_smi</code>: CosMX SMI. Provide raw SGE by <code>--in-csv</code>.</li> <li><code>vizgen_merscope</code>: Vizgen MERSCOPE. Provide raw SGE by <code>--in-csv</code>.</li> <li><code>pixel_seq</code>: Pixel-seq. Provide raw SGE by <code>--in-csv</code>.</li> <li><code>nova_st</code>: NovaST. Provide raw SGE by <code>--in-csv</code>.</li> <li><code>generic</code>: Generic TSV input. Provide raw SGE by <code>--in-csv</code>.</li> </ul> </li> <li> <p><code>--in-mex</code>: Path to the input SGE directory in MEX format. Required for MEX-formatted data (e.g., 10X Visium HD, SeqScope).</p> </li> <li><code>--in-csv</code>: Path to the input SGE file in CSV or TSV format. Required for CSV/TSV-formatted data (e.g., 10X Xenium, StereoSeq, CosMX SMI, MERSCOPE, Pixel-seq, NovaST).</li> <li><code>--in-parquet</code>: Path to the input parquet file with spatial coordinates, if available. Typically named <code>tissue_positions.parquet</code> (10X Visium HD).</li> <li><code>--scale-json</code>: Path to the scale JSON file used to compute <code>--units-per-um</code>, if available. Typically named <code>scalefactors_json.json</code> (10X Visium HD).</li> <li><code>--units-per-um</code>: Coordinate units per micrometer (default: 1.00). Skip if <code>--scale-json</code> is provided.</li> <li><code>--out-dir</code>: Path to the output directory.</li> </ul> Auxiliary SGE Conversion Paramaters <p>Auxiliary Input MEX Parameters:</p> <ul> <li><code>--icols-mtx</code>: Comma-separated, 1-based indices of the target genomic features among the count columns in the input matrix file. (Default: 1)</li> <li><code>--colnames-count</code>: Comma-separated output column names for the specified genomic features. (Default: count). The number of names specified by <code>--colnames-count</code> must match the number of indices provided in <code>--icols-mtx</code>.</li> </ul> <p>Auxiliary Input CSV/TSV Parameters:</p> <ul> <li><code>--csv-comment</code>: If enabled, lines starts with <code>#</code> will be skipped (default: <code>False</code> for 10X Xenium, StereoSeq, CosMx SMI, MERSCOPE, and Pixel-seq; <code>True</code> for NovaST).</li> <li><code>--csv-delim</code>: Delimiter for the input file (default: <code>\",\"</code> for 10X Xenium, CosMx SMI, and MERSCOPE; <code>\"\\t\"</code> for StereoSeq, Pixel-seq, and NovaST).</li> <li><code>--csv-colname-x</code>: Column name for X coordinates (default: <code>x_location</code> for 10X Xenium; <code>x</code> for StereoSeq and NovaST; <code>x_local_px</code> for CosMx SMI; <code>global_x</code> for MERSCOPE; <code>xcoord</code> for Pixel-seq).</li> <li><code>--csv-colname-y</code>: Column name for Y coordinates (default: <code>y_location</code> for 10X Xenium; <code>y</code> for StereoSeq and NovaST; <code>y_local_px</code> for CosMx SMI; <code>global_y</code> for MERSCOPE; <code>ycoord</code> for Pixel-seq).</li> <li><code>--csv-colnames-count</code>: Comma-separated column names for expression count. If not provided, a count of 1 per transcript (default: <code>MIDCounts</code> for StereoSeq; <code>MIDCount</code> for NovaST).</li> <li><code>--csv-colname-feature-name</code>: Column name for gene name (default: <code>feature_name</code> for 10X Xenium; <code>geneID</code> for StereoSeq; <code>target</code> for CosMx SMI; <code>gene</code> for MERSCOPE; <code>geneName</code> for Pixel-seq; <code>geneID</code> for NovaST). </li> <li><code>--csv-colnames-others</code>: Columns names to keep.</li> <li><code>--csv-colname-phredscore</code>: Column name for Phred-scaled quality value estimating the probability of incorrect calls (default: <code>qv</code> for 10X Xenium).</li> <li><code>--min-phred-score</code>: Phred-scaled quality score cutoff (default: <code>20</code> for 10X Xenium).</li> </ul> <p>Auxiliary Output Parameters: </p> <ul> <li><code>--out-transcript</code>: File name for output compressed transcript-indexed SGE file in TSV format (default: <code>transcripts.unsorted.tsv.gz</code>).</li> <li><code>--out-minmax</code>: File name for coordinate min-max values in TSV format (default: <code>coordinate_minmax.tsv</code>).</li> <li><code>--out-feature</code>: File name for compressed UMI count per gene in TSV format (default: <code>feature.clean.tsv.gz</code>).</li> <li><code>--precision-um</code>: Decimal precision for transcript coordinates; set to <code>0</code> to round to integers (default: 2).</li> <li><code>--colname-x</code>: Column name for the X-coordinate in the output SGE (default: X).</li> <li><code>--colname-y</code>: Column name for the Y-coordinate in the output SGE (default: Y).</li> <li><code>--colnames-count</code>: Comma-separated column names for expression count in the output SGE (default: count).</li> <li><code>--colname-feature-name</code>: Column name for the gene name in the output SGE(default: gene). </li> </ul> <p>Auxiliary Environment Parameters If the binaries are already available in your system's <code>PATH</code>, you may omit these options.</p> <ul> <li><code>--gzip</code> (str): Path to <code>gzip</code> binary; consider <code>pigz -p 4</code> for faster processing. (Default: <code>gzip</code>)</li> <li><code>--spatula</code> (str): Path to <code>spatula</code> binary. (Default: <code>spatula</code>)</li> <li><code>--parquet-tools</code> (str): Required if <code>--in-parquet</code> is used; path to <code>parquet-tools</code> binary. (Default: <code>parquet-tools</code>)</li> </ul>"},{"location":"reference/sge_convert/#optional-gene-filtering","title":"Optional Gene Filtering","text":"<ul> <li><code>--include-feature-regex</code>: A regex pattern of feature/gene names to be included.</li> <li><code>--exclude-feature-regex</code>: A regex pattern of feature/gene names to be excluded.</li> </ul>"},{"location":"reference/sge_convert/#optional-density-based-filtering","title":"Optional Density-based Filtering","text":"<ul> <li><code>--filter-by-density</code>: Enable filtering of SGE by density.</li> <li><code>--out-filtered-prefix</code>: Prefix for output filtered SGE files (default: filtered).</li> <li><code>--genomic-feature</code>: Genomic feature to be used for density-based filtering. Defaults to the value of <code>--colnames-count</code> if only one column name is provided.</li> </ul> Auxiliary Density-based Filtering Paramaters <ul> <li><code>--mu-scale</code>: Scale factor for the polygon area calculation (default: 1.0).</li> <li><code>--radius</code>: Radius for the polygon area calculation (default: 15).</li> <li><code>--quartile</code>: Quartile for the polygon area calculation (default: 2).</li> <li><code>--hex-n-move</code>: Sliding step (default: 1).</li> <li><code>--polygon-min-size</code>: The minimum polygon size (default: 500).</li> </ul>"},{"location":"reference/sge_convert/#optional-sge-visualization","title":"Optional SGE Visualization","text":"<ul> <li><code>sge-visual</code>: Enable SGE visualization.</li> <li><code>--north-up</code>: Enable the north-up orientation for the SGE visualization.</li> </ul> Auxiliary SGE Visualization Paramaters <ul> <li><code>--out-xy</code> (str): File name for output SGE visualization image (default: <code>xy.png</code>).</li> <li><code>--out-northup-tif</code> (str): File name for output north-up orientated image (default: <code>xy_northup.tif</code>).</li> <li><code>--srs</code> (str): If <code>--north-up</code>, define the spatial reference system (default: EPSG:3857).</li> <li><code>--resample</code> (str): If <code>--north-up</code>, Define the resampling method (default: cubic). Options: near, bilinear, cubic, etc.</li> <li><code>--gdal_translate</code> (str): Required if <code>--north-up</code>; path to <code>gdal_translate</code> binary. (Default: <code>gdal_translate</code>)</li> <li><code>--gdalwarp</code> (str): Required if <code>--north-up</code>; path to <code>gdalwarp</code> binary. (Default: <code>gdalwarp</code>)</li> </ul>"},{"location":"reference/sge_convert/#output","title":"Output","text":"<p>Cartloader generates the following harmonized outputs:</p>"},{"location":"reference/sge_convert/#unified-sge-matrix","title":"Unified SGE matrix","text":"<p>Both SGE conversion and density-based filtering generate a unified spatial gene expression (SGE) matrix, consisting of:</p> <ul> <li>A compressed transcript-indexed SGE file in TSV format.</li> <li>A TSV file for min and max X and Y coordinates.</li> <li>A TSV file collects UMI counts on a per-gene basis.</li> </ul>"},{"location":"reference/sge_convert/#sge-images","title":"SGE Images","text":"<ul> <li>When <code>--sge-visual</code> is enabled, a monochrome PNG image is generated to visualize the SGE data.</li> <li>When <code>--north-up</code> is enabled, a georeferenced TIFF image is produced with a north-up orientation.</li> </ul>"},{"location":"vignettes/intro/","title":"Getting Started with <code>cartloader</code>","text":"<p>We offer a series of tutorials to help users master the <code>cartloader</code> toolkit across a range of scenarios \u2014 from simple getting-started examples to processing full-scale ST datasets. </p> <p>For a more detailed explanation of each step, refer to our References Page.</p>"},{"location":"vignettes/intro/#quick-start","title":"Quick Start","text":"<p>If you're new to <code>cartloader</code>, we recommend beginning with the Quick Start tutorial. </p> <p>This vignette provides a beginner-friendly walkthrough using a small mouse hippocampus dataset to walks through <code>cartloader</code> functions.</p> <ul> <li> <p> Quick Start Tutorial </p> <p>Read</p> </li> </ul>"},{"location":"vignettes/intro/#getting-started-per-platform","title":"Getting Started per Platform","text":"<p>These tutorials show how to process data from different ST platforms using small, representative subregions.</p> <p>For each platform, we extract a subset of SGE representing the mouse hippocampus as input. If hippocampal data is not available for a given platform, we select one subregion from the mouse brain to illustrate the workflow.</p>"},{"location":"vignettes/intro/#sequencing-based-platforms","title":"Sequencing-based Platforms","text":"<ul> <li> <p> SeqScope Starter Guide </p> <p>Read</p> </li> <li> <p> 10X Visium HD Starter Guide </p> <p>Read</p> </li> <li> <p> StereoSeq Starter Guide </p> <p>Read</p> </li> <li> <p> Pixel-seq Starter Guide </p> <p>Read</p> </li> </ul>"},{"location":"vignettes/intro/#imaging-based-platforms","title":"Imaging-based Platforms","text":"<ul> <li> <p> 10x Xenium Starter Guide </p> <p>Read</p> </li> <li> <p> Vizgen MERSCOPE Starter Guide </p> <p>Read</p> </li> <li> <p> CosMX SMI Starter Guide </p> <p>Read</p> </li> </ul>"},{"location":"vignettes/intro/#real-world-use-cases","title":"Real-World Use Cases","text":"<p>These examples demonstrate how to process walk through real-world whole-sample ST datasets. Each example uses a whole mouse brain sample for consistency.</p>"},{"location":"vignettes/intro/#multi-sample-batch-analysis","title":"Multi-Sample Batch Analysis","text":"<p>Warning</p> <p>This function is still under development</p> <p>This upcoming section will showcase how to process multiple samples in a single batch. It will include tutorials on cross-sample analysis.</p>"},{"location":"vignettes/quickstart/","title":"A Quick Start","text":"<p>This page provides a quick-start example with a small dataset to help users verify their installation and get familiar with <code>cartloader</code> and the <code>cartostore</code> workflow.</p> <p>The workflow consists of four major steps:</p> <ol> <li>SGE Format Conversion \u2014 prepares raw SGE into a harmonized format.</li> <li>FICTURE Analysis \u2014 computes factor embeddings and visualizations via <code>punkst</code>.</li> <li>Cartloader Compilation \u2014 generates web-compatible tiles using <code>tippecanoe</code> and <code>pmtiles</code>.</li> <li>AWS Upload \u2014 places results into an AWS S3 bucket for sharing via <code>cartostore</code>.</li> </ol> <p>Requirement</p> <p>Before getting started, please ensure that cartloader and all prerequisites are installed by following the Installation guide.</p>"},{"location":"vignettes/quickstart/#input-data","title":"Input Data","text":"<p>Input Data Requirement:</p> <p>Input data should be a transcript-indexed SGE containing at least:</p> <ul> <li>Spatial coordinates (X coordinates, Y coordinates)</li> <li>Feature metadata (gene symbols)</li> <li>Expression Counts</li> </ul> <p>Example Dataset</p> <p>This tutorial uses an example SGE from mouse hippocampus, extracted via spatial masking from a Seq-Scope coronal brain slice.</p> <p>File Format</p> <p>Actual input formats are platform-dependent. Please refer to the Vignettes for detailed input specifications by each platform.</p> <p>SeqScope provides SGE with three files:</p> <code>barcodes.tsv.gz</code> \u2013 spatial barcode metadata <pre><code>AAAACAAAAACCTTCTTCGGACACTGGTCT  1   20  1   1   295288  1422349 0,1,0,0,0\nAAAACAAAAATCCTGTTATACATGCCATGG  2   45  1   1   1745544 1110720 2,2,1,0,1\nAAAACAAAACACGGGAAAAAACTATAGGTG  3   58  1   1   887244  250820  7,7,5,0,1\n</code></pre> <ul> <li>Column 1: Sorted spatial barcodes</li> <li>Column 2: 1-based integer index of spatial barcodes, used in <code>matrix.mtx.gz</code></li> <li>Column 3: 1-based integer index from the full barcode that is in the STARsolo output</li> <li>Column 4: Lane ID (fixed as <code>1</code>)  </li> <li>Column 5: Tile ID (fixed as <code>1</code>)  </li> <li>Column 6: X-coordinates</li> <li>Column 7: Y-coordinates</li> <li>Column 8: Five comma-separated numbers denote the count per spatial barcode for \"Gene\", \"GeneFull\", \"Spliced\", \"Unspliced\", and \"Ambiguous\".</li> </ul> <code>features.tsv.gz</code> \u2013 feature metadata  <pre><code>ENSMUSG00000100764  Gm29155 1   1,1,1,0,0\nENSMUSG00000100635  Gm29157 2   0,0,0,0,0\nENSMUSG00000100480  Gm29156 3   0,0,0,0,0\n</code></pre> <ul> <li>Column 1: Feature ID</li> <li>Column 2: Feature symbol</li> <li>Column 3: 1-based integer index of genes, used in <code>matrix.mtx.gz</code></li> <li>Column 4: Five comma-separated numbers denote the count per gene \"Gene\", \"GeneFull\", \"Spliced\", \"Unspliced\", and \"Ambiguous\".</li> </ul> <code>matrix.mtx.gz</code> \u2013 expression count matrix  <pre><code>%%MatrixMarket matrix coordinate integer general\n%\n33989 2928173 5404336\n2487 1 0 1 0 0 0\n5104 2 1 1 0 0 1\n</code></pre> <ul> <li><code>Header</code>: Initial lines form the header, declaring the matrix's adherence to the Market Matrix (MTX) format, outlining its traits. This may include comments (lines beginning with <code>%</code>) for extra metadata, all marked by a \u201c%\u201d.</li> <li><code>Dimensions</code>: Following the header, the first line details the matrix dimensions: the count of rows (features), columns (barcodes), and non-zero entries.</li> <li><code>Data Entries</code>: Post-dimensions, subsequent lines enumerate non-zero entries in seven columns: row index (feature index), column index (barcode index), and five values (expression levels) corresponds to \"Gene\", \"GeneFull\", \"Spliced\", \"Unspliced\", and \"Ambiguous\".       <ul> <li>\"Gene\": represents unique, confidently mapped transcript count (\"gene name\"-based);</li> <li>\"GeneFull\": denotes total transcript count assigned to gene (includes ambiguities).</li> </ul> </li> </ul> <p>Data Access</p> <p>The example data is hosted on Zenedo (10.5281/zenodo.15701394).</p> <p>Follow the commands below to download the example data.</p> <pre><code>wget  https://zenodo.org/api/records/15701394/draft/files/seqscope_mousebrain_subset.raw.tar.gz/content \ntar zxvf seqscope_mousebrain_subset.raw.tar.gz\n</code></pre>"},{"location":"vignettes/quickstart/#set-up-the-environment","title":"Set Up the Environment","text":"<p>Define paths to all required binaries and resources, and target AWS S3 bucket. Optionally, specify a fixed color map for consistent rendering.</p> <pre><code># ====\n# Replace each placeholder with the actual path on your system.  \n# ====\n\n# Define paths to required binaries and resources\nspatula=/path/to/spatula/binary         # path to spatula executable\npunkst=/path/to/punkst/binary           # path to FICTURE2/punkst executable\ntippecanoe=/path/to/tippecanoe/binary   # path to tippecanoe executable\npmtiles=/path/to/pmtiles/binary         # path to pmtiles executable\naws=/path/to/aws/cli/binary             # path to AWS CLI binary\n\n# (Optional) Define path to color map. \ncmap=/path/to/color/map                 # Path to the fixed color map for rendering. cartloader provides a fixed color map at cartloader/assets/fixed_color_map_256.tsv.\n\n# AWS S3 target location for cartostore\nAWS_BUCKET=\"EXAMPLE_AWS_BUCKET\"         # replace this with your actual S3 bucket name\n</code></pre> <p>Define data ID and analysis parameters:</p> <pre><code>cd $work_dir\n\n# Unique identifier for your dataset\nDATA_ID=\"seqscope_hippo\"                # change this to reflect your dataset name\nPLATFORM=\"seqscope\"                     # platform information\nSCALE=1000                            # scale from coordinate to micrometer\n\n# LDA parameters\ntrain_width=18                           # define LDA training hexagon width (comma-separated if multiple widths are applied)\nn_factor=6,12                            # define number of factors in LDA training (comma-separated if multiple n-factor are applied)\n</code></pre> <p>How to Define Scaling Factors for Seq-Scope</p> <p>The latest SeqScope with an Illumina NovaSeq 6000 uses <code>NovaScope</code> pipeline to process sequencing data. <code>NovaScope</code> defaults to generate SGE at nanometer (nm) resolution, meaning each pixel corresponds to 1\u202fnm.</p> <p>Thus, use 1000 as scaling factor from coordinate to micrometer since 1000 nm = 1 \u00b5m.</p>"},{"location":"vignettes/quickstart/#sge-format-conversion","title":"SGE Format Conversion","text":"<p>Convert the raw input to the unified SGE format. See more details in SGE Format Conversion.</p> <pre><code>cartloader sge_convert \\\n  --makefn sge_convert.mk \\\n  --platform ${PLATFORM} \\\n  --in-mex ./raw \\\n  --units-per-um ${SCALE} \\\n  --icols-mtx 1 \\\n  --out-dir ./sge \\\n  --exclude-feature-regex '^(BLANK|NegCon|NegPrb)' \\\n  --sge-visual \\\n  --spatula ${spatula} \\\n  --n-jobs 10\n</code></pre> Parameter Required Type Description <code>--makefn</code> string File name for the generated Makefile <code>--platform</code> required string Platform (options: \"10x_visium_hd\", \"seqscope\", \"10x_xenium\", \"bgi_stereoseq\", \"cosmx_smi\", \"vizgen_merscope\", \"pixel_seq\", \"nova_st\", \"generic\") <code>--in-mex</code> required string Path to the input MEX directory containing gene \u00d7 barcode matrix <code>--units-per-um</code> required float scale to convert coordinates to microns <code>--icols-mtx</code> comma-separated list Comma-separated 1-based indices for the target genomic features among the count columns in input matrix.mtx.gz (the example only takes \"Gene\") <code>--out-dir</code> required string Output directory for the converted SGE files <code>--exclude-feature-regex</code> regex Pattern to exclude control features (e.g., BLANK, NegCon, NegPrb) <code>--sge-visual</code> flag Enable SGE visualization step (generates diagnostic image) <code>--spatula</code> string Path to the spatula binary <code>--n-jobs</code> int Number of parallel jobs for processing"},{"location":"vignettes/quickstart/#ficture-analysis","title":"<code>FICTURE</code> analysis","text":"<p>Compute spatial factors using <code>punkst</code> (FICTURE2 mode). See more details in Reference page.</p> <pre><code>cartloader run_ficture2 \\\n  --makefn run_ficture2.mk \\\n  --main \\\n  --in-transcript ./sge/transcripts.unsorted.tsv.gz \\\n  --in-feature ./sge/feature.clean.tsv.gz \\\n  --in-minmax ./sge/coordinate_minmax.tsv \\\n  --cmap-file ${cmap} \\\n  --exclude-feature-regex '^(mt-.*$|Gm\\d+$)' \\\n  --out-dir ./ficture2 \\\n  --width ${train_width} \\\n  --n-factor ${n_factor} \\\n  --spatula ${spatula} \\\n  --ficture2 ${punkst} \\\n  --n-jobs 10 \\\n  --threads 10\n</code></pre> Parameter Required Type Description <code>--makefn</code> string File name for the generated Makefile <code>--main</code> required flag Run all five steps in <code>run_ficture2</code> <code>--in-transcript</code> required string Path to input transcript-level SGE file <code>--in-feature</code> string Path to input feature file <code>--in-minmax</code> string Path to coordinate min/max file <code>--cmap-file</code> string Path to color map file <code>--exclude-feature-regex</code> regex Pattern to exclude features (e.g., mitochondrial or predicted genes) <code>--out-dir</code> required string Path to output directory <code>--width</code> required int or comma-separated list LDA training hexagon width(s) <code>--n-factor</code> required int or comma-separated list Number of LDA factors <code>--spatula</code> string Path to the <code>spatula</code> binary <code>--ficture2</code> string Path to the <code>punkst</code> directory <code>--n-jobs</code> int Number of parallel jobs <code>--threads</code> int Number of threads per job"},{"location":"vignettes/quickstart/#cartloader-compilation","title":"<code>cartloader</code> Compilation","text":"<p>Generate pmtiles and web-compatible tile directories. See more details in Reference page.</p> <pre><code>cartloader run_cartload2 \\\n  --makefn run_cartload2.mk \\\n  --fic-dir ./ficture2 \\\n  --out-dir ./cartload2 \\\n  --id ${DATA_ID} \\\n  --spatula ${spatula} \\\n  --pmtiles ${pmtiles} \\\n  --tippecanoe ${tippecanoe} \\\n  --n-jobs 10 \\\n  --threads 10\n</code></pre> Parameter Required Type Description <code>--makefn</code> string File name for the generated Makefile <code>--fic-dir</code> required string Path to the input directory containing FICTURE2 output <code>--out-dir</code> required string Path to the output directory for PMTiles and web tiles <code>--id</code> required string Dataset ID used for naming outputs and metadata <code>--spatula</code> string Path to the <code>spatula</code> binary <code>--pmtiles</code> string Path to the <code>pmtiles</code> binary <code>--tippecanoe</code> string Path to the <code>tippecanoe</code> binary <code>--n-jobs</code> int Number of parallel jobs <code>--threads</code> int Number of threads per job"},{"location":"vignettes/quickstart/#upload-to-data-repository","title":"Upload to Data Repository","text":""},{"location":"vignettes/quickstart/#upload-to-aws","title":"Upload to AWS","text":"<p>Copy the generated cartloader outputs to your designated AWS S3 catalog path:</p> <pre><code>cartloader upload_aws_by_catalog \\\n  --in-dir ./cartload2 \\\n  --s3-dir \"s3://${AWS_BUCKET}/${DATA_ID}\" \\\n  --aws ${aws} \\\n  --n-jobs 10\n</code></pre> Parameter Required Type Description <code>--in-dir</code> required string Path to the input directory containing the cartloader compilation output <code>--s3-dir</code> required string Path to the target S3 directory for uploading <code>--aws</code> string Path to the AWS CLI binary <code>--n-jobs</code> int Number of parallel jobs"},{"location":"vignettes/subregion_tutorials/cosmx_smi/","title":"CosMX SMI Starter Tutorial","text":""},{"location":"vignettes/subregion_tutorials/cosmx_smi/#input-data","title":"Input Data","text":"<p>The input data is from an adult mouse hippocampus, extracted by masking a coronal brain section. The original full-section </p> <p>File Format</p> <p>The CosMx SMI by NanoString generates high-resolution spatial transcriptomics data with single-molecule resolution with a comma-separated values (CSV) table.</p> <p>CSV File Format</p> <pre><code>\"fov\",\"cell_ID\",\"x_global_px\",\"y_global_px\",\"x_local_px\",\"y_local_px\",\"z\",\"target\",\"CellComp\"\n64,0,-473043,7954.533,4015.3,4246.2,1,\"Gfap\",\"None\"\n64,0,-473022.9,7902.723,4035.48,4194.39,1,\"Fth1\",\"None\"\n64,0,-473132,7836.476,3926.34,4128.143,1,\"Ptn\",\"None\"\n</code></pre> <ul> <li><code>fov</code>: The field of view (FOV) number.</li> <li><code>cell_ID</code>: Unique identifier for a single cell within a given FOV. 0 if background or unassigned molecules.</li> <li><code>x_global_px</code>, <code>y_global_px</code>: Global pixel coordinates relative to the tisse.</li> <li><code>x_local_px</code>, <code>y_local_px</code>: The x or y position (in pixels) relative to the given FOV.</li> <li><code>z</code>: Z-plane index representing the depth (optical section) where the transcript was detected.</li> <li><code>target</code>: Name of the target.</li> <li><code>CellComp</code>: Subcellular location of target.</li> </ul> <p>Data Access</p> <p>The example data is hosted on Zenedo ().</p> <p>Follow the commands below to download the example data.</p> <pre><code>work_dir=/path/to/work/directory\ncd $work_dir\nwget \ntar -zxvf \n</code></pre>"},{"location":"vignettes/subregion_tutorials/cosmx_smi/#set-up-the-environment","title":"Set Up the Environment","text":"<p>Define paths to all required binaries and resources, and target AWS S3 bucket. Optionally, specify a fixed color map for consistent rendering.</p> <pre><code># ====\n# Replace each placeholder with the actual path on your system.  \n# ====\n\n# Define paths to required binaries and resources\nspatula=/path/to/spatula/binary         # path to spatula executable\npunkst=/path/to/punkst/binary           # path to FICTURE2/punkst executable\ntippecanoe=/path/to/tippecanoe/binary   # path to tippecanoe executable\npmtiles=/path/to/pmtiles/binary         # path to pmtiles executable\naws=/path/to/aws/cli/binary             # path to AWS CLI binary\n\n# (Optional) Define path to color map. \ncmap=/path/to/color/map                 # Path to the fixed color map for rendering. cartloader provides a fixed color map at cartloader/assets/fixed_color_map_256.tsv.\n\n# AWS S3 target location for cartostore\nAWS_BUCKET=\"EXAMPLE_AWS_BUCKET\"         # replace this with your actual S3 bucket name\n</code></pre> <p>Define data ID and analysis parameters:</p> <pre><code>cd $work_dir\n\n# Unique identifier for your dataset\nDATA_ID=\"cosmxsmi_hippo\"                # change this to reflect your dataset name\nPLATFORM=\"cosmx_smi\"                    # platform information\nSCALE=$(echo 1000/120|bc -l)              # scale from coordinate to micrometer\n\n# LDA parameters\ntrain_width=12                           # define LDA training hexagon width (comma-separated if multiple widths are applied)\nn_factor=6,12                            # define number of factors in LDA training (comma-separated if multiple n-factor are applied)\n</code></pre> <p>How to Define Scaling Factors for CosMX SMI?</p> <p>According to the README.html provided with the Pixel-seq dataset, each pixel has an edge length of 120\u202fnm. To calculate the number of pixels per micrometer, use the formula: scale = 1000 / 120.</p>"},{"location":"vignettes/subregion_tutorials/cosmx_smi/#sge-format-conversion","title":"SGE Format Conversion","text":"<p>Convert the raw input to the unified SGE format. See more details in Reference page.</p> <pre><code>cartloader sge_convert \\\n  --makefn sge_convert.mk \\\n  --platform ${PLATFORM} \\\n  --in-csv ./input.tsv.gz \\\n  --units-per-um ${SCALE} \\\n  --out-dir ./sge \\\n  --exclude-feature-regex '^(BLANK|NegCon|NegPrb)' \\\n  --sge-visual \\\n  --spatula ${spatula} \\\n  --n-jobs 10\n</code></pre> Parameter Required Type Description <code>--makefn</code> string File name for the generated Makefile <code>--platform</code> required string platform (options: \"10x_visium_hd\", \"seqscope\", \"10x_xenium\", \"bgi_stereoseq\", \"cosmx_smi\", \"vizgen_merscope\", \"pixel_seq\", \"nova_st\", \"generic\") <code>--in-csv</code> required string Path to the input TSV/CSV file <code>--units-per-um</code> required float Conversion factor: how many input coordinate units per micron <code>--out-dir</code> required string Output directory for the generated SGE files <code>--exclude-feature-regex</code> regex Pattern to exclude features (e.g., BLANK, NegCon) <code>--sge-visual</code> flag Enable generation of diagnostic visualization of the SGE matrix <code>--spatula</code> string Path to the spatula binary <code>--n-jobs</code> int Number of parallel jobs for processing"},{"location":"vignettes/subregion_tutorials/cosmx_smi/#ficture-analysis","title":"<code>FICTURE</code> analysis","text":"<p>Compute spatial factors using <code>punkst</code> (FICTURE2 mode). See more details in Reference page.</p> <pre><code>cartloader run_ficture2 \\\n  --makefn run_ficture2.mk \\\n  --main \\\n  --in-transcript ./sge/transcripts.unsorted.tsv.gz \\\n  --in-feature ./sge/feature.clean.tsv.gz \\\n  --in-minmax ./sge/coordinate_minmax.tsv \\\n  --cmap-file ${cmap} \\\n  --exclude-feature-regex '^(mt-.*$|Gm\\d+$)' \\\n  --out-dir ./ficture2 \\\n  --width ${train_width} \\\n  --n-factor ${n_factor} \\\n  --spatula ${spatula} \\\n  --ficture2 ${punkst} \\\n  --n-jobs 10 \\\n  --threads 10\n</code></pre> Parameter Required Type Description <code>--makefn</code> string File name for the generated Makefile <code>--main</code> required flag Run all five steps in <code>run_ficture2</code> <code>--in-transcript</code> required string Path to input transcript-level SGE file <code>--in-feature</code> string Path to input feature file <code>--in-minmax</code> string Path to coordinate min/max file <code>--cmap-file</code> string Path to color map file <code>--exclude-feature-regex</code> regex Pattern to exclude features (e.g., mitochondrial or predicted genes) <code>--out-dir</code> required string Path to output directory <code>--width</code> required int or comma-separated list LDA training hexagon width(s) <code>--n-factor</code> required int or comma-separated list Number of LDA factors <code>--spatula</code> string Path to the <code>spatula</code> binary <code>--ficture2</code> string Path to the <code>punkst</code> directory <code>--n-jobs</code> int Number of parallel jobs <code>--threads</code> int Number of threads per job"},{"location":"vignettes/subregion_tutorials/cosmx_smi/#cartloader-compilation","title":"<code>cartloader</code> Compilation","text":"<p>Generate pmtiles and web-compatible tile directories. See more details in Reference page.</p> <pre><code>cartloader run_cartload2 \\\n  --makefn run_cartload2.mk \\\n  --fic-dir ./ficture2 \\\n  --out-dir ./cartload2 \\\n  --id ${DATA_ID} \\\n  --spatula ${spatula} \\\n  --pmtiles ${pmtiles} \\\n  --tippecanoe ${tippecanoe} \\\n  --n-jobs 10 \\\n  --threads 10\n</code></pre> Parameter Required Type Description <code>--makefn</code> string File name for the generated Makefile <code>--fic-dir</code> required string Path to the input directory containing FICTURE2 output <code>--out-dir</code> required string Path to the output directory for PMTiles and web tiles <code>--id</code> required string Dataset ID used for naming outputs and metadata <code>--spatula</code> string Path to the <code>spatula</code> binary <code>--pmtiles</code> string Path to the <code>pmtiles</code> binary <code>--tippecanoe</code> string Path to the <code>tippecanoe</code> binary <code>--n-jobs</code> int Number of parallel jobs <code>--threads</code> int Number of threads per job"},{"location":"vignettes/subregion_tutorials/cosmx_smi/#upload-to-data-repository","title":"Upload to Data Repository","text":""},{"location":"vignettes/subregion_tutorials/cosmx_smi/#upload-to-aws","title":"Upload to AWS","text":"<p>Copy the generated cartloader outputs to your designated AWS S3 catalog path:</p> <pre><code>cartloader upload_aws_by_catalog \\\n  --in-dir ./cartload2 \\\n  --s3-dir \"s3://${AWS_BUCKET}/${DATA_ID}\" \\\n  --aws ${aws} \\\n  --n-jobs 10\n</code></pre> Parameter Required Type Description <code>--in-dir</code> required string Path to the input directory containing the cartloader compilation output <code>--s3-dir</code> required string Path to the target S3 directory for uploading <code>--aws</code> string Path to the AWS CLI binary <code>--n-jobs</code> int Number of parallel jobs"},{"location":"vignettes/subregion_tutorials/merscope/","title":"Vizgen MERSCOPE Starter Tutorial","text":""},{"location":"vignettes/subregion_tutorials/merscope/#input-data","title":"Input Data","text":"<p>The input is a spatial gene expression (SGE) dataset from the adult mouse hippocampus, extracted by masking a coronal brain section (Slice Number: 2\uff1bReplicate Number: 1; file: <code>detected_transcripts.csv</code>) from Vizgen MERSCOPE Neuroscience Showcase.</p> <p>File Format</p> <p>The MERSCOPE input SGE includes one comma delimited text file with the following format:</p> <p>CSV file format</p> <pre><code>,barcode_id,global_x,global_y,global_z,x,y,fov,gene\n0,22,56.930107,3851.851,5.0,147.80061,1711.9067,0,Adgre1\n1,22,183.60107,3874.0085,5.0,1320.6799,1917.0692,0,Adgre1\n2,22,59.750736,3666.5576,5.0,132.66754,1844.2372,1,Adgre1\n</code></pre> <ul> <li>Column 1: Unique numeric index for each transcript within a field of view (non-consecutive, ascending).  </li> <li><code>barcode_id</code>: Zero-based index of the transcript barcode in the codebook; forms a composite key with <code>fov</code>.</li> <li><code>global_x</code>: Transcript x coordinates (\u00b5m) in the experimental region; may be negative due to alignment.  </li> <li><code>global_y</code>: Transcript y coordinates (\u00b5m) in the experimental region; may be negative due to alignment.  </li> <li><code>global_z</code>: The index of the z-position. The position is a zero-indexed integer.</li> <li><code>x</code>: The x-coordinate of the transcript (\u00b5m), within the coordinate space of the field of view.</li> <li><code>y</code>: The y-coordinate of the transcript (\u00b5m), within the coordinate space of the field of view.</li> <li><code>fov</code>: Zero-based field of view index; forms a composite key with <code>barcode_id</code>.  </li> <li><code>gene</code>: Gene name associated with the transcript.</li> </ul> <p>Data Access</p> <p>The example data is hosted on Zenedo ().</p> <p>Follow the commands below to download the example data.</p> <pre><code>work_dir=/path/to/work/directory\ncd $work_dir\nwget \ntar -zxvf \n</code></pre>"},{"location":"vignettes/subregion_tutorials/merscope/#set-up-the-environment","title":"Set Up the Environment","text":"<p>Define paths to all required binaries and resources, and target AWS S3 bucket. Optionally, specify a fixed color map for consistent rendering.</p> <pre><code># ====\n# Replace each placeholder with the actual path on your system.  \n# ====\n\n# Define paths to required binaries and resources\nspatula=/path/to/spatula/binary         # path to spatula executable\npunkst=/path/to/punkst/binary           # path to FICTURE2/punkst executable\ntippecanoe=/path/to/tippecanoe/binary   # path to tippecanoe executable\npmtiles=/path/to/pmtiles/binary         # path to pmtiles executable\naws=/path/to/aws/cli/binary             # path to AWS CLI binary\n\n# (Optional) Define path to color map. \ncmap=/path/to/color/map                 # Path to the fixed color map for rendering. cartloader provides a fixed color map at cartloader/assets/fixed_color_map_256.tsv.\n\n# AWS S3 target location for cartostore\nAWS_BUCKET=\"EXAMPLE_AWS_BUCKET\"         # replace this with your actual S3 bucket name\n</code></pre> <p>Define data ID and analysis parameters:</p> <pre><code>cd $work_dir\n\n# Unique identifier for your dataset\nDATA_ID=\"merscope_hippo\"                # change this to reflect your dataset name\nPLATFORM=\"vizgen_merscope\"              # platform information\nSCALE=1                               # scale from coordinate to micrometer\n\n# LDA parameters\ntrain_width=12                           # define LDA training hexagon width (comma-separated if multiple widths are applied)\nn_factor=6,12                            # define number of factors in LDA training (comma-separated if multiple n-factor are applied)\n</code></pre> <p>How to Define Scaling Factors for MERSCOPE?</p> <p>The MERSCOPE example data currently used here provides SGE in micrometer units. Use define scaling factor from coordinate to micrometer as 1.</p>"},{"location":"vignettes/subregion_tutorials/merscope/#sge-format-conversion","title":"SGE Format Conversion","text":"<p>Convert the raw input to the unified SGE format. See more details in Reference page.</p> <pre><code>cartloader sge_convert \\\n  --makefn sge_convert.mk \\\n  --platform ${PLATFORM} \\\n  --in-csv ./input.tsv.gz \\\n  --units-per-um ${SCALE} \\\n  --out-dir ./sge \\\n  --exclude-feature-regex '^(BLANK|NegCon|NegPrb)' \\\n  --sge-visual \\\n  --spatula ${spatula} \\\n  --n-jobs 10\n</code></pre> Parameter Required Type Description <code>--makefn</code> string File name for the generated Makefile <code>--platform</code> required string platform (options: \"10x_visium_hd\", \"seqscope\", \"10x_xenium\", \"bgi_stereoseq\", \"cosmx_smi\", \"vizgen_merscope\", \"pixel_seq\", \"nova_st\", \"generic\") <code>--in-csv</code> required string Path to the input TSV/CSV file <code>--units-per-um</code> required float Conversion factor: how many input coordinate units per micron <code>--out-dir</code> required string Output directory for the generated SGE files <code>--exclude-feature-regex</code> regex Pattern to exclude features (e.g., BLANK, NegCon) <code>--sge-visual</code> flag Enable generation of diagnostic visualization of the SGE matrix <code>--spatula</code> string Path to the spatula binary <code>--n-jobs</code> int Number of parallel jobs for processing"},{"location":"vignettes/subregion_tutorials/merscope/#ficture-analysis","title":"<code>FICTURE</code> analysis","text":"<p>Compute spatial factors using <code>punkst</code> (FICTURE2 mode). See more details in Reference page.</p> <pre><code>cartloader run_ficture2 \\\n  --makefn run_ficture2.mk \\\n  --main \\\n  --in-transcript ./sge/transcripts.unsorted.tsv.gz \\\n  --in-feature ./sge/feature.clean.tsv.gz \\\n  --in-minmax ./sge/coordinate_minmax.tsv \\\n  --cmap-file ${cmap} \\\n  --exclude-feature-regex '^(mt-.*$|Gm\\d+$)' \\\n  --out-dir ./ficture2 \\\n  --width ${train_width} \\\n  --n-factor ${n_factor} \\\n  --spatula ${spatula} \\\n  --ficture2 ${punkst} \\\n  --n-jobs 10 \\\n  --threads 10\n</code></pre> Parameter Required Type Description <code>--makefn</code> string File name for the generated Makefile <code>--main</code> required flag Run all five steps in <code>run_ficture2</code> <code>--in-transcript</code> required string Path to input transcript-level SGE file <code>--in-feature</code> string Path to input feature file <code>--in-minmax</code> string Path to coordinate min/max file <code>--cmap-file</code> string Path to color map file <code>--exclude-feature-regex</code> regex Pattern to exclude features (e.g., mitochondrial or predicted genes) <code>--out-dir</code> required string Path to output directory <code>--width</code> required int or comma-separated list LDA training hexagon width(s) <code>--n-factor</code> required int or comma-separated list Number of LDA factors <code>--spatula</code> string Path to the <code>spatula</code> binary <code>--ficture2</code> string Path to the <code>punkst</code> directory <code>--n-jobs</code> int Number of parallel jobs <code>--threads</code> int Number of threads per job"},{"location":"vignettes/subregion_tutorials/merscope/#cartloader-compilation","title":"<code>cartloader</code> Compilation","text":"<p>Generate pmtiles and web-compatible tile directories. See more details in Reference page.</p> <pre><code>cartloader run_cartload2 \\\n  --makefn run_cartload2.mk \\\n  --fic-dir ./ficture2 \\\n  --out-dir ./cartload2 \\\n  --id ${DATA_ID} \\\n  --spatula ${spatula} \\\n  --pmtiles ${pmtiles} \\\n  --tippecanoe ${tippecanoe} \\\n  --n-jobs 10 \\\n  --threads 10\n</code></pre> Parameter Required Type Description <code>--makefn</code> string File name for the generated Makefile <code>--fic-dir</code> required string Path to the input directory containing FICTURE2 output <code>--out-dir</code> required string Path to the output directory for PMTiles and web tiles <code>--id</code> required string Dataset ID used for naming outputs and metadata <code>--spatula</code> string Path to the <code>spatula</code> binary <code>--pmtiles</code> string Path to the <code>pmtiles</code> binary <code>--tippecanoe</code> string Path to the <code>tippecanoe</code> binary <code>--n-jobs</code> int Number of parallel jobs <code>--threads</code> int Number of threads per job"},{"location":"vignettes/subregion_tutorials/merscope/#upload-to-data-repository","title":"Upload to Data Repository","text":""},{"location":"vignettes/subregion_tutorials/merscope/#upload-to-aws","title":"Upload to AWS","text":"<p>Copy the generated cartloader outputs to your designated AWS S3 catalog path:</p> <pre><code>cartloader upload_aws_by_catalog \\\n  --in-dir ./cartload2 \\\n  --s3-dir \"s3://${AWS_BUCKET}/${DATA_ID}\" \\\n  --aws ${aws} \\\n  --n-jobs 10\n</code></pre> Parameter Required Type Description <code>--in-dir</code> required string Path to the input directory containing the cartloader compilation output <code>--s3-dir</code> required string Path to the target S3 directory for uploading <code>--aws</code> string Path to the AWS CLI binary <code>--n-jobs</code> int Number of parallel jobs"},{"location":"vignettes/subregion_tutorials/pixelseq/","title":"Pixel-Seq Starter Tutorial","text":""},{"location":"vignettes/subregion_tutorials/pixelseq/#input-data","title":"Input Data","text":"<p>Since the Pixel-Seq publication provides SGE data only from the mouse olfactory bulb and parabrachial nucleus \u2014 neither of which includes the hippocampus \u2014 we extract a subregion from the olfactory bulb as the input for this tutorial.</p> <p>File Format</p> <p>The Pixel-Seq SGE includes one tab-delimited text file, where each row represents a unique RNA molecule detected within a defined field of view (FOV), with associated genomic and spatial metadata.</p> <p>TSV file format</p> <pre><code>FOVx  FOVy  xcoord     ycoord     UMIs     SpatialBarcode            MapStrand  Chrom  Start      STARmapping        Counts  geneID              geneName  bioType                 intronRatio\n017   005   26691.5    5786.5     TAACGAA  AAGGTTCATACCTACGACTGTTAA  16         1      24613729   150M               1       ENSMUSG00000101111  Gm28437   unprocessed_pseudogene  0.00\n016   007   27590.25   4639.0815  TAATATA  AATGGCGCATTTTGCTGTTTAGGC  16         2      39001628   138M2341N12M       1       ENSMUSG00000062997  Rpl35     protein_coding          0.00\n018   006   25099.945  5621.8335  AGTTGTA  CTGCATATGTGTCACCTAGGTAGC  16         1      24615767   150M               1       ENSMUSG00000101249  Gm29216   unprocessed_pseudogene  0.00\n</code></pre> <ul> <li><code>FOVx</code>, <code>FOVy</code>: Field-of-view indices indicating the imaging tile coordinates in the x and y directions.</li> <li><code>xcoord</code>, <code>ycoord</code>: Spatial coordinates (in microns or pixels).</li> <li><code>UMIs</code>: Unique molecular identifier (UMI) sequence.</li> <li><code>SpatialBarcode</code>: Spatial barcode capturing the location and identity.</li> <li><code>MapStrand</code>: Indicates the strand orientation of the mapped read.</li> <li><code>Chrom</code>, <code>Start</code>: Chromosome number and start position of the mapped read on the genome.</li> <li><code>STARmapping</code>: Alignment pattern (CIGAR string) from the STAR aligner indicating how the transcript maps to the genome.</li> <li><code>Counts</code>: Number of times the UMI/gene combination was observed.</li> <li><code>geneID</code>, <code>geneName</code>: Ensembl gene ID and gene symbol.</li> <li><code>bioType</code>: Gene biotype.</li> <li><code>intronRatio</code>: Fraction of UMI counts assigned to intronic regions.</li> </ul> <p>Data Access</p> <p>The example data is hosted on Zenedo ().</p> <p>Follow the commands below to download the example data.</p> <pre><code>work_dir=/path/to/work/directory\ncd $work_dir\nwget \ntar -zxvf \n</code></pre>"},{"location":"vignettes/subregion_tutorials/pixelseq/#set-up-the-environment","title":"Set Up the Environment","text":"<p>Define paths to all required binaries and resources, and target AWS S3 bucket. Optionally, specify a fixed color map for consistent rendering.</p> <pre><code># ====\n# Replace each placeholder with the actual path on your system.  \n# ====\n\n# Define paths to required binaries and resources\nspatula=/path/to/spatula/binary         # path to spatula executable\npunkst=/path/to/punkst/binary           # path to FICTURE2/punkst executable\ntippecanoe=/path/to/tippecanoe/binary   # path to tippecanoe executable\npmtiles=/path/to/pmtiles/binary         # path to pmtiles executable\naws=/path/to/aws/cli/binary             # path to AWS CLI binary\n\n# (Optional) Define path to color map. \ncmap=/path/to/color/map                 # Path to the fixed color map for rendering. cartloader provides a fixed color map at cartloader/assets/fixed_color_map_256.tsv.\n\n# AWS S3 target location for cartostore\nAWS_BUCKET=\"EXAMPLE_AWS_BUCKET\"         # replace this with your actual S3 bucket name\n</code></pre> <p>Define data ID and analysis parameters:</p> <pre><code>cd $work_dir\n\n# Unique identifier for your dataset\nDATA_ID=\"pixelseq_hippo\"                # change this to reflect your dataset name\nPLATFORM=\"pixel_seq\"                    # platform information\nSCALE=3.076923                        # scale from coordinate to micrometer\n\n# LDA parameters\ntrain_width=18                           # define LDA training hexagon width (comma-separated if multiple widths are applied)\nn_factor=6,12                            # define number of factors in LDA training (comma-separated if multiple n-factor are applied)\n</code></pre> <p>How to Define Scaling Factors for Pixel-Seq?</p> <p>In Pixel-Seq publication:</p> <p>\"Because polonies have varied sizes and shapes, to maximize the feature resolution we developed a base-calling pipeline to determine the major barcode species in each pixel (0.325 * 0.325 mm2) of gel images to construct a spatial barcode map\".</p> <p>Accordingly, we defined scale as 1/0.325 = 3.076923</p>"},{"location":"vignettes/subregion_tutorials/pixelseq/#sge-format-conversion","title":"SGE Format Conversion","text":"<p>Convert the raw input to the unified SGE format. See more details in Reference page.</p> <pre><code>cartloader sge_convert \\\n  --makefn sge_convert.mk \\\n  --platform ${PLATFORM} \\\n  --in-csv ./input.tsv.gz \\\n  --units-per-um ${SCALE} \\\n  --out-dir ./sge \\\n  --exclude-feature-regex '^(BLANK|NegCon|NegPrb)' \\\n  --sge-visual \\\n  --spatula ${spatula} \\\n  --n-jobs 10\n</code></pre> Parameter Required Type Description <code>--makefn</code> string File name for the generated Makefile <code>--platform</code> required string platform (options: \"10x_visium_hd\", \"seqscope\", \"10x_xenium\", \"bgi_stereoseq\", \"cosmx_smi\", \"vizgen_merscope\", \"pixel_seq\", \"nova_st\", \"generic\") <code>--in-csv</code> required string Path to the input TSV/CSV file <code>--units-per-um</code> required float Conversion factor: how many input coordinate units per micron <code>--out-dir</code> required string Output directory for the generated SGE files <code>--exclude-feature-regex</code> regex Pattern to exclude features (e.g., BLANK, NegCon) <code>--sge-visual</code> flag Enable generation of diagnostic visualization of the SGE matrix <code>--spatula</code> string Path to the spatula binary <code>--n-jobs</code> int Number of parallel jobs for processing"},{"location":"vignettes/subregion_tutorials/pixelseq/#ficture-analysis","title":"<code>FICTURE</code> analysis","text":"<p>Compute spatial factors using <code>punkst</code> (FICTURE2 mode). See more details in Reference page.</p> <pre><code>cartloader run_ficture2 \\\n  --makefn run_ficture2.mk \\\n  --main \\\n  --in-transcript ./sge/transcripts.unsorted.tsv.gz \\\n  --in-feature ./sge/feature.clean.tsv.gz \\\n  --in-minmax ./sge/coordinate_minmax.tsv \\\n  --cmap-file ${cmap} \\\n  --exclude-feature-regex '^(mt-.*$|Gm\\d+$)' \\\n  --out-dir ./ficture2 \\\n  --width ${train_width} \\\n  --n-factor ${n_factor} \\\n  --spatula ${spatula} \\\n  --ficture2 ${punkst} \\\n  --n-jobs 10 \\\n  --threads 10\n</code></pre> Parameter Required Type Description <code>--makefn</code> string File name for the generated Makefile <code>--main</code> required flag Run all five steps in <code>run_ficture2</code> <code>--in-transcript</code> required string Path to input transcript-level SGE file <code>--in-feature</code> string Path to input feature file <code>--in-minmax</code> string Path to coordinate min/max file <code>--cmap-file</code> string Path to color map file <code>--exclude-feature-regex</code> regex Pattern to exclude features (e.g., mitochondrial or predicted genes) <code>--out-dir</code> required string Path to output directory <code>--width</code> required int or comma-separated list LDA training hexagon width(s) <code>--n-factor</code> required int or comma-separated list Number of LDA factors <code>--spatula</code> string Path to the <code>spatula</code> binary <code>--ficture2</code> string Path to the <code>punkst</code> directory <code>--n-jobs</code> int Number of parallel jobs <code>--threads</code> int Number of threads per job"},{"location":"vignettes/subregion_tutorials/pixelseq/#cartloader-compilation","title":"<code>cartloader</code> Compilation","text":"<p>Generate pmtiles and web-compatible tile directories. See more details in Reference page.</p> <pre><code>cartloader run_cartload2 \\\n  --makefn run_cartload2.mk \\\n  --fic-dir ./ficture2 \\\n  --out-dir ./cartload2 \\\n  --id ${DATA_ID} \\\n  --spatula ${spatula} \\\n  --pmtiles ${pmtiles} \\\n  --tippecanoe ${tippecanoe} \\\n  --n-jobs 10 \\\n  --threads 10\n</code></pre> Parameter Required Type Description <code>--makefn</code> string File name for the generated Makefile <code>--fic-dir</code> required string Path to the input directory containing FICTURE2 output <code>--out-dir</code> required string Path to the output directory for PMTiles and web tiles <code>--id</code> required string Dataset ID used for naming outputs and metadata <code>--spatula</code> string Path to the <code>spatula</code> binary <code>--pmtiles</code> string Path to the <code>pmtiles</code> binary <code>--tippecanoe</code> string Path to the <code>tippecanoe</code> binary <code>--n-jobs</code> int Number of parallel jobs <code>--threads</code> int Number of threads per job"},{"location":"vignettes/subregion_tutorials/pixelseq/#upload-to-data-repository","title":"Upload to Data Repository","text":""},{"location":"vignettes/subregion_tutorials/pixelseq/#upload-to-aws","title":"Upload to AWS","text":"<p>Copy the generated cartloader outputs to your designated AWS S3 catalog path:</p> <pre><code>cartloader upload_aws_by_catalog \\\n  --in-dir ./cartload2 \\\n  --s3-dir \"s3://${AWS_BUCKET}/${DATA_ID}\" \\\n  --aws ${aws} \\\n  --n-jobs 10\n</code></pre> Parameter Required Type Description <code>--in-dir</code> required string Path to the input directory containing the cartloader compilation output <code>--s3-dir</code> required string Path to the target S3 directory for uploading <code>--aws</code> string Path to the AWS CLI binary <code>--n-jobs</code> int Number of parallel jobs"},{"location":"vignettes/subregion_tutorials/stereoseq/","title":"StereoSeq Starter Tutorial","text":""},{"location":"vignettes/subregion_tutorials/stereoseq/#input-data","title":"Input Data","text":"<p>The input data represents mouse hippocampus. For demonstration purposes, we selected the adult mouse brain coronal section from the official release and extracted only the hippocampus region. The full-section data sourced from the Stereo-seq platform, as part of the MOSTA project.</p> <p>File Format</p> <p>The StereoSeq SGE includes one tab-delimited \u201cBin1\u201d gene expression matrix file:</p> <p>TSV File Format</p> <pre><code>geneID          x       y       MIDCounts\n0610005C13Rik   6632    9074    1\n0610005C13Rik   8651    8935    1\n0610005C13Rik   7228    12814   2\n</code></pre> <ul> <li>\"<code>geneID</code>\": gene symbols</li> <li>\"<code>x</code>\": x coordinates of each DNB on the captured chip</li> <li>\"<code>y</code>\": y coordinates of each DNB on the captured chip</li> <li>\"<code>MIDCounts</code>\": the number of UMI for each gene at each DNB</li> </ul> <p>Data Access</p> <p>The example data is hosted on Zenedo ().</p> <p>Follow the commands below to download the example data.</p> <pre><code>work_dir=/path/to/work/directory\ncd $work_dir\nwget \ntar -zxvf \n</code></pre>"},{"location":"vignettes/subregion_tutorials/stereoseq/#set-up-the-environment","title":"Set Up the Environment","text":"<p>Define paths to all required binaries and resources, and target AWS S3 bucket. Optionally, specify a fixed color map for consistent rendering.</p> <pre><code># ====\n# Replace each placeholder with the actual path on your system.  \n# ====\n\n# Define paths to required binaries and resources\nspatula=/path/to/spatula/binary         # path to spatula executable\npunkst=/path/to/punkst/binary           # path to FICTURE2/punkst executable\ntippecanoe=/path/to/tippecanoe/binary   # path to tippecanoe executable\npmtiles=/path/to/pmtiles/binary         # path to pmtiles executable\naws=/path/to/aws/cli/binary             # path to AWS CLI binary\n\n# (Optional) Define path to color map. \ncmap=/path/to/color/map                 # Path to the fixed color map for rendering. cartloader provides a fixed color map at cartloader/assets/fixed_color_map_256.tsv.\n\n# AWS S3 target location for cartostore\nAWS_BUCKET=\"EXAMPLE_AWS_BUCKET\"         # replace this with your actual S3 bucket name\n</code></pre> <p>Define data ID and analysis parameters:</p> <pre><code>cd $work_dir\n\n# Unique identifier for your dataset\nDATA_ID=\"stereoseq_hippo\"                # change this to reflect your dataset name\nPLATFORM=\"bgi_stereoseq\"                 # platform information\nSCALE=2                                  # scale from coordinate to micrometer\n\n# LDA parameters\ntrain_width=18                           # define LDA training hexagon width (comma-separated if multiple widths are applied)\nn_factor=6,12                            # define number of factors in LDA training (comma-separated if multiple n-factor are applied)\n</code></pre> <p>How to Define Scaling Factors for StereoSeq?</p> <p>According to the StereoSeq paper, the technology features spot sizes of approximately 220 nanometers in diameter with center-to-center distances of about 500 nanometers. Thus, each pixel corresponds to approximately 0.5 micrometers. The scaling factor from coordinate to um is defined as 2.</p>"},{"location":"vignettes/subregion_tutorials/stereoseq/#sge-format-conversion","title":"SGE Format Conversion","text":"<p>Convert the raw input to the unified SGE format. See more details in Reference page.</p> <pre><code>cartloader sge_convert \\\n  --makefn sge_convert.mk \\\n  --platform ${PLATFORM} \\\n  --in-csv ./input.tsv.gz \\\n  --units-per-um ${SCALE} \\\n  --out-dir ./sge \\\n  --exclude-feature-regex '^(BLANK|NegCon|NegPrb)' \\\n  --sge-visual \\\n  --spatula ${spatula} \\\n  --n-jobs 10\n</code></pre> Parameter Required Type Description <code>--makefn</code> string File name for the generated Makefile <code>--platform</code> required string platform (options: \"10x_visium_hd\", \"seqscope\", \"10x_xenium\", \"bgi_stereoseq\", \"cosmx_smi\", \"vizgen_merscope\", \"pixel_seq\", \"nova_st\", \"generic\") <code>--in-csv</code> required string Path to the input TSV/CSV file <code>--units-per-um</code> required float Conversion factor: how many input coordinate units per micron <code>--out-dir</code> required string Output directory for the generated SGE files <code>--exclude-feature-regex</code> regex Pattern to exclude features (e.g., BLANK, NegCon) <code>--sge-visual</code> flag Enable generation of diagnostic visualization of the SGE matrix <code>--spatula</code> string Path to the spatula binary <code>--n-jobs</code> int Number of parallel jobs for processing"},{"location":"vignettes/subregion_tutorials/stereoseq/#ficture-analysis","title":"<code>FICTURE</code> analysis","text":"<p>Compute spatial factors using <code>punkst</code> (FICTURE2 mode). See more details in Reference page.</p> <pre><code>cartloader run_ficture2 \\\n  --makefn run_ficture2.mk \\\n  --main \\\n  --in-transcript ./sge/transcripts.unsorted.tsv.gz \\\n  --in-feature ./sge/feature.clean.tsv.gz \\\n  --in-minmax ./sge/coordinate_minmax.tsv \\\n  --cmap-file ${cmap} \\\n  --exclude-feature-regex '^(mt-.*$|Gm\\d+$)' \\\n  --out-dir ./ficture2 \\\n  --width ${train_width} \\\n  --n-factor ${n_factor} \\\n  --spatula ${spatula} \\\n  --ficture2 ${punkst} \\\n  --n-jobs 10 \\\n  --threads 10\n</code></pre> Parameter Required Type Description <code>--makefn</code> string File name for the generated Makefile <code>--main</code> required flag Run all five steps in <code>run_ficture2</code> <code>--in-transcript</code> required string Path to input transcript-level SGE file <code>--in-feature</code> string Path to input feature file <code>--in-minmax</code> string Path to coordinate min/max file <code>--cmap-file</code> string Path to color map file <code>--exclude-feature-regex</code> regex Pattern to exclude features (e.g., mitochondrial or predicted genes) <code>--out-dir</code> required string Path to output directory <code>--width</code> required int or comma-separated list LDA training hexagon width(s) <code>--n-factor</code> required int or comma-separated list Number of LDA factors <code>--spatula</code> string Path to the <code>spatula</code> binary <code>--ficture2</code> string Path to the <code>punkst</code> directory <code>--n-jobs</code> int Number of parallel jobs <code>--threads</code> int Number of threads per job"},{"location":"vignettes/subregion_tutorials/stereoseq/#cartloader-compilation","title":"<code>cartloader</code> Compilation","text":"<p>Generate pmtiles and web-compatible tile directories. See more details in Reference page.</p> <pre><code>cartloader run_cartload2 \\\n  --makefn run_cartload2.mk \\\n  --fic-dir ./ficture2 \\\n  --out-dir ./cartload2 \\\n  --id ${DATA_ID} \\\n  --spatula ${spatula} \\\n  --pmtiles ${pmtiles} \\\n  --tippecanoe ${tippecanoe} \\\n  --n-jobs 10 \\\n  --threads 10\n</code></pre> Parameter Required Type Description <code>--makefn</code> string File name for the generated Makefile <code>--fic-dir</code> required string Path to the input directory containing FICTURE2 output <code>--out-dir</code> required string Path to the output directory for PMTiles and web tiles <code>--id</code> required string Dataset ID used for naming outputs and metadata <code>--spatula</code> string Path to the <code>spatula</code> binary <code>--pmtiles</code> string Path to the <code>pmtiles</code> binary <code>--tippecanoe</code> string Path to the <code>tippecanoe</code> binary <code>--n-jobs</code> int Number of parallel jobs <code>--threads</code> int Number of threads per job"},{"location":"vignettes/subregion_tutorials/stereoseq/#upload-to-data-repository","title":"Upload to Data Repository","text":""},{"location":"vignettes/subregion_tutorials/stereoseq/#upload-to-aws","title":"Upload to AWS","text":"<p>Copy the generated cartloader outputs to your designated AWS S3 catalog path:</p> <pre><code>cartloader upload_aws_by_catalog \\\n  --in-dir ./cartload2 \\\n  --s3-dir \"s3://${AWS_BUCKET}/${DATA_ID}\" \\\n  --aws ${aws} \\\n  --n-jobs 10\n</code></pre> Parameter Required Type Description <code>--in-dir</code> required string Path to the input directory containing the cartloader compilation output <code>--s3-dir</code> required string Path to the target S3 directory for uploading <code>--aws</code> string Path to the AWS CLI binary <code>--n-jobs</code> int Number of parallel jobs"},{"location":"vignettes/subregion_tutorials/visiumhd/","title":"10X VisiumHD Starter Tutorial","text":""},{"location":"vignettes/subregion_tutorials/visiumhd/#input-data","title":"Input Data","text":"<p>The input data originates from the mouse hippocampus and is extracted from an official release of mouse brain spatial gene expression (SGE) data.</p> <p>File Format</p> <p>Visium HD slides use a 2\u00d72\u202f\u00b5m grid of barcoded squares (<code>square_002um</code>) for high-resolution spatial gene mapping. The SGE file format comprises several key files as below: </p> <code>barcodes.tsv.gz</code> \u2013 spatial barcode for tissue locations  <pre><code>s_002um_00639_00600-1\ns_002um_00923_01639-1\ns_002um_01050_01530-1\n</code></pre> <ul> <li>Column 1: spatial barcodes corresponding to specific locations on the tissue section. </li> </ul> <code>features.tsv.gz</code> \u2013 feature metadata  <pre><code>ENSMUSG00000051951  Xkr4    Gene Expression\nENSMUSG00000025900  Rp1     Gene Expression\nENSMUSG00000025902  Sox17   Gene Expression\n</code></pre> <ul> <li>Column 1: Feature ID</li> <li>Column 2: Feature symbol</li> <li>Column 3: Features types</li> </ul> <code>matrix.mtx.gz</code> \u2013 expression count matrix  <pre><code>%%MatrixMarket matrix coordinate integer general\n%\n19059 869411 11376563\n3606 1 1\n8957 1 1\n9733 1 1\n</code></pre> <ul> <li><code>Header</code>: Initial lines form the header, declaring the matrix's adherence to the Market Matrix (MTX) format, outlining its traits. This may include comments (lines beginning with <code>%</code>) for extra metadata, all marked by a \u201c%\u201d.</li> <li><code>Dimensions</code>: Following the header, the first line details the matrix dimensions: the count of rows (features), columns (barcodes), and non-zero entries.</li> <li><code>Data Entries</code>: Post-dimensions, subsequent lines enumerate non-zero entries in seven columns: row index (feature index), column index (barcode index), and one value presenting the expression count per barcode per feature.</li> </ul> <code>tissue_positions.parquet</code> \u2013 spatial barcode metadata  <pre><code>barcode                 in_tissue   array_row   array_col   pxl_row_in_fullres  pxl_col_in_fullres\ns_002um_00434_01637-1   1           434         1637        3396.371014         9125.919898\n</code></pre> <ul> <li><code>barcode</code>: Unique spatial barcode associated with each capture spot.</li> <li><code>in_tissue</code>: Binary flag (1 = in tissue, 0 = background) indicating whether the spot falls within the tissue boundary.</li> <li><code>array_row</code>, <code>array_col</code>: Integer indices representing the position of the spot on the capture array grid.</li> <li><code>pxl_row_in_fullres</code>, <code>pxl_col_in_fullres</code>: Floating point coordinates locating the spot in full-resolution tissue image pixels.</li> </ul> <code>scalefactors_json.json</code> \u2013 pixel-to-micrometer scaling factors  <pre><code>{\n    \"spot_diameter_fullres\": 7.303953797779634,\n    \"bin_size_um\": 2.0,\n    \"microns_per_pixel\": 0.2738242950835738,\n    \"regist_target_img_scalef\": 0.2505533,\n    \"tissue_lowres_scalef\": 0.02505533,\n    \"fiducial_diameter_fullres\": 1205.1523766336395,\n    \"tissue_hires_scalef\": 0.2505533\n}\n</code></pre> <ul> <li><code>spot_diameter_fullres</code>: Estimated diameter of a barcoded spot in full-resolution pixels.</li> <li><code>bin_size_um</code>: Physical size (in micrometers) of the smallest bin, typically 2.0\u202f\u00b5m for Visium HD.</li> <li><code>microns_per_pixel</code>: Resolution of the full-res image, used to convert pixel distances to micrometers.</li> <li><code>regist_target_img_scalef</code>: Scaling factor applied during image registration to the target image.</li> <li><code>tissue_lowres_scalef</code>: Downscaling factor from full-res to low-resolution tissue image.</li> <li><code>fiducial_diameter_fullres</code>: Diameter of fiducial markers in full-resolution pixels, useful for alignment.</li> <li><code>tissue_hires_scalef</code>: Downscaling factor from full-res to high-resolution tissue image.</li> </ul> <p>Data Access</p> <p>The example data is hosted on Zenedo ().</p> <p>Follow the commands below to download the example data.</p> <pre><code>work_dir=/path/to/work/directory\ncd $work_dir\nwget \ntar -zxvf \n</code></pre>"},{"location":"vignettes/subregion_tutorials/visiumhd/#set-up-the-environment","title":"Set Up the Environment","text":"<p>Define paths to all required binaries and resources, and target AWS S3 bucket. Optionally, specify a fixed color map for consistent rendering.</p> <pre><code># ====\n# Replace each placeholder with the actual path on your system.  \n# ====\n\n# Define paths to required binaries and resources\nspatula=/path/to/spatula/binary         # path to spatula executable\npunkst=/path/to/punkst/binary           # path to FICTURE2/punkst executable\ntippecanoe=/path/to/tippecanoe/binary   # path to tippecanoe executable\npmtiles=/path/to/pmtiles/binary         # path to pmtiles executable\naws=/path/to/aws/cli/binary             # path to AWS CLI binary\n\n# (Optional) Define path to color map. \ncmap=/path/to/color/map                 # Path to the fixed color map for rendering. cartloader provides a fixed color map at cartloader/assets/fixed_color_map_256.tsv.\n\n# AWS S3 target location for cartostore\nAWS_BUCKET=\"EXAMPLE_AWS_BUCKET\"         # replace this with your actual S3 bucket name\n</code></pre> <p>Define data ID and analysis parameters:</p> <pre><code>cd $work_dir\n\n# Unique identifier for your dataset\nDATA_ID=\"visiumhd_hippo\"                 # change this to reflect your dataset name\nPLATFORM=\"10x_visium_hd\"                 # platform information\n\n# LDA parameters\ntrain_width=18                           # define LDA training hexagon width (comma-separated if multiple widths are applied)\nn_factor=6,12                            # define number of factors in LDA training (comma-separated if multiple n-factor are applied)\n</code></pre> <p>How to Define Scaling Factors for Visium HD</p> <p>10x Visium HD includes a <code>scalefactors_json.json</code> file that provides pixel-to-micrometer scaling information. <code>cartloader</code> can directly accept this file via the <code>--scale-json</code> option and will automatically compute the appropriate scaling factor, omitting manually calculate and specify <code>--units-per-um</code>. </p> <p>Alternatively, users may bypass the JSON file by directly providing a value through the <code>--units-per-um</code> option.</p>"},{"location":"vignettes/subregion_tutorials/visiumhd/#sge-format-conversion","title":"SGE Format Conversion","text":"<p>Convert the raw input to the unified SGE format. See more details in Reference page.</p> <pre><code>cartloader sge_convert \\\n  --makefn sge_convert.mk \\\n  --platform ${PLATFORM} \\\n  --in-mex ./raw \\\n  --in-parquet ./raw/tissue_positions.parquet \\\n  --scale-json ./raw/scalefactors_json.json \\\n  --out-dir ./sge \\\n  --exclude-feature-regex '^(BLANK|NegCon|NegPrb)' \\\n  --sge-visual \\\n  --spatula ${spatula} \\\n  --n-jobs 10\n</code></pre> Parameter Required Type Description <code>--makefn</code> string File name for the generated Makefile <code>--platform</code> required string Platform (options: \"10x_visium_hd\", \"seqscope\", \"10x_xenium\", \"bgi_stereoseq\", \"cosmx_smi\", \"vizgen_merscope\", \"pixel_seq\", \"nova_st\", \"generic\") <code>--in-mex</code> required string Path to the input MEX directory containing gene \u00d7 barcode matrix <code>--in-parquet</code> required string Path to the <code>tissue_positions.parquet</code> file with spatial barcode metadata <code>--scale-json</code> string Path to the <code>scalefactors_json.json</code> file with coordinate scaling information. Alternatively, user could define the scale directly use <code>--units-per-um</code> <code>--out-dir</code> required string Output directory for the converted SGE files <code>--exclude-feature-regex</code> regex Pattern to exclude control features (e.g., BLANK, NegCon, NegPrb) <code>--sge-visual</code> flag Enable SGE visualization step (generates diagnostic image) <code>--spatula</code> string Path to the spatula binary <code>--n-jobs</code> int Number of parallel jobs for processing"},{"location":"vignettes/subregion_tutorials/visiumhd/#ficture-analysis","title":"<code>FICTURE</code> analysis","text":"<p>Compute spatial factors using <code>punkst</code> (FICTURE2 mode). See more details in Reference page.</p> <pre><code>cartloader run_ficture2 \\\n  --makefn run_ficture2.mk \\\n  --main \\\n  --in-transcript ./sge/transcripts.unsorted.tsv.gz \\\n  --in-feature ./sge/feature.clean.tsv.gz \\\n  --in-minmax ./sge/coordinate_minmax.tsv \\\n  --cmap-file ${cmap} \\\n  --exclude-feature-regex '^(mt-.*$|Gm\\d+$)' \\\n  --out-dir ./ficture2 \\\n  --width ${train_width} \\\n  --n-factor ${n_factor} \\\n  --spatula ${spatula} \\\n  --ficture2 ${punkst} \\\n  --n-jobs 10 \\\n  --threads 10\n</code></pre> Parameter Required Type Description <code>--makefn</code> string File name for the generated Makefile <code>--main</code> required flag Run all five steps in <code>run_ficture2</code> <code>--in-transcript</code> required string Path to input transcript-level SGE file <code>--in-feature</code> string Path to input feature file <code>--in-minmax</code> string Path to coordinate min/max file <code>--cmap-file</code> string Path to color map file <code>--exclude-feature-regex</code> regex Pattern to exclude features (e.g., mitochondrial or predicted genes) <code>--out-dir</code> required string Path to output directory <code>--width</code> required int or comma-separated list LDA training hexagon width(s) <code>--n-factor</code> required int or comma-separated list Number of LDA factors <code>--spatula</code> string Path to the <code>spatula</code> binary <code>--ficture2</code> string Path to the <code>punkst</code> directory <code>--n-jobs</code> int Number of parallel jobs <code>--threads</code> int Number of threads per job"},{"location":"vignettes/subregion_tutorials/visiumhd/#cartloader-compilation","title":"<code>cartloader</code> Compilation","text":"<p>Generate pmtiles and web-compatible tile directories. See more details in Reference page.</p> <pre><code>cartloader run_cartload2 \\\n  --makefn run_cartload2.mk \\\n  --fic-dir ./ficture2 \\\n  --out-dir ./cartload2 \\\n  --id ${DATA_ID} \\\n  --spatula ${spatula} \\\n  --pmtiles ${pmtiles} \\\n  --tippecanoe ${tippecanoe} \\\n  --n-jobs 10 \\\n  --threads 10\n</code></pre> Parameter Required Type Description <code>--makefn</code> string File name for the generated Makefile <code>--fic-dir</code> required string Path to the input directory containing FICTURE2 output <code>--out-dir</code> required string Path to the output directory for PMTiles and web tiles <code>--id</code> required string Dataset ID used for naming outputs and metadata <code>--spatula</code> string Path to the <code>spatula</code> binary <code>--pmtiles</code> string Path to the <code>pmtiles</code> binary <code>--tippecanoe</code> string Path to the <code>tippecanoe</code> binary <code>--n-jobs</code> int Number of parallel jobs <code>--threads</code> int Number of threads per job"},{"location":"vignettes/subregion_tutorials/visiumhd/#upload-to-data-repository","title":"Upload to Data Repository","text":""},{"location":"vignettes/subregion_tutorials/visiumhd/#upload-to-aws","title":"Upload to AWS","text":"<p>Copy the generated cartloader outputs to your designated AWS S3 catalog path:</p> <pre><code>cartloader upload_aws_by_catalog \\\n  --in-dir ./cartload2 \\\n  --s3-dir \"s3://${AWS_BUCKET}/${DATA_ID}\" \\\n  --aws ${aws} \\\n  --n-jobs 10\n</code></pre> Parameter Required Type Description <code>--in-dir</code> required string Path to the input directory containing the cartloader compilation output <code>--s3-dir</code> required string Path to the target S3 directory for uploading <code>--aws</code> string Path to the AWS CLI binary <code>--n-jobs</code> int Number of parallel jobs"},{"location":"vignettes/subregion_tutorials/xenium/","title":"10X Xenium Starter Tutorial","text":""},{"location":"vignettes/subregion_tutorials/xenium/#input-data","title":"Input Data","text":"<p>This tutorial uses SGE data generated with the 10x Genomics Xenium platform, and it has been cropped to a small region of the adult mouse brain for demonstration purposes.</p> <p>File Format</p> <p>10X Genomics Xenium platform outputs Spatial Gene Expression (SGE) data in a comma-separated values (CSV) format. </p> <p>CSV File Format</p> <pre><code>\"transcript_id\",\"cell_id\",\"overlaps_nucleus\",\"feature_name\",\"x_location\",\"y_location\",\"z_location\",\"qv\"\n281827164036151,133793,1,\"Sox10\",2350.0232,4153.6846,16.592316,40.0\n281827164036152,133793,1,\"Sox10\",2350.2585,4154.5225,17.237207,10.514394\n281827164036164,151216,0,\"Sox10\",2350.5874,4277.699,14.285685,40.0\n</code></pre> <ul> <li>\"<code>transcript_id</code>\": Unique identifier for each detected transcript molecule.  </li> <li>\"<code>cell_id</code>\": ID of the segmented cell associated with the transcript.</li> <li>\"<code>overlaps_nucleus</code>\": 1 if the transcript overlaps the nucleus mask, 0 otherwise.  </li> <li>\"<code>feature_name</code>\": Gene or other features name corresponding to the transcript.  </li> <li>\"<code>x_location</code>\": X-coordinate of the transcript.  </li> <li>\"<code>y_location</code>\": Y-coordinate of the transcript.  </li> <li>\"<code>z_location</code>\": Z-coordinate (depth) of the transcript.  </li> <li>\"<code>qv</code>\": Quality value indicating confidence in transcript detection.</li> </ul> <p>Data Access</p> <p>The example data is hosted on Zenedo ().</p> <p>Follow the commands below to download the example data.</p> <pre><code>wget  \n</code></pre>"},{"location":"vignettes/subregion_tutorials/xenium/#set-up-the-environment","title":"Set Up the Environment","text":"<p>Define paths to all required binaries and resources, and target AWS S3 bucket. Optionally, specify a fixed color map for consistent rendering.</p> <pre><code># ====\n# Replace each placeholder with the actual path on your system.  \n# ====\n\n# Define paths to required binaries and resources\nspatula=/path/to/spatula/binary         # path to spatula executable\npunkst=/path/to/punkst/binary           # path to FICTURE2/punkst executable\ntippecanoe=/path/to/tippecanoe/binary   # path to tippecanoe executable\npmtiles=/path/to/pmtiles/binary         # path to pmtiles executable\naws=/path/to/aws/cli/binary             # path to AWS CLI binary\n\n# (Optional) Define path to color map. \ncmap=/path/to/color/map                 # Path to the fixed color map for rendering. cartloader provides a fixed color map at cartloader/assets/fixed_color_map_256.tsv.\n\n# AWS S3 target location for cartostore\nAWS_BUCKET=\"EXAMPLE_AWS_BUCKET\"         # replace this with your actual S3 bucket name\n</code></pre> <p>Define data ID and analysis parameters:</p> <pre><code>cd $work_dir\n\n# Unique identifier for your dataset\nDATA_ID=\"xenium_hippo\"                  # change this to reflect your dataset name\nPLATFORM=\"10x_xenium\"                   # platform information\nSCALE=1                                 # coordinate to micrometer scaling factor\n\n# LDA parameters\ntrain_width=12                           # define LDA training hexagon width (comma-separated if multiple widths are applied)\nn_factor=6,12                            # define number of factors in LDA training (comma-separated if multiple n-factor are applied)\n</code></pre> <p>How to Define Scaling Factors for Xenium</p> <p>The Xenium example data currently used here provides SGE in micrometer units. Use define scaling factor from coordinate to micrometer as 1.</p>"},{"location":"vignettes/subregion_tutorials/xenium/#sge-format-conversion","title":"SGE Format Conversion","text":"<p>Convert the raw input to the unified SGE format. See more details in Reference page.</p> <pre><code>cartloader sge_convert \\\n  --makefn sge_convert.mk \\\n  --platform ${PLATFORM} \\\n  --in-csv ./input.tsv.gz \\\n  --units-per-um ${SCALE} \\\n  --out-dir ./sge \\\n  --exclude-feature-regex '^(BLANK|NegCon|NegPrb)' \\\n  --sge-visual \\\n  --spatula ${spatula} \\\n  --n-jobs 10\n</code></pre> Parameter Required Type Description <code>--makefn</code> string File name for the generated Makefile <code>--platform</code> required string platform (options: \"10x_visium_hd\", \"seqscope\", \"10x_xenium\", \"bgi_stereoseq\", \"cosmx_smi\", \"vizgen_merscope\", \"pixel_seq\", \"nova_st\", \"generic\") <code>--in-csv</code> required string Path to the input TSV/CSV file <code>--units-per-um</code> required float Conversion factor: how many input coordinate units per micron <code>--out-dir</code> required string Output directory for the generated SGE files <code>--exclude-feature-regex</code> regex Pattern to exclude features (e.g., BLANK, NegCon) <code>--sge-visual</code> flag Enable generation of diagnostic visualization of the SGE matrix <code>--spatula</code> string Path to the spatula binary <code>--n-jobs</code> int Number of parallel jobs for processing"},{"location":"vignettes/subregion_tutorials/xenium/#ficture-analysis","title":"<code>FICTURE</code> analysis","text":"<p>Compute spatial factors using <code>punkst</code> (FICTURE2 mode). See more details in Reference page.</p> <pre><code>cartloader run_ficture2 \\\n  --makefn run_ficture2.mk \\\n  --main \\\n  --in-transcript ./sge/transcripts.unsorted.tsv.gz \\\n  --in-feature ./sge/feature.clean.tsv.gz \\\n  --in-minmax ./sge/coordinate_minmax.tsv \\\n  --cmap-file ${cmap} \\\n  --exclude-feature-regex '^(mt-.*$|Gm\\d+$)' \\\n  --out-dir ./ficture2 \\\n  --width ${train_width} \\\n  --n-factor ${n_factor} \\\n  --spatula ${spatula} \\\n  --ficture2 ${punkst} \\\n  --n-jobs 10 \\\n  --threads 10\n</code></pre> Parameter Required Type Description <code>--makefn</code> string File name for the generated Makefile <code>--main</code> required flag Run all five steps in <code>run_ficture2</code> <code>--in-transcript</code> required string Path to input transcript-level SGE file <code>--in-feature</code> string Path to input feature file <code>--in-minmax</code> string Path to coordinate min/max file <code>--cmap-file</code> string Path to color map file <code>--exclude-feature-regex</code> regex Pattern to exclude features (e.g., mitochondrial or predicted genes) <code>--out-dir</code> required string Path to output directory <code>--width</code> required int or comma-separated list LDA training hexagon width(s) <code>--n-factor</code> required int or comma-separated list Number of LDA factors <code>--spatula</code> string Path to the <code>spatula</code> binary <code>--ficture2</code> string Path to the <code>punkst</code> directory <code>--n-jobs</code> int Number of parallel jobs <code>--threads</code> int Number of threads per job"},{"location":"vignettes/subregion_tutorials/xenium/#cartloader-compilation","title":"<code>cartloader</code> Compilation","text":"<p>Generate pmtiles and web-compatible tile directories. See more details in Reference page.</p> <pre><code>cartloader run_cartload2 \\\n  --makefn run_cartload2.mk \\\n  --fic-dir ./ficture2 \\\n  --out-dir ./cartload2 \\\n  --id ${DATA_ID} \\\n  --spatula ${spatula} \\\n  --pmtiles ${pmtiles} \\\n  --tippecanoe ${tippecanoe} \\\n  --n-jobs 10 \\\n  --threads 10\n</code></pre> Parameter Required Type Description <code>--makefn</code> string File name for the generated Makefile <code>--fic-dir</code> required string Path to the input directory containing FICTURE2 output <code>--out-dir</code> required string Path to the output directory for PMTiles and web tiles <code>--id</code> required string Dataset ID used for naming outputs and metadata <code>--spatula</code> string Path to the <code>spatula</code> binary <code>--pmtiles</code> string Path to the <code>pmtiles</code> binary <code>--tippecanoe</code> string Path to the <code>tippecanoe</code> binary <code>--n-jobs</code> int Number of parallel jobs <code>--threads</code> int Number of threads per job"},{"location":"vignettes/subregion_tutorials/xenium/#upload-to-data-repository","title":"Upload to Data Repository","text":""},{"location":"vignettes/subregion_tutorials/xenium/#upload-to-aws","title":"Upload to AWS","text":"<p>Copy the generated cartloader outputs to your designated AWS S3 catalog path:</p> <pre><code>cartloader upload_aws_by_catalog \\\n  --in-dir ./cartload2 \\\n  --s3-dir \"s3://${AWS_BUCKET}/${DATA_ID}\" \\\n  --aws ${aws} \\\n  --n-jobs 10\n</code></pre> Parameter Required Type Description <code>--in-dir</code> required string Path to the input directory containing the cartloader compilation output <code>--s3-dir</code> required string Path to the target S3 directory for uploading <code>--aws</code> string Path to the AWS CLI binary <code>--n-jobs</code> int Number of parallel jobs"}]}